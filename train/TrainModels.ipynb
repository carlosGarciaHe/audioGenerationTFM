{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8127a77-6a95-47b6-8e58-f15933908cac",
   "metadata": {},
   "source": [
    "# **Train Models**\n",
    "\n",
    "Este notebook tiene como misión proporcionar el punto de acceso para entrenamiento y evaluación de cada uno de los modelos desarrollados adaptándose a sus particularidades de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ef305-0bce-4d37-b028-4ea414a64ce2",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed9d722-3e8c-4307-9d95-5cbff1813b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bea0aa-9b7a-4b33-bd7e-bab6e75cd46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122a39fb-7178-497e-9cb5-70700ed0de7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48edebb-a3fa-4eb4-b690-d03640528b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676dcd87-03fb-47cb-b716-bd15f0c2c606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ddad0e-7faa-44ee-a28b-e61385cc2b99",
   "metadata": {},
   "source": [
    "Añadimos al sistema la ruta con nuestro código desarrollado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fbc3bf-7273-41ec-b048-5e1448477dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00ec36-f295-4212-89de-7908153fd64f",
   "metadata": {},
   "source": [
    "Importamos el código desarrollado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee90540a-37e2-473e-afae-409270905013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import VideoDatasetAprox1, LocalVideoDatasetAprox1, VideoDatasetAprox2, LocalVideoDatasetAprox2, VideoDatasetAprox3, VideoDatasetAprox4\n",
    "from Model import ModelAprox1, ModelAprox2, ModelAprox3, ModelAprox4, ModelAprox5\n",
    "from Model import ModelAprox6, ModelAprox7, ModelAprox8, ModelAprox9, ModelAprox10\n",
    "from Model import ModelAprox11, ModelAprox12, ModelAprox13, ModelAprox14, ModelAprox15\n",
    "from Model import ModelAprox16, ModelAprox17, ModelAprox18, ModelAprox19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90472e31-f44f-4baa-ad3e-99ff83801130",
   "metadata": {},
   "source": [
    "## **1. RNN con audio como input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f9745-18fc-40c1-baf7-00b24ce45f31",
   "metadata": {},
   "source": [
    "Inicializamos el dataset correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966c90cc-38c1-4273-a7da-4c517a1f3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalVideoDatasetAprox1(set_selected=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7502c56-bbaa-422c-a23b-ed4d832cac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57211ff-a204-4ed1-9d6e-5c514f3cfc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con 60157 instancias con las que poder trabajar\n"
     ]
    }
   ],
   "source": [
    "#print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))\n",
    "print(\"Dataset con %d instancias con las que poder trabajar\"%(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb0f3e-6094-42e4-8874-73e56b86338b",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779e7bd7-cbc8-4130-87ed-925ba15a8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbbfa3b-b5ee-4033-803f-aa869a91e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox1(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(0)\n",
    "model.cuda()\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0caaef2-598f-4537-88eb-1ae083b260c4",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "711c26b4-a007-44e1-b7ff-a553705ca85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081f15e-2d32-4a06-8249-99ca4dca7167",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe238f1-1930-43a4-93e3-115705a41438",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos_mds/train/../src/Dataset.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sound_frames = torch.tensor(sound_frames, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 20/60157............. Loss: 5.5456\n",
      "batch: 40/60157............. Loss: 5.5447\n",
      "batch: 60/60157............. Loss: 5.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid new backstep -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 80/60157............. Loss: 5.5427\n",
      "batch: 100/60157............. Loss: 5.5418\n",
      "batch: 120/60157............. Loss: 5.5411\n",
      "batch: 140/60157............. Loss: 5.5391\n",
      "batch: 160/60157............. Loss: 5.5393\n",
      "batch: 180/60157............. Loss: 5.5382\n",
      "batch: 200/60157............. Loss: 5.5386\n",
      "batch: 220/60157............. Loss: 5.5368\n",
      "batch: 240/60157............. Loss: 5.5368\n",
      "batch: 260/60157............. Loss: 5.5366\n",
      "batch: 280/60157............. Loss: 5.5343\n",
      "batch: 300/60157............. Loss: 5.5330\n",
      "batch: 320/60157............. Loss: 5.5349\n",
      "batch: 340/60157............. Loss: 5.5327\n",
      "batch: 360/60157............. Loss: 5.5314\n",
      "batch: 380/60157............. Loss: 5.5345\n",
      "batch: 400/60157............. Loss: 5.5326\n",
      "batch: 420/60157............. Loss: 5.5349\n",
      "batch: 440/60157............. Loss: 5.5315\n",
      "batch: 460/60157............. Loss: 5.5325\n",
      "batch: 480/60157............. Loss: 5.5326\n",
      "batch: 500/60157............. Loss: 5.5316\n",
      "batch: 520/60157............. Loss: 5.5340\n",
      "batch: 540/60157............. Loss: 5.5352\n",
      "batch: 560/60157............. Loss: 5.5279\n",
      "batch: 580/60157............. Loss: 5.5317\n",
      "batch: 600/60157............. Loss: 5.5341\n",
      "batch: 620/60157............. Loss: 5.5352\n",
      "batch: 640/60157............. Loss: 5.5326\n",
      "batch: 660/60157............. Loss: 5.5330\n",
      "batch: 680/60157............. Loss: 5.5296\n",
      "batch: 700/60157............. Loss: 5.5290\n",
      "batch: 720/60157............. Loss: 5.5291\n",
      "batch: 740/60157............. Loss: 5.5292\n",
      "batch: 760/60157............. Loss: 5.5301\n",
      "batch: 780/60157............. Loss: 5.5276\n",
      "batch: 800/60157............. Loss: 5.5264\n",
      "batch: 820/60157............. Loss: 5.5312\n",
      "batch: 840/60157............. Loss: 5.5266\n",
      "batch: 860/60157............. Loss: 5.5285\n",
      "batch: 880/60157............. Loss: 5.5307\n",
      "batch: 900/60157............. Loss: 5.5311\n",
      "batch: 920/60157............. Loss: 5.5339\n",
      "batch: 940/60157............. Loss: 5.5306\n",
      "batch: 960/60157............. Loss: 5.5328\n",
      "batch: 980/60157............. Loss: 5.5297\n",
      "batch: 1000/60157............. Loss: 5.5302\n",
      "batch: 1020/60157............. Loss: 5.5274\n",
      "batch: 1040/60157............. Loss: 5.5285\n",
      "batch: 1060/60157............. Loss: 5.5295\n",
      "batch: 1080/60157............. Loss: 5.5312\n",
      "batch: 1100/60157............. Loss: 5.5292\n",
      "batch: 1120/60157............. Loss: 5.5298\n",
      "batch: 1140/60157............. Loss: 5.5296\n",
      "batch: 1160/60157............. Loss: 5.5312\n",
      "batch: 1180/60157............. Loss: 5.5266\n",
      "batch: 1200/60157............. Loss: 5.5235\n",
      "batch: 1220/60157............. Loss: 5.5269\n",
      "batch: 1240/60157............. Loss: 5.5304\n",
      "batch: 1260/60157............. Loss: 5.5267\n",
      "batch: 1280/60157............. Loss: 5.5281\n",
      "batch: 1300/60157............. Loss: 5.5251\n",
      "batch: 1320/60157............. Loss: 5.5273\n",
      "batch: 1340/60157............. Loss: 5.5286\n",
      "batch: 1360/60157............. Loss: 5.5287\n",
      "batch: 1380/60157............. Loss: 5.5247\n",
      "batch: 1400/60157............. Loss: 5.5256\n",
      "batch: 1420/60157............. Loss: 5.5285\n",
      "batch: 1440/60157............. Loss: 5.5218\n",
      "batch: 1460/60157............. Loss: 5.5280\n",
      "batch: 1480/60157............. Loss: 5.5254\n",
      "batch: 1500/60157............. Loss: 5.5275\n",
      "batch: 1520/60157............. Loss: 5.5279\n",
      "batch: 1540/60157............. Loss: 5.5288\n",
      "batch: 1560/60157............. Loss: 5.5249\n",
      "batch: 1580/60157............. Loss: 5.5270\n",
      "batch: 1600/60157............. Loss: 5.5301\n",
      "batch: 1620/60157............. Loss: 5.5243\n",
      "batch: 1640/60157............. Loss: 5.5264\n",
      "batch: 1660/60157............. Loss: 5.5296\n",
      "batch: 1680/60157............. Loss: 5.5268\n",
      "batch: 1700/60157............. Loss: 5.5246\n",
      "batch: 1720/60157............. Loss: 5.5296\n",
      "batch: 1740/60157............. Loss: 5.5265\n",
      "batch: 1760/60157............. Loss: 5.5271\n",
      "batch: 1780/60157............. Loss: 5.5230\n",
      "batch: 1800/60157............. Loss: 5.5236\n",
      "batch: 1820/60157............. Loss: 5.5284\n",
      "batch: 1840/60157............. Loss: 5.5282\n",
      "batch: 1860/60157............. Loss: 5.5247\n",
      "batch: 1880/60157............. Loss: 5.5231\n",
      "batch: 1900/60157............. Loss: 5.5243\n",
      "batch: 1920/60157............. Loss: 5.5290\n",
      "batch: 1940/60157............. Loss: 5.5244\n",
      "batch: 1960/60157............. Loss: 5.5300\n",
      "batch: 1980/60157............. Loss: 5.5254\n",
      "batch: 2000/60157............. Loss: 5.5252\n",
      "batch: 2020/60157............. Loss: 5.5241\n",
      "batch: 2040/60157............. Loss: 5.5305\n",
      "batch: 2060/60157............. Loss: 5.5261\n",
      "batch: 2080/60157............. Loss: 5.5257\n",
      "batch: 2100/60157............. Loss: 5.5281\n",
      "batch: 2120/60157............. Loss: 5.5279\n",
      "batch: 2140/60157............. Loss: 5.5262\n",
      "batch: 2160/60157............. Loss: 5.5261\n",
      "batch: 2180/60157............. Loss: 5.5253\n",
      "batch: 2200/60157............. Loss: 5.5249\n",
      "batch: 2220/60157............. Loss: 5.5270\n",
      "batch: 2240/60157............. Loss: 5.5223\n",
      "batch: 2260/60157............. Loss: 5.5225\n",
      "batch: 2280/60157............. Loss: 5.5260\n",
      "batch: 2300/60157............. Loss: 5.5298\n",
      "batch: 2320/60157............. Loss: 5.5249\n",
      "batch: 2340/60157............. Loss: 5.5274\n",
      "batch: 2360/60157............. Loss: 5.5287\n",
      "batch: 2380/60157............. Loss: 5.5251\n",
      "batch: 2400/60157............. Loss: 5.5243\n",
      "batch: 2420/60157............. Loss: 5.5204\n",
      "batch: 2440/60157............. Loss: 5.5274\n",
      "batch: 2460/60157............. Loss: 5.5253\n",
      "batch: 2480/60157............. Loss: 5.5264\n",
      "batch: 2500/60157............. Loss: 5.5260\n",
      "batch: 2520/60157............. Loss: 5.5246\n",
      "batch: 2540/60157............. Loss: 5.5239\n",
      "batch: 2560/60157............. Loss: 5.5272\n",
      "batch: 2580/60157............. Loss: 5.5284\n",
      "batch: 2600/60157............. Loss: 5.5222\n",
      "batch: 2620/60157............. Loss: 5.5233\n",
      "batch: 2640/60157............. Loss: 5.5213\n",
      "batch: 2660/60157............. Loss: 5.5285\n",
      "batch: 2680/60157............. Loss: 5.5250\n",
      "batch: 2700/60157............. Loss: 5.5277\n",
      "batch: 2720/60157............. Loss: 5.5268\n",
      "batch: 2740/60157............. Loss: 5.5261\n",
      "batch: 2760/60157............. Loss: 5.5243\n",
      "batch: 2780/60157............. Loss: 5.5294\n",
      "batch: 2800/60157............. Loss: 5.5252\n",
      "batch: 2820/60157............. Loss: 5.5227\n",
      "batch: 2840/60157............. Loss: 5.5281\n",
      "batch: 2860/60157............. Loss: 5.5263\n",
      "batch: 2880/60157............. Loss: 5.5256\n",
      "batch: 2900/60157............. Loss: 5.5213\n",
      "batch: 2920/60157............. Loss: 5.5263\n",
      "batch: 2940/60157............. Loss: 5.5266\n",
      "batch: 2960/60157............. Loss: 5.5300\n",
      "batch: 2980/60157............. Loss: 5.5230\n",
      "batch: 3000/60157............. Loss: 5.5232\n",
      "batch: 3020/60157............. Loss: 5.5287\n",
      "batch: 3040/60157............. Loss: 5.5274\n",
      "batch: 3060/60157............. Loss: 5.5197\n",
      "batch: 3080/60157............. Loss: 5.5249\n",
      "batch: 3100/60157............. Loss: 5.5271\n",
      "batch: 3120/60157............. Loss: 5.5245\n",
      "batch: 3140/60157............. Loss: 5.5243\n",
      "batch: 3160/60157............. Loss: 5.5255\n",
      "batch: 3180/60157............. Loss: 5.5218\n",
      "batch: 3200/60157............. Loss: 5.5251\n",
      "batch: 3220/60157............. Loss: 5.5279\n",
      "batch: 3240/60157............. Loss: 5.5199\n",
      "batch: 3260/60157............. Loss: 5.5267\n",
      "batch: 3280/60157............. Loss: 5.5256\n",
      "batch: 3300/60157............. Loss: 5.5257\n",
      "batch: 3320/60157............. Loss: 5.5228\n",
      "batch: 3340/60157............. Loss: 5.5250\n",
      "batch: 3360/60157............. Loss: 5.5291\n",
      "batch: 3380/60157............. Loss: 5.5292\n",
      "batch: 3400/60157............. Loss: 5.5299\n",
      "batch: 3420/60157............. Loss: 5.5281\n",
      "batch: 3440/60157............. Loss: 5.5234\n",
      "batch: 3460/60157............. Loss: 5.5253\n",
      "batch: 3480/60157............. Loss: 5.5233\n",
      "batch: 3500/60157............. Loss: 5.5207\n",
      "batch: 3520/60157............. Loss: 5.5249\n",
      "batch: 3540/60157............. Loss: 5.5213\n",
      "batch: 3560/60157............. Loss: 5.5224\n",
      "batch: 3580/60157............. Loss: 5.5217\n",
      "batch: 3600/60157............. Loss: 5.5242\n",
      "batch: 3620/60157............. Loss: 5.5275\n",
      "batch: 3640/60157............. Loss: 5.5260\n",
      "batch: 3660/60157............. Loss: 5.5284\n",
      "batch: 3680/60157............. Loss: 5.5226\n",
      "batch: 3700/60157............. Loss: 5.5200\n",
      "batch: 3720/60157............. Loss: 5.5270\n",
      "batch: 3740/60157............. Loss: 5.5261\n",
      "batch: 3760/60157............. Loss: 5.5243\n",
      "batch: 3780/60157............. Loss: 5.5269\n",
      "batch: 3800/60157............. Loss: 5.5234\n",
      "batch: 3820/60157............. Loss: 5.5240\n",
      "batch: 3840/60157............. Loss: 5.5249\n",
      "batch: 3860/60157............. Loss: 5.5198\n",
      "batch: 3880/60157............. Loss: 5.5221\n",
      "batch: 3900/60157............. Loss: 5.5257\n",
      "batch: 3920/60157............. Loss: 5.5279\n",
      "batch: 3940/60157............. Loss: 5.5273\n",
      "batch: 3960/60157............. Loss: 5.5176\n",
      "batch: 3980/60157............. Loss: 5.5269\n",
      "batch: 4000/60157............. Loss: 5.5235\n",
      "batch: 4020/60157............. Loss: 5.5240\n",
      "batch: 4040/60157............. Loss: 5.5256\n",
      "batch: 4060/60157............. Loss: 5.5269\n",
      "batch: 4080/60157............. Loss: 5.5213\n",
      "batch: 4100/60157............. Loss: 5.5219\n",
      "batch: 4120/60157............. Loss: 5.5229\n",
      "batch: 4140/60157............. Loss: 5.5292\n",
      "batch: 4160/60157............. Loss: 5.5289\n",
      "batch: 4180/60157............. Loss: 5.5269\n",
      "batch: 4200/60157............. Loss: 5.5239\n",
      "batch: 4220/60157............. Loss: 5.5232\n",
      "batch: 4240/60157............. Loss: 5.5258\n",
      "batch: 4260/60157............. Loss: 5.5262\n",
      "batch: 4280/60157............. Loss: 5.5233\n",
      "batch: 4300/60157............. Loss: 5.5283\n",
      "batch: 4320/60157............. Loss: 5.5251\n",
      "batch: 4340/60157............. Loss: 5.5284\n",
      "batch: 4360/60157............. Loss: 5.5191\n",
      "batch: 4380/60157............. Loss: 5.5255\n",
      "batch: 4400/60157............. Loss: 5.5266\n",
      "batch: 4420/60157............. Loss: 5.5297\n",
      "batch: 4440/60157............. Loss: 5.5282\n",
      "batch: 4460/60157............. Loss: 5.5214\n",
      "batch: 4480/60157............. Loss: 5.5310\n",
      "batch: 4500/60157............. Loss: 5.5247\n",
      "batch: 4520/60157............. Loss: 5.5225\n",
      "batch: 4540/60157............. Loss: 5.5203\n",
      "batch: 4560/60157............. Loss: 5.5228\n",
      "batch: 4580/60157............. Loss: 5.5265\n",
      "batch: 4600/60157............. Loss: 5.5206\n",
      "batch: 4620/60157............. Loss: 5.5231\n",
      "batch: 4640/60157............. Loss: 5.5272\n",
      "batch: 4660/60157............. Loss: 5.5264\n",
      "batch: 4680/60157............. Loss: 5.5263\n",
      "batch: 4700/60157............. Loss: 5.5236\n",
      "batch: 4720/60157............. Loss: 5.5257\n",
      "batch: 4740/60157............. Loss: 5.5238\n",
      "batch: 4760/60157............. Loss: 5.5189\n",
      "batch: 4780/60157............. Loss: 5.5256\n",
      "batch: 4800/60157............. Loss: 5.5274\n",
      "batch: 4820/60157............. Loss: 5.5184\n",
      "batch: 4840/60157............. Loss: 5.5256\n",
      "batch: 4860/60157............. Loss: 5.5225\n",
      "batch: 4880/60157............. Loss: 5.5024\n",
      "batch: 4900/60157............. Loss: 5.5214\n",
      "batch: 4920/60157............. Loss: 5.5256\n",
      "batch: 4940/60157............. Loss: 5.5266\n",
      "batch: 4960/60157............. Loss: 5.5289\n",
      "batch: 4980/60157............. Loss: 5.5277\n",
      "batch: 5000/60157............. Loss: 5.5251\n",
      "batch: 5020/60157............. Loss: 5.5246\n",
      "batch: 5040/60157............. Loss: 5.5266\n",
      "batch: 5060/60157............. Loss: 5.5243\n",
      "batch: 5080/60157............. Loss: 5.5202\n",
      "batch: 5100/60157............. Loss: 5.5214\n",
      "batch: 5120/60157............. Loss: 5.5195\n",
      "batch: 5140/60157............. Loss: 5.5267\n",
      "batch: 5160/60157............. Loss: 5.5212\n",
      "batch: 5180/60157............. Loss: 5.5234\n",
      "batch: 5200/60157............. Loss: 5.5231\n",
      "batch: 5220/60157............. Loss: 5.5319\n",
      "batch: 5240/60157............. Loss: 5.5255\n",
      "batch: 5260/60157............. Loss: 5.5256\n",
      "batch: 5280/60157............. Loss: 5.5237\n",
      "batch: 5300/60157............. Loss: 5.5240\n",
      "batch: 5320/60157............. Loss: 5.5255\n",
      "batch: 5340/60157............. Loss: 5.5274\n",
      "batch: 5360/60157............. Loss: 5.5275\n",
      "batch: 5380/60157............. Loss: 5.5247\n",
      "batch: 5400/60157............. Loss: 5.5275\n",
      "batch: 5420/60157............. Loss: 5.5276\n",
      "batch: 5440/60157............. Loss: 5.5241\n",
      "batch: 5460/60157............. Loss: 5.5251\n",
      "batch: 5480/60157............. Loss: 5.5248\n",
      "batch: 5500/60157............. Loss: 5.5266\n",
      "batch: 5520/60157............. Loss: 5.5202\n",
      "batch: 5540/60157............. Loss: 5.5200\n",
      "batch: 5560/60157............. Loss: 5.5251\n",
      "batch: 5580/60157............. Loss: 5.5240\n",
      "batch: 5600/60157............. Loss: 5.5258\n",
      "batch: 5620/60157............. Loss: 5.5201\n",
      "batch: 5640/60157............. Loss: 5.5215\n",
      "batch: 5660/60157............. Loss: 5.5274\n",
      "batch: 5680/60157............. Loss: 5.5213\n",
      "batch: 5700/60157............. Loss: 5.5162\n",
      "batch: 5720/60157............. Loss: 5.5245\n",
      "batch: 5740/60157............. Loss: 5.5305\n",
      "batch: 5760/60157............. Loss: 5.5264\n",
      "batch: 5780/60157............. Loss: 5.5285\n",
      "batch: 5800/60157............. Loss: 5.5269\n",
      "batch: 5820/60157............. Loss: 5.5282\n",
      "batch: 5840/60157............. Loss: 5.5277\n",
      "batch: 5860/60157............. Loss: 5.5247\n",
      "batch: 5880/60157............. Loss: 5.5301\n",
      "batch: 5900/60157............. Loss: 5.5242\n",
      "batch: 5920/60157............. Loss: 5.5213\n",
      "batch: 5940/60157............. Loss: 5.5288\n",
      "batch: 5960/60157............. Loss: 5.5218\n",
      "batch: 5980/60157............. Loss: 5.5277\n",
      "batch: 6000/60157............. Loss: 5.5253\n",
      "batch: 6020/60157............. Loss: 5.5308\n",
      "batch: 6040/60157............. Loss: 5.5276\n",
      "batch: 6060/60157............. Loss: 5.5255\n",
      "batch: 6080/60157............. Loss: 5.5315\n",
      "batch: 6100/60157............. Loss: 5.5251\n",
      "batch: 6120/60157............. Loss: 5.5206\n",
      "batch: 6140/60157............. Loss: 5.5267\n",
      "batch: 6160/60157............. Loss: 5.5253\n",
      "batch: 6180/60157............. Loss: 5.5205\n",
      "batch: 6200/60157............. Loss: 5.5275\n",
      "batch: 6220/60157............. Loss: 5.5234\n",
      "batch: 6240/60157............. Loss: 5.5263\n",
      "batch: 6260/60157............. Loss: 5.5232\n",
      "batch: 6280/60157............. Loss: 5.5259\n",
      "batch: 6300/60157............. Loss: 5.5219\n",
      "batch: 6320/60157............. Loss: 5.5268\n",
      "batch: 6340/60157............. Loss: 5.5229\n",
      "batch: 6360/60157............. Loss: 5.5235\n",
      "batch: 6380/60157............. Loss: 5.5220\n",
      "batch: 6400/60157............. Loss: 5.5282\n",
      "batch: 6420/60157............. Loss: 5.5238\n",
      "batch: 6440/60157............. Loss: 5.5264\n",
      "batch: 6460/60157............. Loss: 5.5279\n",
      "batch: 6480/60157............. Loss: 5.5244\n",
      "batch: 6500/60157............. Loss: 5.5272\n",
      "batch: 6520/60157............. Loss: 5.5208\n",
      "batch: 6540/60157............. Loss: 5.5253\n",
      "batch: 6560/60157............. Loss: 5.5219\n",
      "batch: 6580/60157............. Loss: 5.5295\n",
      "batch: 6600/60157............. Loss: 5.5257\n",
      "batch: 6620/60157............. Loss: 5.5268\n",
      "batch: 6640/60157............. Loss: 5.5257\n",
      "batch: 6660/60157............. Loss: 5.5263\n",
      "batch: 6680/60157............. Loss: 5.5289\n",
      "batch: 6700/60157............. Loss: 5.5220\n",
      "batch: 6720/60157............. Loss: 5.5282\n",
      "batch: 6740/60157............. Loss: 5.5228\n",
      "batch: 6760/60157............. Loss: 5.5288\n",
      "batch: 6780/60157............. Loss: 5.5254\n",
      "batch: 6800/60157............. Loss: 5.5277\n",
      "batch: 6820/60157............. Loss: 5.5226\n",
      "batch: 6840/60157............. Loss: 5.5279\n",
      "batch: 6860/60157............. Loss: 5.5252\n",
      "batch: 6880/60157............. Loss: 5.5260\n",
      "batch: 6900/60157............. Loss: 5.5270\n",
      "batch: 6920/60157............. Loss: 5.5253\n",
      "batch: 6940/60157............. Loss: 5.5248\n",
      "batch: 6960/60157............. Loss: 5.5262\n",
      "batch: 6980/60157............. Loss: 5.5281\n",
      "batch: 7000/60157............. Loss: 5.5222\n",
      "batch: 7020/60157............. Loss: 5.5224\n",
      "batch: 7040/60157............. Loss: 5.5251\n",
      "batch: 7060/60157............. Loss: 5.5210\n",
      "batch: 7080/60157............. Loss: 5.5234\n",
      "batch: 7100/60157............. Loss: 5.5234\n",
      "batch: 7120/60157............. Loss: 5.5192\n",
      "batch: 7140/60157............. Loss: 5.5242\n",
      "batch: 7160/60157............. Loss: 5.5264\n",
      "batch: 7180/60157............. Loss: 5.5228\n",
      "batch: 7200/60157............. Loss: 5.5267\n",
      "batch: 7220/60157............. Loss: 5.5279\n",
      "batch: 7240/60157............. Loss: 5.5218\n",
      "batch: 7260/60157............. Loss: 5.5279\n",
      "batch: 7280/60157............. Loss: 5.5241\n",
      "batch: 7300/60157............. Loss: 5.5252\n",
      "batch: 7320/60157............. Loss: 5.5256\n",
      "batch: 7340/60157............. Loss: 5.5270\n",
      "batch: 7360/60157............. Loss: 5.5191\n",
      "batch: 7380/60157............. Loss: 5.5250\n",
      "batch: 7400/60157............. Loss: 5.5283\n",
      "batch: 7420/60157............. Loss: 5.5287\n",
      "batch: 7440/60157............. Loss: 5.5261\n",
      "batch: 7460/60157............. Loss: 5.5219\n",
      "batch: 7480/60157............. Loss: 5.5232\n",
      "batch: 7500/60157............. Loss: 5.5232\n",
      "batch: 7520/60157............. Loss: 5.5270\n",
      "batch: 7540/60157............. Loss: 5.5258\n",
      "batch: 7560/60157............. Loss: 5.5236\n",
      "batch: 7580/60157............. Loss: 5.5248\n",
      "batch: 7600/60157............. Loss: 5.5184\n",
      "batch: 7620/60157............. Loss: 5.5246\n",
      "batch: 7640/60157............. Loss: 5.5216\n",
      "batch: 7660/60157............. Loss: 5.5268\n",
      "batch: 7680/60157............. Loss: 5.5205\n",
      "batch: 7700/60157............. Loss: 5.5234\n",
      "batch: 7720/60157............. Loss: 5.5261\n",
      "batch: 7740/60157............. Loss: 5.5222\n",
      "batch: 7760/60157............. Loss: 5.5224\n",
      "batch: 7780/60157............. Loss: 5.5265\n",
      "batch: 7800/60157............. Loss: 5.5214\n",
      "batch: 7820/60157............. Loss: 5.5244\n",
      "batch: 7840/60157............. Loss: 5.5269\n",
      "batch: 7860/60157............. Loss: 5.5244\n",
      "batch: 7880/60157............. Loss: 5.5245\n",
      "batch: 7900/60157............. Loss: 5.5231\n",
      "batch: 7920/60157............. Loss: 5.5248\n",
      "batch: 7940/60157............. Loss: 5.5189\n",
      "batch: 7960/60157............. Loss: 5.5207\n",
      "batch: 7980/60157............. Loss: 5.5205\n",
      "batch: 8000/60157............. Loss: 5.5259\n",
      "batch: 8020/60157............. Loss: 5.5302\n",
      "batch: 8040/60157............. Loss: 5.5203\n",
      "batch: 8060/60157............. Loss: 5.5285\n",
      "batch: 8080/60157............. Loss: 5.5257\n",
      "batch: 8100/60157............. Loss: 5.5196\n",
      "batch: 8120/60157............. Loss: 5.5231\n",
      "batch: 8140/60157............. Loss: 5.5271\n",
      "batch: 8160/60157............. Loss: 5.5234\n",
      "batch: 8180/60157............. Loss: 5.5237\n",
      "batch: 8200/60157............. Loss: 5.5250\n",
      "batch: 8220/60157............. Loss: 5.5271\n",
      "batch: 8240/60157............. Loss: 5.5281\n",
      "batch: 8260/60157............. Loss: 5.5226\n",
      "batch: 8280/60157............. Loss: 5.5225\n",
      "batch: 8300/60157............. Loss: 5.5211\n",
      "batch: 8320/60157............. Loss: 5.5211\n",
      "batch: 8340/60157............. Loss: 5.5235\n",
      "batch: 8360/60157............. Loss: 5.5220\n",
      "batch: 8380/60157............. Loss: 5.5255\n",
      "batch: 8400/60157............. Loss: 5.5253\n",
      "batch: 8420/60157............. Loss: 5.5263\n",
      "batch: 8440/60157............. Loss: 5.5173\n",
      "batch: 8460/60157............. Loss: 5.5243\n",
      "batch: 8480/60157............. Loss: 5.5260\n",
      "batch: 8500/60157............. Loss: 5.5205\n",
      "batch: 8520/60157............. Loss: 5.5280\n",
      "batch: 8540/60157............. Loss: 5.5271\n",
      "batch: 8560/60157............. Loss: 5.5224\n",
      "batch: 8580/60157............. Loss: 5.5245\n",
      "batch: 8600/60157............. Loss: 5.5240\n",
      "batch: 8620/60157............. Loss: 5.5234\n",
      "batch: 8640/60157............. Loss: 5.5249\n",
      "batch: 8660/60157............. Loss: 5.5250\n",
      "batch: 8680/60157............. Loss: 5.5248\n",
      "batch: 8700/60157............. Loss: 5.5242\n",
      "batch: 8720/60157............. Loss: 5.5190\n",
      "batch: 8740/60157............. Loss: 5.5208\n",
      "batch: 8760/60157............. Loss: 5.5262\n",
      "batch: 8780/60157............. Loss: 5.5249\n",
      "batch: 8800/60157............. Loss: 5.5209\n",
      "batch: 8820/60157............. Loss: 5.5263\n",
      "batch: 8840/60157............. Loss: 5.5264\n",
      "batch: 8860/60157............. Loss: 5.5260\n",
      "batch: 8880/60157............. Loss: 5.5198\n",
      "batch: 8900/60157............. Loss: 5.5227\n",
      "batch: 8920/60157............. Loss: 5.5276\n",
      "batch: 8940/60157............. Loss: 5.5256\n",
      "batch: 8960/60157............. Loss: 5.5217\n",
      "batch: 8980/60157............. Loss: 5.5278\n",
      "batch: 9000/60157............. Loss: 5.5238\n",
      "batch: 9020/60157............. Loss: 5.5254\n",
      "batch: 9040/60157............. Loss: 5.5222\n",
      "batch: 9060/60157............. Loss: 5.5187\n",
      "batch: 9080/60157............. Loss: 5.5239\n",
      "batch: 9100/60157............. Loss: 5.5249\n",
      "batch: 9120/60157............. Loss: 5.5199\n",
      "batch: 9140/60157............. Loss: 5.5292\n",
      "batch: 9160/60157............. Loss: 5.5211\n",
      "batch: 9180/60157............. Loss: 5.5198\n",
      "batch: 9200/60157............. Loss: 5.5226\n",
      "batch: 9220/60157............. Loss: 5.5219\n",
      "batch: 9240/60157............. Loss: 5.5232\n",
      "batch: 9260/60157............. Loss: 5.5213\n",
      "batch: 9280/60157............. Loss: 5.5262\n",
      "batch: 9300/60157............. Loss: 5.5218\n",
      "batch: 9320/60157............. Loss: 5.5234\n",
      "batch: 9340/60157............. Loss: 5.5208\n",
      "batch: 9360/60157............. Loss: 5.5224\n",
      "batch: 9380/60157............. Loss: 5.5199\n",
      "batch: 9400/60157............. Loss: 5.5192\n",
      "batch: 9420/60157............. Loss: 5.5250\n",
      "batch: 9440/60157............. Loss: 5.5259\n",
      "batch: 9460/60157............. Loss: 5.5211\n",
      "batch: 9480/60157............. Loss: 5.5265\n",
      "batch: 9500/60157............. Loss: 5.5216\n",
      "batch: 9520/60157............. Loss: 5.5218\n",
      "batch: 9540/60157............. Loss: 5.5213\n",
      "batch: 9560/60157............. Loss: 5.5273\n",
      "batch: 9580/60157............. Loss: 5.5229\n",
      "batch: 9600/60157............. Loss: 5.5226\n",
      "batch: 9620/60157............. Loss: 5.5191\n",
      "batch: 9640/60157............. Loss: 5.5272\n",
      "batch: 9660/60157............. Loss: 5.5280\n",
      "batch: 9680/60157............. Loss: 5.5237\n",
      "batch: 9700/60157............. Loss: 5.5267\n",
      "batch: 9720/60157............. Loss: 5.5276\n",
      "batch: 9740/60157............. Loss: 5.5245\n",
      "batch: 9760/60157............. Loss: 5.5226\n",
      "batch: 9780/60157............. Loss: 5.5177\n",
      "batch: 9800/60157............. Loss: 5.5198\n",
      "batch: 9820/60157............. Loss: 5.5242\n",
      "batch: 9840/60157............. Loss: 5.5193\n",
      "batch: 9860/60157............. Loss: 5.5208\n",
      "batch: 9880/60157............. Loss: 5.5225\n",
      "batch: 9900/60157............. Loss: 5.5223\n",
      "batch: 9920/60157............. Loss: 5.5204\n",
      "batch: 9940/60157............. Loss: 5.5234\n",
      "batch: 9960/60157............. Loss: 5.5200\n",
      "batch: 9980/60157............. Loss: 5.5252\n",
      "batch: 10000/60157............. Loss: 5.5231\n",
      "batch: 10020/60157............. Loss: 5.5246\n",
      "batch: 10040/60157............. Loss: 5.5221\n",
      "batch: 10060/60157............. Loss: 5.5231\n",
      "batch: 10080/60157............. Loss: 5.5234\n",
      "batch: 10100/60157............. Loss: 5.5204\n",
      "batch: 10120/60157............. Loss: 5.5218\n",
      "batch: 10140/60157............. Loss: 5.5228\n",
      "batch: 10160/60157............. Loss: 5.5232\n",
      "batch: 10180/60157............. Loss: 5.5260\n",
      "batch: 10200/60157............. Loss: 5.5233\n",
      "batch: 10220/60157............. Loss: 5.5208\n",
      "batch: 10240/60157............. Loss: 5.5266\n",
      "batch: 10260/60157............. Loss: 5.5217\n",
      "batch: 10280/60157............. Loss: 5.5290\n",
      "batch: 10300/60157............. Loss: 5.5265\n",
      "batch: 10320/60157............. Loss: 5.5255\n",
      "batch: 10340/60157............. Loss: 5.5229\n",
      "batch: 10360/60157............. Loss: 5.5276\n",
      "batch: 10380/60157............. Loss: 5.5271\n",
      "batch: 10400/60157............. Loss: 5.5205\n",
      "batch: 10420/60157............. Loss: 5.5188\n",
      "batch: 10440/60157............. Loss: 5.5197\n",
      "batch: 10460/60157............. Loss: 5.5234\n",
      "batch: 10480/60157............. Loss: 5.5234\n",
      "batch: 10500/60157............. Loss: 5.5236\n",
      "batch: 10520/60157............. Loss: 5.5286\n",
      "batch: 10540/60157............. Loss: 5.5247\n",
      "batch: 10560/60157............. Loss: 5.5256\n",
      "batch: 10580/60157............. Loss: 5.5237\n",
      "batch: 10600/60157............. Loss: 5.5271\n",
      "batch: 10620/60157............. Loss: 5.5262\n",
      "batch: 10640/60157............. Loss: 5.5231\n",
      "batch: 10660/60157............. Loss: 5.5194\n",
      "batch: 10680/60157............. Loss: 5.5250\n",
      "batch: 10700/60157............. Loss: 5.5204\n",
      "batch: 10720/60157............. Loss: 5.5214\n",
      "batch: 10740/60157............. Loss: 5.5214\n",
      "batch: 10760/60157............. Loss: 5.5194\n",
      "batch: 10780/60157............. Loss: 5.5228\n",
      "batch: 10800/60157............. Loss: 5.5221\n",
      "batch: 10820/60157............. Loss: 5.5257\n",
      "batch: 10840/60157............. Loss: 5.5244\n",
      "batch: 10860/60157............. Loss: 5.5221\n",
      "batch: 10880/60157............. Loss: 5.5223\n",
      "batch: 10900/60157............. Loss: 5.5196\n",
      "batch: 10920/60157............. Loss: 5.5234\n",
      "batch: 10940/60157............. Loss: 5.5214\n",
      "batch: 10960/60157............. Loss: 5.5252\n",
      "batch: 10980/60157............. Loss: 5.5224\n",
      "batch: 11000/60157............. Loss: 5.5257\n",
      "batch: 11020/60157............. Loss: 5.5240\n",
      "batch: 11040/60157............. Loss: 5.5255\n",
      "batch: 11060/60157............. Loss: 5.5237\n",
      "batch: 11080/60157............. Loss: 5.5242\n",
      "batch: 11100/60157............. Loss: 5.5228\n",
      "batch: 11120/60157............. Loss: 5.5226\n",
      "batch: 11140/60157............. Loss: 5.5194\n",
      "batch: 11160/60157............. Loss: 5.5252\n",
      "batch: 11180/60157............. Loss: 5.5248\n",
      "batch: 11200/60157............. Loss: 5.5240\n",
      "batch: 11220/60157............. Loss: 5.5247\n",
      "batch: 11240/60157............. Loss: 5.5204\n",
      "batch: 11260/60157............. Loss: 5.5234\n",
      "batch: 11280/60157............. Loss: 5.5245\n",
      "batch: 11300/60157............. Loss: 5.5232\n",
      "batch: 11320/60157............. Loss: 5.5301\n",
      "batch: 11340/60157............. Loss: 5.5259\n",
      "batch: 11360/60157............. Loss: 5.5245\n",
      "batch: 11380/60157............. Loss: 5.5226\n",
      "batch: 11400/60157............. Loss: 5.5210\n",
      "batch: 11420/60157............. Loss: 5.5223\n",
      "batch: 11440/60157............. Loss: 5.5231\n",
      "batch: 11460/60157............. Loss: 5.5235\n",
      "batch: 11480/60157............. Loss: 5.5220\n",
      "batch: 11500/60157............. Loss: 5.5228\n",
      "batch: 11520/60157............. Loss: 5.5237\n",
      "batch: 11540/60157............. Loss: 5.5223\n",
      "batch: 11560/60157............. Loss: 5.5240\n",
      "batch: 11580/60157............. Loss: 5.5188\n",
      "batch: 11600/60157............. Loss: 5.5257\n",
      "batch: 11620/60157............. Loss: 5.5258\n",
      "batch: 11640/60157............. Loss: 5.5207\n",
      "batch: 11660/60157............. Loss: 5.5209\n",
      "batch: 11680/60157............. Loss: 5.5186\n",
      "batch: 11700/60157............. Loss: 5.5233\n",
      "batch: 11720/60157............. Loss: 5.5213\n",
      "batch: 11740/60157............. Loss: 5.5217\n",
      "batch: 11760/60157............. Loss: 5.5196\n",
      "batch: 11780/60157............. Loss: 5.5260\n",
      "batch: 11800/60157............. Loss: 5.5257\n",
      "batch: 11820/60157............. Loss: 5.5216\n",
      "batch: 11840/60157............. Loss: 5.5241\n",
      "batch: 11860/60157............. Loss: 5.5204\n",
      "batch: 11880/60157............. Loss: 5.5180\n",
      "batch: 11900/60157............. Loss: 5.5225\n",
      "batch: 11920/60157............. Loss: 5.5244\n",
      "batch: 11940/60157............. Loss: 5.5292\n",
      "batch: 11960/60157............. Loss: 5.5230\n",
      "batch: 11980/60157............. Loss: 5.5257\n",
      "batch: 12000/60157............. Loss: 5.5263\n",
      "batch: 12020/60157............. Loss: 5.5273\n",
      "batch: 12040/60157............. Loss: 5.5226\n",
      "batch: 12060/60157............. Loss: 5.5272\n",
      "batch: 12080/60157............. Loss: 5.5231\n",
      "batch: 12100/60157............. Loss: 5.5228\n",
      "batch: 12120/60157............. Loss: 5.5218\n",
      "batch: 12140/60157............. Loss: 5.5160\n",
      "batch: 12160/60157............. Loss: 5.5194\n",
      "batch: 12180/60157............. Loss: 5.5242\n",
      "batch: 12200/60157............. Loss: 5.5247\n",
      "batch: 12220/60157............. Loss: 5.5197\n",
      "batch: 12240/60157............. Loss: 5.5219\n",
      "batch: 12260/60157............. Loss: 5.5240\n",
      "batch: 12280/60157............. Loss: 5.5270\n",
      "batch: 12300/60157............. Loss: 5.5242\n",
      "batch: 12320/60157............. Loss: 5.5265\n",
      "batch: 12340/60157............. Loss: 5.5238\n",
      "batch: 12360/60157............. Loss: 5.5225\n",
      "batch: 12380/60157............. Loss: 5.5193\n",
      "batch: 12400/60157............. Loss: 5.5251\n",
      "batch: 12420/60157............. Loss: 5.5214\n",
      "batch: 12440/60157............. Loss: 5.5253\n",
      "batch: 12460/60157............. Loss: 5.5206\n",
      "batch: 12480/60157............. Loss: 5.5229\n",
      "batch: 12500/60157............. Loss: 5.5234\n",
      "batch: 12520/60157............. Loss: 5.5196\n",
      "batch: 12540/60157............. Loss: 5.5272\n",
      "batch: 12560/60157............. Loss: 5.5237\n",
      "batch: 12580/60157............. Loss: 5.5237\n",
      "batch: 12600/60157............. Loss: 5.5206\n",
      "batch: 12620/60157............. Loss: 5.5253\n",
      "batch: 12640/60157............. Loss: 5.5226\n",
      "batch: 12660/60157............. Loss: 5.5181\n",
      "batch: 12680/60157............. Loss: 5.5243\n",
      "batch: 12700/60157............. Loss: 5.5261\n",
      "batch: 12720/60157............. Loss: 5.5261\n",
      "batch: 12740/60157............. Loss: 5.5237\n",
      "batch: 12760/60157............. Loss: 5.5238\n",
      "batch: 12780/60157............. Loss: 5.5261\n",
      "batch: 12800/60157............. Loss: 5.5216\n",
      "batch: 12820/60157............. Loss: 5.5226\n",
      "batch: 12840/60157............. Loss: 5.5189\n",
      "batch: 12860/60157............. Loss: 5.5232\n",
      "batch: 12880/60157............. Loss: 5.5243\n",
      "batch: 12900/60157............. Loss: 5.5292\n",
      "batch: 12920/60157............. Loss: 5.5273\n",
      "batch: 12940/60157............. Loss: 5.5270\n",
      "batch: 12960/60157............. Loss: 5.5254\n",
      "batch: 12980/60157............. Loss: 5.5115\n",
      "batch: 13000/60157............. Loss: 5.5224\n",
      "batch: 13020/60157............. Loss: 5.5240\n",
      "batch: 13040/60157............. Loss: 5.5270\n",
      "batch: 13060/60157............. Loss: 5.5256\n",
      "batch: 13080/60157............. Loss: 5.5277\n",
      "batch: 13100/60157............. Loss: 5.5214\n",
      "batch: 13120/60157............. Loss: 5.5237\n",
      "batch: 13140/60157............. Loss: 5.5248\n",
      "batch: 13160/60157............. Loss: 5.5266\n",
      "batch: 13180/60157............. Loss: 5.5296\n",
      "batch: 13200/60157............. Loss: 5.5219\n",
      "batch: 13220/60157............. Loss: 5.5275\n",
      "batch: 13240/60157............. Loss: 5.5261\n",
      "batch: 13260/60157............. Loss: 5.5203\n",
      "batch: 13280/60157............. Loss: 5.5192\n",
      "batch: 13300/60157............. Loss: 5.5235\n",
      "batch: 13320/60157............. Loss: 5.5258\n",
      "batch: 13340/60157............. Loss: 5.5245\n",
      "batch: 13360/60157............. Loss: 5.5245\n",
      "batch: 13380/60157............. Loss: 5.5296\n",
      "batch: 13400/60157............. Loss: 5.5229\n",
      "batch: 13420/60157............. Loss: 5.5277\n",
      "batch: 13440/60157............. Loss: 5.5194\n",
      "batch: 13460/60157............. Loss: 5.5265\n",
      "batch: 13480/60157............. Loss: 5.5249\n",
      "batch: 13500/60157............. Loss: 5.5259\n",
      "batch: 13520/60157............. Loss: 5.5282\n",
      "batch: 13540/60157............. Loss: 5.5215\n",
      "batch: 13560/60157............. Loss: 5.5240\n",
      "batch: 13580/60157............. Loss: 5.5281\n",
      "batch: 13600/60157............. Loss: 5.5229\n",
      "batch: 13620/60157............. Loss: 5.5213\n",
      "batch: 13640/60157............. Loss: 5.5205\n",
      "batch: 13660/60157............. Loss: 5.5234\n",
      "batch: 13680/60157............. Loss: 5.5265\n",
      "batch: 13700/60157............. Loss: 5.5271\n",
      "batch: 13720/60157............. Loss: 5.5225\n",
      "batch: 13740/60157............. Loss: 5.5278\n",
      "batch: 13760/60157............. Loss: 5.5249\n",
      "batch: 13780/60157............. Loss: 5.5240\n",
      "batch: 13800/60157............. Loss: 5.5205\n",
      "batch: 13820/60157............. Loss: 5.5232\n",
      "batch: 13840/60157............. Loss: 5.5245\n",
      "batch: 13860/60157............. Loss: 5.5216\n",
      "batch: 13880/60157............. Loss: 5.5259\n",
      "batch: 13900/60157............. Loss: 5.5199\n",
      "batch: 13920/60157............. Loss: 5.5221\n",
      "batch: 13940/60157............. Loss: 5.5282\n",
      "batch: 13960/60157............. Loss: 5.5272\n",
      "batch: 13980/60157............. Loss: 5.5206\n",
      "batch: 14000/60157............. Loss: 5.5254\n",
      "batch: 14020/60157............. Loss: 5.5281\n",
      "batch: 14040/60157............. Loss: 5.5256\n",
      "batch: 14060/60157............. Loss: 5.5237\n",
      "batch: 14080/60157............. Loss: 5.5280\n",
      "batch: 14100/60157............. Loss: 5.5292\n",
      "batch: 14120/60157............. Loss: 5.5217\n",
      "batch: 14140/60157............. Loss: 5.5185\n",
      "batch: 14160/60157............. Loss: 5.5267\n",
      "batch: 14180/60157............. Loss: 5.5204\n",
      "batch: 14200/60157............. Loss: 5.5238\n",
      "batch: 14220/60157............. Loss: 5.5220\n",
      "batch: 14240/60157............. Loss: 5.5298\n",
      "batch: 14260/60157............. Loss: 5.5277\n",
      "batch: 14280/60157............. Loss: 5.5263\n",
      "batch: 14300/60157............. Loss: 5.5276\n",
      "batch: 14320/60157............. Loss: 5.5288\n",
      "batch: 14340/60157............. Loss: 5.5238\n",
      "batch: 14360/60157............. Loss: 5.5210\n",
      "batch: 14380/60157............. Loss: 5.5236\n",
      "batch: 14400/60157............. Loss: 5.5228\n",
      "batch: 14420/60157............. Loss: 5.5238\n",
      "batch: 14440/60157............. Loss: 5.5241\n",
      "batch: 14460/60157............. Loss: 5.5284\n",
      "batch: 14480/60157............. Loss: 5.5223\n",
      "batch: 14500/60157............. Loss: 5.5231\n",
      "batch: 14520/60157............. Loss: 5.5227\n",
      "batch: 14540/60157............. Loss: 5.5256\n",
      "batch: 14560/60157............. Loss: 5.5232\n",
      "batch: 14580/60157............. Loss: 5.5227\n",
      "batch: 14600/60157............. Loss: 5.5237\n",
      "batch: 14620/60157............. Loss: 5.5223\n",
      "batch: 14640/60157............. Loss: 5.5216\n",
      "batch: 14660/60157............. Loss: 5.5230\n",
      "batch: 14680/60157............. Loss: 5.5242\n",
      "batch: 14700/60157............. Loss: 5.5229\n",
      "batch: 14720/60157............. Loss: 5.5232\n",
      "batch: 14740/60157............. Loss: 5.5214\n",
      "batch: 14760/60157............. Loss: 5.5205\n",
      "batch: 14780/60157............. Loss: 5.5251\n",
      "batch: 14800/60157............. Loss: 5.5204\n",
      "batch: 14820/60157............. Loss: 5.5293\n",
      "batch: 14840/60157............. Loss: 5.5264\n",
      "batch: 14860/60157............. Loss: 5.5267\n",
      "batch: 14880/60157............. Loss: 5.5254\n",
      "batch: 14900/60157............. Loss: 5.5275\n",
      "batch: 14920/60157............. Loss: 5.5238\n",
      "batch: 14940/60157............. Loss: 5.5202\n",
      "batch: 14960/60157............. Loss: 5.5265\n",
      "batch: 14980/60157............. Loss: 5.5264\n",
      "batch: 15000/60157............. Loss: 5.5277\n",
      "batch: 15020/60157............. Loss: 5.5245\n",
      "batch: 15040/60157............. Loss: 5.5256\n",
      "batch: 15060/60157............. Loss: 5.5203\n",
      "batch: 15080/60157............. Loss: 5.5233\n",
      "batch: 15100/60157............. Loss: 5.5222\n",
      "batch: 15120/60157............. Loss: 5.5251\n",
      "batch: 15140/60157............. Loss: 5.5262\n",
      "batch: 15160/60157............. Loss: 5.5249\n",
      "batch: 15180/60157............. Loss: 5.5244\n",
      "batch: 15200/60157............. Loss: 5.5283\n",
      "batch: 15220/60157............. Loss: 5.5260\n",
      "batch: 15240/60157............. Loss: 5.5213\n",
      "batch: 15260/60157............. Loss: 5.5246\n",
      "batch: 15280/60157............. Loss: 5.5253\n",
      "batch: 15300/60157............. Loss: 5.5251\n",
      "batch: 15320/60157............. Loss: 5.5237\n",
      "batch: 15340/60157............. Loss: 5.5241\n",
      "batch: 15360/60157............. Loss: 5.5285\n",
      "batch: 15380/60157............. Loss: 5.5217\n",
      "batch: 15400/60157............. Loss: 5.5306\n",
      "batch: 15420/60157............. Loss: 5.5292\n",
      "batch: 15440/60157............. Loss: 5.5264\n",
      "batch: 15460/60157............. Loss: 5.5265\n",
      "batch: 15480/60157............. Loss: 5.5265\n",
      "batch: 15500/60157............. Loss: 5.5189\n",
      "batch: 15520/60157............. Loss: 5.5292\n",
      "batch: 15540/60157............. Loss: 5.5272\n",
      "batch: 15560/60157............. Loss: 5.5260\n",
      "batch: 15580/60157............. Loss: 5.5268\n",
      "batch: 15600/60157............. Loss: 5.5274\n",
      "batch: 15620/60157............. Loss: 5.5225\n",
      "batch: 15640/60157............. Loss: 5.5247\n",
      "batch: 15660/60157............. Loss: 5.5286\n",
      "batch: 15680/60157............. Loss: 5.5238\n",
      "batch: 15700/60157............. Loss: 5.5265\n",
      "batch: 15720/60157............. Loss: 5.5243\n",
      "batch: 15740/60157............. Loss: 5.5161\n",
      "batch: 15760/60157............. Loss: 5.5221\n",
      "batch: 15780/60157............. Loss: 5.5230\n",
      "batch: 15800/60157............. Loss: 5.5236\n",
      "batch: 15820/60157............. Loss: 5.5219\n",
      "batch: 15840/60157............. Loss: 5.5252\n",
      "batch: 15860/60157............. Loss: 5.5252\n",
      "batch: 15880/60157............. Loss: 5.5282\n",
      "batch: 15900/60157............. Loss: 5.5249\n",
      "batch: 15920/60157............. Loss: 5.5252\n",
      "batch: 15940/60157............. Loss: 5.5234\n",
      "batch: 15960/60157............. Loss: 5.5220\n",
      "batch: 15980/60157............. Loss: 5.5257\n",
      "batch: 16000/60157............. Loss: 5.5265\n",
      "batch: 16020/60157............. Loss: 5.5260\n",
      "batch: 16040/60157............. Loss: 5.5187\n",
      "batch: 16060/60157............. Loss: 5.5233\n",
      "batch: 16080/60157............. Loss: 5.5285\n",
      "batch: 16100/60157............. Loss: 5.5211\n",
      "batch: 16120/60157............. Loss: 5.5222\n",
      "batch: 16140/60157............. Loss: 5.5226\n",
      "batch: 16160/60157............. Loss: 5.5226\n",
      "batch: 16180/60157............. Loss: 5.5181\n",
      "batch: 16200/60157............. Loss: 5.5195\n",
      "batch: 16220/60157............. Loss: 5.5262\n",
      "batch: 16240/60157............. Loss: 5.5224\n",
      "batch: 16260/60157............. Loss: 5.5258\n",
      "batch: 16280/60157............. Loss: 5.5171\n",
      "batch: 16300/60157............. Loss: 5.5232\n",
      "batch: 16320/60157............. Loss: 5.5222\n",
      "batch: 16340/60157............. Loss: 5.5257\n",
      "batch: 16360/60157............. Loss: 5.5233\n",
      "batch: 16380/60157............. Loss: 5.5194\n",
      "batch: 16400/60157............. Loss: 5.5215\n",
      "batch: 16420/60157............. Loss: 5.5211\n",
      "batch: 16440/60157............. Loss: 5.5241\n",
      "batch: 16460/60157............. Loss: 5.5204\n",
      "batch: 16480/60157............. Loss: 5.5225\n",
      "batch: 16500/60157............. Loss: 5.5229\n",
      "batch: 16520/60157............. Loss: 5.5243\n",
      "batch: 16540/60157............. Loss: 5.5281\n",
      "batch: 16560/60157............. Loss: 5.5237\n",
      "batch: 16580/60157............. Loss: 5.5222\n",
      "batch: 16600/60157............. Loss: 5.5265\n",
      "batch: 16620/60157............. Loss: 5.5254\n",
      "batch: 16640/60157............. Loss: 5.5261\n",
      "batch: 16660/60157............. Loss: 5.5191\n",
      "batch: 16680/60157............. Loss: 5.5232\n",
      "batch: 16700/60157............. Loss: 5.5275\n",
      "batch: 16720/60157............. Loss: 5.5301\n",
      "batch: 16740/60157............. Loss: 5.5249\n",
      "batch: 16760/60157............. Loss: 5.5256\n",
      "batch: 16780/60157............. Loss: 5.5265\n",
      "batch: 16800/60157............. Loss: 5.5257\n",
      "batch: 16820/60157............. Loss: 5.5227\n",
      "batch: 16840/60157............. Loss: 5.5226\n",
      "batch: 16860/60157............. Loss: 5.5214\n",
      "batch: 16880/60157............. Loss: 5.5217\n",
      "batch: 16900/60157............. Loss: 5.5238\n",
      "batch: 16920/60157............. Loss: 5.5210\n",
      "batch: 16940/60157............. Loss: 5.5271\n",
      "batch: 16960/60157............. Loss: 5.5253\n",
      "batch: 16980/60157............. Loss: 5.5139\n",
      "batch: 17000/60157............. Loss: 5.5264\n",
      "batch: 17020/60157............. Loss: 5.5245\n",
      "batch: 17040/60157............. Loss: 5.5323\n",
      "batch: 17060/60157............. Loss: 5.5251\n",
      "batch: 17080/60157............. Loss: 5.5242\n",
      "batch: 17100/60157............. Loss: 5.5208\n",
      "batch: 17120/60157............. Loss: 5.5205\n",
      "batch: 17140/60157............. Loss: 5.5191\n",
      "batch: 17160/60157............. Loss: 5.5275\n",
      "batch: 17180/60157............. Loss: 5.5279\n",
      "batch: 17200/60157............. Loss: 5.5224\n",
      "batch: 17220/60157............. Loss: 5.5253\n",
      "batch: 17240/60157............. Loss: 5.5215\n",
      "batch: 17260/60157............. Loss: 5.5278\n",
      "batch: 17280/60157............. Loss: 5.5256\n",
      "batch: 17300/60157............. Loss: 5.5277\n",
      "batch: 17320/60157............. Loss: 5.5250\n",
      "batch: 17340/60157............. Loss: 5.5223\n",
      "batch: 17360/60157............. Loss: 5.5279\n",
      "batch: 17380/60157............. Loss: 5.5281\n",
      "batch: 17400/60157............. Loss: 5.5274\n",
      "batch: 17420/60157............. Loss: 5.5218\n",
      "batch: 17440/60157............. Loss: 5.5202\n",
      "batch: 17460/60157............. Loss: 5.5184\n",
      "batch: 17480/60157............. Loss: 5.5229\n",
      "batch: 17500/60157............. Loss: 5.5236\n",
      "batch: 17520/60157............. Loss: 5.5220\n",
      "batch: 17540/60157............. Loss: 5.5290\n",
      "batch: 17560/60157............. Loss: 5.5230\n",
      "batch: 17580/60157............. Loss: 5.5242\n",
      "batch: 17600/60157............. Loss: 5.5270\n",
      "batch: 17620/60157............. Loss: 5.5235\n",
      "batch: 17640/60157............. Loss: 5.5244\n",
      "batch: 17660/60157............. Loss: 5.5226\n",
      "batch: 17680/60157............. Loss: 5.5195\n",
      "batch: 17700/60157............. Loss: 5.5255\n",
      "batch: 17720/60157............. Loss: 5.5220\n",
      "batch: 17740/60157............. Loss: 5.5241\n",
      "batch: 17760/60157............. Loss: 5.5238\n",
      "batch: 17780/60157............. Loss: 5.5246\n",
      "batch: 17800/60157............. Loss: 5.5216\n",
      "batch: 17820/60157............. Loss: 5.5203\n",
      "batch: 17840/60157............. Loss: 5.5200\n",
      "batch: 17860/60157............. Loss: 5.5235\n",
      "batch: 17880/60157............. Loss: 5.5178\n",
      "batch: 17900/60157............. Loss: 5.5242\n",
      "batch: 17920/60157............. Loss: 5.5285\n",
      "batch: 17940/60157............. Loss: 5.5273\n",
      "batch: 17960/60157............. Loss: 5.5234\n",
      "batch: 17980/60157............. Loss: 5.5265\n",
      "batch: 18000/60157............. Loss: 5.5262\n",
      "batch: 18020/60157............. Loss: 5.5286\n",
      "batch: 18040/60157............. Loss: 5.5205\n",
      "batch: 18060/60157............. Loss: 5.5252\n",
      "batch: 18080/60157............. Loss: 5.5246\n",
      "batch: 18100/60157............. Loss: 5.5181\n",
      "batch: 18120/60157............. Loss: 5.5233\n",
      "batch: 18140/60157............. Loss: 5.5221\n",
      "batch: 18160/60157............. Loss: 5.5223\n",
      "batch: 18180/60157............. Loss: 5.5225\n",
      "batch: 18200/60157............. Loss: 5.5278\n",
      "batch: 18220/60157............. Loss: 5.5262\n",
      "batch: 18240/60157............. Loss: 5.5245\n",
      "batch: 18260/60157............. Loss: 5.5257\n",
      "batch: 18280/60157............. Loss: 5.5230\n",
      "batch: 18300/60157............. Loss: 5.5273\n",
      "batch: 18320/60157............. Loss: 5.5259\n",
      "batch: 18340/60157............. Loss: 5.5241\n",
      "batch: 18360/60157............. Loss: 5.5204\n",
      "batch: 18380/60157............. Loss: 5.5204\n",
      "batch: 18400/60157............. Loss: 5.5244\n",
      "batch: 18420/60157............. Loss: 5.5241\n",
      "batch: 18440/60157............. Loss: 5.5267\n",
      "batch: 18460/60157............. Loss: 5.5252\n",
      "batch: 18480/60157............. Loss: 5.5241\n",
      "batch: 18500/60157............. Loss: 5.5266\n",
      "batch: 18520/60157............. Loss: 5.5253\n",
      "batch: 18540/60157............. Loss: 5.5224\n",
      "batch: 18560/60157............. Loss: 5.5192\n",
      "batch: 18580/60157............. Loss: 5.5240\n",
      "batch: 18600/60157............. Loss: 5.5225\n",
      "batch: 18620/60157............. Loss: 5.5221\n",
      "batch: 18640/60157............. Loss: 5.5247\n",
      "batch: 18660/60157............. Loss: 5.5251\n",
      "batch: 18680/60157............. Loss: 5.5186\n",
      "batch: 18700/60157............. Loss: 5.5267\n",
      "batch: 18720/60157............. Loss: 5.5217\n",
      "batch: 18740/60157............. Loss: 5.5266\n",
      "batch: 18760/60157............. Loss: 5.5231\n",
      "batch: 18780/60157............. Loss: 5.5149\n",
      "batch: 18800/60157............. Loss: 5.5192\n",
      "batch: 18820/60157............. Loss: 5.5226\n",
      "batch: 18840/60157............. Loss: 5.5265\n",
      "batch: 18860/60157............. Loss: 5.5272\n",
      "batch: 18880/60157............. Loss: 5.5249\n",
      "batch: 18900/60157............. Loss: 5.5206\n",
      "batch: 18920/60157............. Loss: 5.5190\n",
      "batch: 18940/60157............. Loss: 5.5260\n",
      "batch: 18960/60157............. Loss: 5.5246\n",
      "batch: 18980/60157............. Loss: 5.5217\n",
      "batch: 19000/60157............. Loss: 5.5219\n",
      "batch: 19020/60157............. Loss: 5.5245\n",
      "batch: 19040/60157............. Loss: 5.5256\n",
      "batch: 19060/60157............. Loss: 5.5253\n",
      "batch: 19080/60157............. Loss: 5.5287\n",
      "batch: 19100/60157............. Loss: 5.5258\n",
      "batch: 19120/60157............. Loss: 5.5294\n",
      "batch: 19140/60157............. Loss: 5.5250\n",
      "batch: 19160/60157............. Loss: 5.5243\n",
      "batch: 19180/60157............. Loss: 5.5192\n",
      "batch: 19200/60157............. Loss: 5.5258\n",
      "batch: 19220/60157............. Loss: 5.5204\n",
      "batch: 19240/60157............. Loss: 5.5233\n",
      "batch: 19260/60157............. Loss: 5.5231\n",
      "batch: 19280/60157............. Loss: 5.5214\n",
      "batch: 19300/60157............. Loss: 5.5214\n",
      "batch: 19320/60157............. Loss: 5.5206\n",
      "batch: 19340/60157............. Loss: 5.5280\n",
      "batch: 19360/60157............. Loss: 5.5250\n",
      "batch: 19380/60157............. Loss: 5.5238\n",
      "batch: 19400/60157............. Loss: 5.5269\n",
      "batch: 19420/60157............. Loss: 5.5242\n",
      "batch: 19440/60157............. Loss: 5.5216\n",
      "batch: 19460/60157............. Loss: 5.5239\n",
      "batch: 19480/60157............. Loss: 5.5275\n",
      "batch: 19500/60157............. Loss: 5.5238\n",
      "batch: 19520/60157............. Loss: 5.5231\n",
      "batch: 19540/60157............. Loss: 5.5217\n",
      "batch: 19560/60157............. Loss: 5.5279\n",
      "batch: 19580/60157............. Loss: 5.5239\n",
      "batch: 19600/60157............. Loss: 5.5253\n",
      "batch: 19620/60157............. Loss: 5.5244\n",
      "batch: 19640/60157............. Loss: 5.5210\n",
      "batch: 19660/60157............. Loss: 5.5247\n",
      "batch: 19680/60157............. Loss: 5.5262\n",
      "batch: 19700/60157............. Loss: 5.5187\n",
      "batch: 19720/60157............. Loss: 5.5241\n",
      "batch: 19740/60157............. Loss: 5.5270\n",
      "batch: 19760/60157............. Loss: 5.5207\n",
      "batch: 19780/60157............. Loss: 5.5137\n",
      "batch: 19800/60157............. Loss: 5.5196\n",
      "batch: 19820/60157............. Loss: 5.5288\n",
      "batch: 19840/60157............. Loss: 5.5211\n",
      "batch: 19860/60157............. Loss: 5.5279\n",
      "batch: 19880/60157............. Loss: 5.5259\n",
      "batch: 19900/60157............. Loss: 5.5264\n",
      "batch: 19920/60157............. Loss: 5.5218\n",
      "batch: 19940/60157............. Loss: 5.5271\n",
      "batch: 19960/60157............. Loss: 5.5284\n",
      "batch: 19980/60157............. Loss: 5.5265\n",
      "batch: 20000/60157............. Loss: 5.5273\n",
      "batch: 20020/60157............. Loss: 5.5261\n",
      "batch: 20040/60157............. Loss: 5.5241\n",
      "batch: 20060/60157............. Loss: 5.5241\n",
      "batch: 20080/60157............. Loss: 5.5213\n",
      "batch: 20100/60157............. Loss: 5.5254\n",
      "batch: 20120/60157............. Loss: 5.5255\n",
      "batch: 20140/60157............. Loss: 5.5248\n",
      "batch: 20160/60157............. Loss: 5.5228\n",
      "batch: 20180/60157............. Loss: 5.5247\n",
      "batch: 20200/60157............. Loss: 5.5310\n",
      "batch: 20220/60157............. Loss: 5.5253\n",
      "batch: 20240/60157............. Loss: 5.5195\n",
      "batch: 20260/60157............. Loss: 5.5213\n",
      "batch: 20280/60157............. Loss: 5.5278\n",
      "batch: 20300/60157............. Loss: 5.5228\n",
      "batch: 20320/60157............. Loss: 5.5290\n",
      "batch: 20340/60157............. Loss: 5.5238\n",
      "batch: 20360/60157............. Loss: 5.5220\n",
      "batch: 20380/60157............. Loss: 5.5260\n",
      "batch: 20400/60157............. Loss: 5.5227\n",
      "batch: 20420/60157............. Loss: 5.5255\n",
      "batch: 20440/60157............. Loss: 5.5234\n",
      "batch: 20460/60157............. Loss: 5.5313\n",
      "batch: 20480/60157............. Loss: 5.5250\n",
      "batch: 20500/60157............. Loss: 5.5247\n",
      "batch: 20520/60157............. Loss: 5.5218\n",
      "batch: 20540/60157............. Loss: 5.5233\n",
      "batch: 20560/60157............. Loss: 5.5226\n",
      "batch: 20580/60157............. Loss: 5.5283\n",
      "batch: 20600/60157............. Loss: 5.5218\n",
      "batch: 20620/60157............. Loss: 5.5245\n",
      "batch: 20640/60157............. Loss: 5.5242\n",
      "batch: 20660/60157............. Loss: 5.5317\n",
      "batch: 20680/60157............. Loss: 5.5310\n",
      "batch: 20700/60157............. Loss: 5.5262\n",
      "batch: 20720/60157............. Loss: 5.5190\n",
      "batch: 20740/60157............. Loss: 5.5221\n",
      "batch: 20760/60157............. Loss: 5.5278\n",
      "batch: 20780/60157............. Loss: 5.5256\n",
      "batch: 20800/60157............. Loss: 5.5264\n",
      "batch: 20820/60157............. Loss: 5.5261\n",
      "batch: 20840/60157............. Loss: 5.5290\n",
      "batch: 20860/60157............. Loss: 5.5192\n",
      "batch: 20880/60157............. Loss: 5.5258\n",
      "batch: 20900/60157............. Loss: 5.5264\n",
      "batch: 20920/60157............. Loss: 5.5254\n",
      "batch: 20940/60157............. Loss: 5.5272\n",
      "batch: 20960/60157............. Loss: 5.5286\n",
      "batch: 20980/60157............. Loss: 5.5271\n",
      "batch: 21000/60157............. Loss: 5.5237\n",
      "batch: 21020/60157............. Loss: 5.5259\n",
      "batch: 21040/60157............. Loss: 5.5323\n",
      "batch: 21060/60157............. Loss: 5.5229\n",
      "batch: 21080/60157............. Loss: 5.5280\n",
      "batch: 21100/60157............. Loss: 5.5330\n",
      "batch: 21120/60157............. Loss: 5.5253\n",
      "batch: 21140/60157............. Loss: 5.5280\n",
      "batch: 21160/60157............. Loss: 5.5254\n",
      "batch: 21180/60157............. Loss: 5.5260\n",
      "batch: 21200/60157............. Loss: 5.5254\n",
      "batch: 21220/60157............. Loss: 5.5242\n",
      "batch: 21240/60157............. Loss: 5.5272\n",
      "batch: 21260/60157............. Loss: 5.5239\n",
      "batch: 21280/60157............. Loss: 5.5241\n",
      "batch: 21300/60157............. Loss: 5.5207\n",
      "batch: 21320/60157............. Loss: 5.5285\n",
      "batch: 21340/60157............. Loss: 5.5263\n",
      "batch: 21360/60157............. Loss: 5.5236\n",
      "batch: 21380/60157............. Loss: 5.5277\n",
      "batch: 21400/60157............. Loss: 5.5201\n",
      "batch: 21420/60157............. Loss: 5.5223\n",
      "batch: 21440/60157............. Loss: 5.5167\n",
      "batch: 21460/60157............. Loss: 5.5147\n",
      "batch: 21480/60157............. Loss: 5.5274\n",
      "batch: 21500/60157............. Loss: 5.5270\n",
      "batch: 21520/60157............. Loss: 5.5241\n",
      "batch: 21540/60157............. Loss: 5.5252\n",
      "batch: 21560/60157............. Loss: 5.5164\n",
      "batch: 21580/60157............. Loss: 5.5218\n",
      "batch: 21600/60157............. Loss: 5.5242\n",
      "batch: 21620/60157............. Loss: 5.5228\n",
      "batch: 21640/60157............. Loss: 5.5200\n",
      "batch: 21660/60157............. Loss: 5.5277\n",
      "batch: 21680/60157............. Loss: 5.5239\n",
      "batch: 21700/60157............. Loss: 5.5256\n",
      "batch: 21720/60157............. Loss: 5.5298\n",
      "batch: 21740/60157............. Loss: 5.5208\n",
      "batch: 21760/60157............. Loss: 5.5312\n",
      "batch: 21780/60157............. Loss: 5.5240\n",
      "batch: 21800/60157............. Loss: 5.5246\n",
      "batch: 21820/60157............. Loss: 5.5242\n",
      "batch: 21840/60157............. Loss: 5.5239\n",
      "batch: 21860/60157............. Loss: 5.5289\n",
      "batch: 21880/60157............. Loss: 5.5250\n",
      "batch: 21900/60157............. Loss: 5.5263\n",
      "batch: 21920/60157............. Loss: 5.5260\n",
      "batch: 21940/60157............. Loss: 5.5171\n",
      "batch: 21960/60157............. Loss: 5.5226\n",
      "batch: 21980/60157............. Loss: 5.5252\n",
      "batch: 22000/60157............. Loss: 5.5287\n",
      "batch: 22020/60157............. Loss: 5.5252\n",
      "batch: 22040/60157............. Loss: 5.5252\n",
      "batch: 22060/60157............. Loss: 5.5320\n",
      "batch: 22080/60157............. Loss: 5.5294\n",
      "batch: 22100/60157............. Loss: 5.5286\n",
      "batch: 22120/60157............. Loss: 5.5302\n",
      "batch: 22140/60157............. Loss: 5.5297\n",
      "batch: 22160/60157............. Loss: 5.5267\n",
      "batch: 22180/60157............. Loss: 5.5302\n",
      "batch: 22200/60157............. Loss: 5.5301\n",
      "batch: 22220/60157............. Loss: 5.5266\n",
      "batch: 22240/60157............. Loss: 5.5282\n",
      "batch: 22260/60157............. Loss: 5.5325\n",
      "batch: 22280/60157............. Loss: 5.5277\n",
      "batch: 22300/60157............. Loss: 5.5307\n",
      "batch: 22320/60157............. Loss: 5.5247\n",
      "batch: 22340/60157............. Loss: 5.5253\n",
      "batch: 22360/60157............. Loss: 5.5261\n",
      "batch: 22380/60157............. Loss: 5.5293\n",
      "batch: 22400/60157............. Loss: 5.5257\n",
      "batch: 22420/60157............. Loss: 5.5243\n",
      "batch: 22440/60157............. Loss: 5.5261\n",
      "batch: 22460/60157............. Loss: 5.5265\n",
      "batch: 22480/60157............. Loss: 5.5227\n",
      "batch: 22500/60157............. Loss: 5.5245\n",
      "batch: 22520/60157............. Loss: 5.5243\n",
      "batch: 22540/60157............. Loss: 5.5259\n",
      "batch: 22560/60157............. Loss: 5.5265\n",
      "batch: 22580/60157............. Loss: 5.5307\n",
      "batch: 22600/60157............. Loss: 5.5213\n",
      "batch: 22620/60157............. Loss: 5.5232\n",
      "batch: 22640/60157............. Loss: 5.5267\n",
      "batch: 22660/60157............. Loss: 5.5252\n",
      "batch: 22680/60157............. Loss: 5.5247\n",
      "batch: 22700/60157............. Loss: 5.5291\n",
      "batch: 22720/60157............. Loss: 5.5259\n",
      "batch: 22740/60157............. Loss: 5.5262\n",
      "batch: 22760/60157............. Loss: 5.5212\n",
      "batch: 22780/60157............. Loss: 5.5262\n",
      "batch: 22800/60157............. Loss: 5.5257\n",
      "batch: 22820/60157............. Loss: 5.5268\n",
      "batch: 22840/60157............. Loss: 5.5266\n",
      "batch: 22860/60157............. Loss: 5.5222\n",
      "batch: 22880/60157............. Loss: 5.5224\n",
      "batch: 22900/60157............. Loss: 5.5210\n",
      "batch: 22920/60157............. Loss: 5.5260\n",
      "batch: 22940/60157............. Loss: 5.5276\n",
      "batch: 22960/60157............. Loss: 5.5263\n",
      "batch: 22980/60157............. Loss: 5.5241\n",
      "batch: 23000/60157............. Loss: 5.5322\n",
      "batch: 23020/60157............. Loss: 5.5242\n",
      "batch: 23040/60157............. Loss: 5.5246\n",
      "batch: 23060/60157............. Loss: 5.5255\n",
      "batch: 23080/60157............. Loss: 5.5256\n",
      "batch: 23100/60157............. Loss: 5.5210\n",
      "batch: 23120/60157............. Loss: 5.5224\n",
      "batch: 23140/60157............. Loss: 5.5259\n",
      "batch: 23160/60157............. Loss: 5.5254\n",
      "batch: 23180/60157............. Loss: 5.5256\n",
      "batch: 23200/60157............. Loss: 5.5236\n",
      "batch: 23220/60157............. Loss: 5.5288\n",
      "batch: 23240/60157............. Loss: 5.5253\n",
      "batch: 23260/60157............. Loss: 5.5246\n",
      "batch: 23280/60157............. Loss: 5.5234\n",
      "batch: 23300/60157............. Loss: 5.5272\n",
      "batch: 23320/60157............. Loss: 5.5288\n",
      "batch: 23340/60157............. Loss: 5.5251\n",
      "batch: 23360/60157............. Loss: 5.5257\n",
      "batch: 23380/60157............. Loss: 5.5293\n",
      "batch: 23400/60157............. Loss: 5.5272\n",
      "batch: 23420/60157............. Loss: 5.5245\n",
      "batch: 23440/60157............. Loss: 5.5239\n",
      "batch: 23460/60157............. Loss: 5.5278\n",
      "batch: 23480/60157............. Loss: 5.5258\n",
      "batch: 23500/60157............. Loss: 5.5270\n",
      "batch: 23520/60157............. Loss: 5.5268\n",
      "batch: 23540/60157............. Loss: 5.5256\n",
      "batch: 23560/60157............. Loss: 5.5224\n",
      "batch: 23580/60157............. Loss: 5.5215\n",
      "batch: 23600/60157............. Loss: 5.5263\n",
      "batch: 23620/60157............. Loss: 5.5252\n",
      "batch: 23640/60157............. Loss: 5.5267\n",
      "batch: 23660/60157............. Loss: 5.5252\n",
      "batch: 23680/60157............. Loss: 5.5267\n",
      "batch: 23700/60157............. Loss: 5.5277\n",
      "batch: 23720/60157............. Loss: 5.5270\n",
      "batch: 23740/60157............. Loss: 5.5242\n",
      "batch: 23760/60157............. Loss: 5.5231\n",
      "batch: 23780/60157............. Loss: 5.5276\n",
      "batch: 23800/60157............. Loss: 5.5269\n",
      "batch: 23820/60157............. Loss: 5.5216\n",
      "batch: 23840/60157............. Loss: 5.5253\n",
      "batch: 23860/60157............. Loss: 5.5254\n",
      "batch: 23880/60157............. Loss: 5.5288\n",
      "batch: 23900/60157............. Loss: 5.5262\n",
      "batch: 23920/60157............. Loss: 5.5266\n",
      "batch: 23940/60157............. Loss: 5.5214\n",
      "batch: 23960/60157............. Loss: 5.5281\n",
      "batch: 23980/60157............. Loss: 5.5212\n",
      "batch: 24000/60157............. Loss: 5.5231\n",
      "batch: 24020/60157............. Loss: 5.5291\n",
      "batch: 24040/60157............. Loss: 5.5282\n",
      "batch: 24060/60157............. Loss: 5.5244\n",
      "batch: 24080/60157............. Loss: 5.5171\n",
      "batch: 24100/60157............. Loss: 5.5220\n",
      "batch: 24120/60157............. Loss: 5.5246\n",
      "batch: 24140/60157............. Loss: 5.5224\n",
      "batch: 24160/60157............. Loss: 5.5213\n",
      "batch: 24180/60157............. Loss: 5.5254\n",
      "batch: 24200/60157............. Loss: 5.5285\n",
      "batch: 24220/60157............. Loss: 5.5248\n",
      "batch: 24240/60157............. Loss: 5.5252\n",
      "batch: 24260/60157............. Loss: 5.5238\n",
      "batch: 24280/60157............. Loss: 5.5270\n",
      "batch: 24300/60157............. Loss: 5.5255\n",
      "batch: 24320/60157............. Loss: 5.5262\n",
      "batch: 24340/60157............. Loss: 5.5259\n",
      "batch: 24360/60157............. Loss: 5.5255\n",
      "batch: 24380/60157............. Loss: 5.5255\n",
      "batch: 24400/60157............. Loss: 5.5242\n",
      "batch: 24420/60157............. Loss: 5.5276\n",
      "batch: 24440/60157............. Loss: 5.5206\n",
      "batch: 24460/60157............. Loss: 5.5246\n",
      "batch: 24480/60157............. Loss: 5.5270\n",
      "batch: 24500/60157............. Loss: 5.5324\n",
      "batch: 24520/60157............. Loss: 5.5260\n",
      "batch: 24540/60157............. Loss: 5.5289\n",
      "batch: 24560/60157............. Loss: 5.5233\n",
      "batch: 24580/60157............. Loss: 5.5224\n",
      "batch: 24600/60157............. Loss: 5.5244\n",
      "batch: 24620/60157............. Loss: 5.5238\n",
      "batch: 24640/60157............. Loss: 5.5243\n",
      "batch: 24660/60157............. Loss: 5.5247\n",
      "batch: 24680/60157............. Loss: 5.5245\n",
      "batch: 24700/60157............. Loss: 5.5244\n",
      "batch: 24720/60157............. Loss: 5.5238\n",
      "batch: 24740/60157............. Loss: 5.5207\n",
      "batch: 24760/60157............. Loss: 5.5253\n",
      "batch: 24780/60157............. Loss: 5.5257\n",
      "batch: 24800/60157............. Loss: 5.5231\n",
      "batch: 24820/60157............. Loss: 5.5207\n",
      "batch: 24840/60157............. Loss: 5.5236\n",
      "batch: 24860/60157............. Loss: 5.5245\n",
      "batch: 24880/60157............. Loss: 5.5260\n",
      "batch: 24900/60157............. Loss: 5.5223\n",
      "batch: 24920/60157............. Loss: 5.5218\n",
      "batch: 24940/60157............. Loss: 5.5313\n",
      "batch: 24960/60157............. Loss: 5.5178\n",
      "batch: 24980/60157............. Loss: 5.5222\n",
      "batch: 25000/60157............. Loss: 5.5271\n",
      "batch: 25020/60157............. Loss: 5.5242\n",
      "batch: 25040/60157............. Loss: 5.5221\n",
      "batch: 25060/60157............. Loss: 5.5207\n",
      "batch: 25080/60157............. Loss: 5.5251\n",
      "batch: 25100/60157............. Loss: 5.5238\n",
      "batch: 25120/60157............. Loss: 5.5189\n",
      "batch: 25140/60157............. Loss: 5.5237\n",
      "batch: 25160/60157............. Loss: 5.5202\n",
      "batch: 25180/60157............. Loss: 5.5276\n",
      "batch: 25200/60157............. Loss: 5.5265\n",
      "batch: 25220/60157............. Loss: 5.5245\n",
      "batch: 25240/60157............. Loss: 5.5253\n",
      "batch: 25260/60157............. Loss: 5.5246\n",
      "batch: 25280/60157............. Loss: 5.5303\n",
      "batch: 25300/60157............. Loss: 5.5278\n",
      "batch: 25320/60157............. Loss: 5.5260\n",
      "batch: 25340/60157............. Loss: 5.5267\n",
      "batch: 25360/60157............. Loss: 5.5254\n",
      "batch: 25380/60157............. Loss: 5.5229\n",
      "batch: 25400/60157............. Loss: 5.5272\n",
      "batch: 25420/60157............. Loss: 5.5223\n",
      "batch: 25440/60157............. Loss: 5.5260\n",
      "batch: 25460/60157............. Loss: 5.5215\n",
      "batch: 25480/60157............. Loss: 5.5247\n",
      "batch: 25500/60157............. Loss: 5.5223\n",
      "batch: 25520/60157............. Loss: 5.5202\n",
      "batch: 25540/60157............. Loss: 5.5275\n",
      "batch: 25560/60157............. Loss: 5.5252\n",
      "batch: 25580/60157............. Loss: 5.5256\n",
      "batch: 25600/60157............. Loss: 5.5258\n",
      "batch: 25620/60157............. Loss: 5.5262\n",
      "batch: 25640/60157............. Loss: 5.5242\n",
      "batch: 25660/60157............. Loss: 5.5250\n",
      "batch: 25680/60157............. Loss: 5.5233\n",
      "batch: 25700/60157............. Loss: 5.5289\n",
      "batch: 25720/60157............. Loss: 5.5240\n",
      "batch: 25740/60157............. Loss: 5.5237\n",
      "batch: 25760/60157............. Loss: 5.5314\n",
      "batch: 25780/60157............. Loss: 5.5261\n",
      "batch: 25800/60157............. Loss: 5.5250\n",
      "batch: 25820/60157............. Loss: 5.5181\n",
      "batch: 25840/60157............. Loss: 5.5247\n",
      "batch: 25860/60157............. Loss: 5.5205\n",
      "batch: 25880/60157............. Loss: 5.5292\n",
      "batch: 25900/60157............. Loss: 5.5239\n",
      "batch: 25920/60157............. Loss: 5.5302\n",
      "batch: 25940/60157............. Loss: 5.5256\n",
      "batch: 25960/60157............. Loss: 5.5286\n",
      "batch: 25980/60157............. Loss: 5.5216\n",
      "batch: 26000/60157............. Loss: 5.5260\n",
      "batch: 26020/60157............. Loss: 5.5259\n",
      "batch: 26040/60157............. Loss: 5.5282\n",
      "batch: 26060/60157............. Loss: 5.5277\n",
      "batch: 26080/60157............. Loss: 5.5245\n",
      "batch: 26100/60157............. Loss: 5.5270\n",
      "batch: 26120/60157............. Loss: 5.5266\n",
      "batch: 26140/60157............. Loss: 5.5269\n",
      "batch: 26160/60157............. Loss: 5.5236\n",
      "batch: 26180/60157............. Loss: 5.5241\n",
      "batch: 26200/60157............. Loss: 5.5243\n",
      "batch: 26220/60157............. Loss: 5.5330\n",
      "batch: 26240/60157............. Loss: 5.5247\n",
      "batch: 26260/60157............. Loss: 5.5302\n",
      "batch: 26280/60157............. Loss: 5.5277\n",
      "batch: 26300/60157............. Loss: 5.5253\n",
      "batch: 26320/60157............. Loss: 5.5272\n",
      "batch: 26340/60157............. Loss: 5.5267\n",
      "batch: 26360/60157............. Loss: 5.5260\n",
      "batch: 26380/60157............. Loss: 5.5265\n",
      "batch: 26400/60157............. Loss: 5.5284\n",
      "batch: 26420/60157............. Loss: 5.5269\n",
      "batch: 26440/60157............. Loss: 5.5269\n",
      "batch: 26460/60157............. Loss: 5.5243\n",
      "batch: 26480/60157............. Loss: 5.5257\n",
      "batch: 26500/60157............. Loss: 5.5199\n",
      "batch: 26520/60157............. Loss: 5.5265\n",
      "batch: 26540/60157............. Loss: 5.5298\n",
      "batch: 26560/60157............. Loss: 5.5231\n",
      "batch: 26580/60157............. Loss: 5.5296\n",
      "batch: 26600/60157............. Loss: 5.5257\n",
      "batch: 26620/60157............. Loss: 5.5279\n",
      "batch: 26640/60157............. Loss: 5.5263\n",
      "batch: 26660/60157............. Loss: 5.5281\n",
      "batch: 26680/60157............. Loss: 5.5276\n",
      "batch: 26700/60157............. Loss: 5.5222\n",
      "batch: 26720/60157............. Loss: 5.5225\n",
      "batch: 26740/60157............. Loss: 5.5289\n",
      "batch: 26760/60157............. Loss: 5.5266\n",
      "batch: 26780/60157............. Loss: 5.5285\n",
      "batch: 26800/60157............. Loss: 5.5233\n",
      "batch: 26820/60157............. Loss: 5.5247\n",
      "batch: 26840/60157............. Loss: 5.5189\n",
      "batch: 26860/60157............. Loss: 5.5300\n",
      "batch: 26880/60157............. Loss: 5.5231\n",
      "batch: 26900/60157............. Loss: 5.5290\n",
      "batch: 26920/60157............. Loss: 5.5255\n",
      "batch: 26940/60157............. Loss: 5.5238\n",
      "batch: 26960/60157............. Loss: 5.5230\n",
      "batch: 26980/60157............. Loss: 5.5244\n",
      "batch: 27000/60157............. Loss: 5.5247\n",
      "batch: 27020/60157............. Loss: 5.5286\n",
      "batch: 27040/60157............. Loss: 5.5259\n",
      "batch: 27060/60157............. Loss: 5.5248\n",
      "batch: 27080/60157............. Loss: 5.5260\n",
      "batch: 27100/60157............. Loss: 5.5241\n",
      "batch: 27120/60157............. Loss: 5.5276\n",
      "batch: 27140/60157............. Loss: 5.5213\n",
      "batch: 27160/60157............. Loss: 5.5255\n",
      "batch: 27180/60157............. Loss: 5.5205\n",
      "batch: 27200/60157............. Loss: 5.5260\n",
      "batch: 27220/60157............. Loss: 5.5248\n",
      "batch: 27240/60157............. Loss: 5.5235\n",
      "batch: 27260/60157............. Loss: 5.5240\n",
      "batch: 27280/60157............. Loss: 5.5195\n",
      "batch: 27300/60157............. Loss: 5.5233\n",
      "batch: 27320/60157............. Loss: 5.5289\n",
      "batch: 27340/60157............. Loss: 5.5235\n",
      "batch: 27360/60157............. Loss: 5.5262\n",
      "batch: 27380/60157............. Loss: 5.5221\n",
      "batch: 27400/60157............. Loss: 5.5248\n",
      "batch: 27420/60157............. Loss: 5.5254\n",
      "batch: 27440/60157............. Loss: 5.5266\n",
      "batch: 27460/60157............. Loss: 5.5259\n",
      "batch: 27480/60157............. Loss: 5.5247\n",
      "batch: 27500/60157............. Loss: 5.5258\n",
      "batch: 27520/60157............. Loss: 5.5226\n",
      "batch: 27540/60157............. Loss: 5.5260\n",
      "batch: 27560/60157............. Loss: 5.5253\n",
      "batch: 27580/60157............. Loss: 5.5191\n",
      "batch: 27600/60157............. Loss: 5.5271\n",
      "batch: 27620/60157............. Loss: 5.5219\n",
      "batch: 27640/60157............. Loss: 5.5227\n",
      "batch: 27660/60157............. Loss: 5.5255\n",
      "batch: 27680/60157............. Loss: 5.5222\n",
      "batch: 27700/60157............. Loss: 5.5246\n",
      "batch: 27720/60157............. Loss: 5.5198\n",
      "batch: 27740/60157............. Loss: 5.5300\n",
      "batch: 27760/60157............. Loss: 5.5252\n",
      "batch: 27780/60157............. Loss: 5.5246\n",
      "batch: 27800/60157............. Loss: 5.5219\n",
      "batch: 27820/60157............. Loss: 5.5310\n",
      "batch: 27840/60157............. Loss: 5.5280\n",
      "batch: 27860/60157............. Loss: 5.5271\n",
      "batch: 27880/60157............. Loss: 5.5228\n",
      "batch: 27900/60157............. Loss: 5.5295\n",
      "batch: 27920/60157............. Loss: 5.5301\n",
      "batch: 27940/60157............. Loss: 5.5241\n",
      "batch: 27960/60157............. Loss: 5.5289\n",
      "batch: 27980/60157............. Loss: 5.5268\n",
      "batch: 28000/60157............. Loss: 5.5291\n",
      "batch: 28020/60157............. Loss: 5.5221\n",
      "batch: 28040/60157............. Loss: 5.5267\n",
      "batch: 28060/60157............. Loss: 5.5248\n",
      "batch: 28080/60157............. Loss: 5.5292\n",
      "batch: 28100/60157............. Loss: 5.5232\n",
      "batch: 28120/60157............. Loss: 5.5223\n",
      "batch: 28140/60157............. Loss: 5.5285\n",
      "batch: 28160/60157............. Loss: 5.5216\n",
      "batch: 28180/60157............. Loss: 5.5267\n",
      "batch: 28200/60157............. Loss: 5.5255\n",
      "batch: 28220/60157............. Loss: 5.5233\n",
      "batch: 28240/60157............. Loss: 5.5251\n",
      "batch: 28260/60157............. Loss: 5.5266\n",
      "batch: 28280/60157............. Loss: 5.5273\n",
      "batch: 28300/60157............. Loss: 5.5249\n",
      "batch: 28320/60157............. Loss: 5.5233\n",
      "batch: 28340/60157............. Loss: 5.5263\n",
      "batch: 28360/60157............. Loss: 5.5264\n",
      "batch: 28380/60157............. Loss: 5.5271\n",
      "batch: 28400/60157............. Loss: 5.5273\n",
      "batch: 28420/60157............. Loss: 5.5290\n",
      "batch: 28440/60157............. Loss: 5.5248\n",
      "batch: 28460/60157............. Loss: 5.5299\n",
      "batch: 28480/60157............. Loss: 5.5259\n",
      "batch: 28500/60157............. Loss: 5.5246\n",
      "batch: 28520/60157............. Loss: 5.5268\n",
      "batch: 28540/60157............. Loss: 5.5244\n",
      "batch: 28560/60157............. Loss: 5.5290\n",
      "batch: 28580/60157............. Loss: 5.5233\n",
      "batch: 28600/60157............. Loss: 5.5272\n",
      "batch: 28620/60157............. Loss: 5.5225\n",
      "batch: 28640/60157............. Loss: 5.5238\n",
      "batch: 28660/60157............. Loss: 5.5264\n",
      "batch: 28680/60157............. Loss: 5.5281\n",
      "batch: 28700/60157............. Loss: 5.5264\n",
      "batch: 28720/60157............. Loss: 5.5235\n",
      "batch: 28740/60157............. Loss: 5.5279\n",
      "batch: 28760/60157............. Loss: 5.5237\n",
      "batch: 28780/60157............. Loss: 5.5270\n",
      "batch: 28800/60157............. Loss: 5.5262\n",
      "batch: 28820/60157............. Loss: 5.5303\n",
      "batch: 28840/60157............. Loss: 5.5225\n",
      "batch: 28860/60157............. Loss: 5.5169\n",
      "batch: 28880/60157............. Loss: 5.5261\n",
      "batch: 28900/60157............. Loss: 5.5294\n",
      "batch: 28920/60157............. Loss: 5.5247\n",
      "batch: 28940/60157............. Loss: 5.5276\n",
      "batch: 28960/60157............. Loss: 5.5242\n",
      "batch: 28980/60157............. Loss: 5.5290\n",
      "batch: 29000/60157............. Loss: 5.5229\n",
      "batch: 29020/60157............. Loss: 5.5295\n",
      "batch: 29040/60157............. Loss: 5.5238\n",
      "batch: 29060/60157............. Loss: 5.5301\n",
      "batch: 29080/60157............. Loss: 5.5245\n",
      "batch: 29100/60157............. Loss: 5.5227\n",
      "batch: 29120/60157............. Loss: 5.5276\n",
      "batch: 29140/60157............. Loss: 5.5232\n",
      "batch: 29160/60157............. Loss: 5.5256\n",
      "batch: 29180/60157............. Loss: 5.5273\n",
      "batch: 29200/60157............. Loss: 5.5192\n",
      "batch: 29220/60157............. Loss: 5.5234\n",
      "batch: 29240/60157............. Loss: 5.5257\n",
      "batch: 29260/60157............. Loss: 5.5250\n",
      "batch: 29280/60157............. Loss: 5.5210\n",
      "batch: 29300/60157............. Loss: 5.5262\n",
      "batch: 29320/60157............. Loss: 5.5299\n",
      "batch: 29340/60157............. Loss: 5.5259\n",
      "batch: 29360/60157............. Loss: 5.5357\n",
      "batch: 29380/60157............. Loss: 5.5303\n",
      "batch: 29400/60157............. Loss: 5.5273\n",
      "batch: 29420/60157............. Loss: 5.5266\n",
      "batch: 29440/60157............. Loss: 5.5240\n",
      "batch: 29460/60157............. Loss: 5.5275\n",
      "batch: 29480/60157............. Loss: 5.5261\n",
      "batch: 29500/60157............. Loss: 5.5281\n",
      "batch: 29520/60157............. Loss: 5.5251\n",
      "batch: 29540/60157............. Loss: 5.5245\n",
      "batch: 29560/60157............. Loss: 5.5265\n",
      "batch: 29580/60157............. Loss: 5.5259\n",
      "batch: 29600/60157............. Loss: 5.5244\n",
      "batch: 29620/60157............. Loss: 5.5264\n",
      "batch: 29640/60157............. Loss: 5.5264\n",
      "batch: 29660/60157............. Loss: 5.5221\n",
      "batch: 29680/60157............. Loss: 5.5249\n",
      "batch: 29700/60157............. Loss: 5.5282\n",
      "batch: 29720/60157............. Loss: 5.5313\n",
      "batch: 29740/60157............. Loss: 5.5280\n",
      "batch: 29760/60157............. Loss: 5.5269\n",
      "batch: 29780/60157............. Loss: 5.5253\n",
      "batch: 29800/60157............. Loss: 5.5266\n",
      "batch: 29820/60157............. Loss: 5.5305\n",
      "batch: 29840/60157............. Loss: 5.5260\n",
      "batch: 29860/60157............. Loss: 5.5250\n",
      "batch: 29880/60157............. Loss: 5.5203\n",
      "batch: 29900/60157............. Loss: 5.5267\n",
      "batch: 29920/60157............. Loss: 5.5280\n",
      "batch: 29940/60157............. Loss: 5.5247\n",
      "batch: 29960/60157............. Loss: 5.5242\n",
      "batch: 29980/60157............. Loss: 5.5253\n",
      "batch: 30000/60157............. Loss: 5.5239\n",
      "batch: 30020/60157............. Loss: 5.5234\n",
      "batch: 30040/60157............. Loss: 5.5294\n",
      "batch: 30060/60157............. Loss: 5.5286\n",
      "batch: 30080/60157............. Loss: 5.5194\n",
      "batch: 30100/60157............. Loss: 5.5274\n",
      "batch: 30120/60157............. Loss: 5.5235\n",
      "batch: 30140/60157............. Loss: 5.5279\n",
      "batch: 30160/60157............. Loss: 5.5248\n",
      "batch: 30180/60157............. Loss: 5.5249\n",
      "batch: 30200/60157............. Loss: 5.5269\n",
      "batch: 30220/60157............. Loss: 5.5234\n",
      "batch: 30240/60157............. Loss: 5.5229\n",
      "batch: 30260/60157............. Loss: 5.5265\n",
      "batch: 30280/60157............. Loss: 5.5243\n",
      "batch: 30300/60157............. Loss: 5.5209\n",
      "batch: 30320/60157............. Loss: 5.5268\n",
      "batch: 30340/60157............. Loss: 5.5266\n",
      "batch: 30360/60157............. Loss: 5.5272\n",
      "batch: 30380/60157............. Loss: 5.5268\n",
      "batch: 30400/60157............. Loss: 5.5285\n",
      "batch: 30420/60157............. Loss: 5.5246\n",
      "batch: 30440/60157............. Loss: 5.5201\n",
      "batch: 30460/60157............. Loss: 5.5271\n",
      "batch: 30480/60157............. Loss: 5.5264\n",
      "batch: 30500/60157............. Loss: 5.5265\n",
      "batch: 30520/60157............. Loss: 5.5277\n",
      "batch: 30540/60157............. Loss: 5.5231\n",
      "batch: 30560/60157............. Loss: 5.5257\n",
      "batch: 30580/60157............. Loss: 5.5258\n",
      "batch: 30600/60157............. Loss: 5.5249\n",
      "batch: 30620/60157............. Loss: 5.5258\n",
      "batch: 30640/60157............. Loss: 5.5223\n",
      "batch: 30660/60157............. Loss: 5.5223\n",
      "batch: 30680/60157............. Loss: 5.5268\n",
      "batch: 30700/60157............. Loss: 5.5317\n",
      "batch: 30720/60157............. Loss: 5.5208\n",
      "batch: 30740/60157............. Loss: 5.5292\n",
      "batch: 30760/60157............. Loss: 5.5283\n",
      "batch: 30780/60157............. Loss: 5.5245\n",
      "batch: 30800/60157............. Loss: 5.5208\n",
      "batch: 30820/60157............. Loss: 5.5253\n",
      "batch: 30840/60157............. Loss: 5.5277\n",
      "batch: 30860/60157............. Loss: 5.5294\n",
      "batch: 30880/60157............. Loss: 5.5238\n",
      "batch: 30900/60157............. Loss: 5.5214\n",
      "batch: 30920/60157............. Loss: 5.5193\n",
      "batch: 30940/60157............. Loss: 5.5227\n",
      "batch: 30960/60157............. Loss: 5.5264\n",
      "batch: 30980/60157............. Loss: 5.5266\n",
      "batch: 31000/60157............. Loss: 5.5235\n",
      "batch: 31020/60157............. Loss: 5.5273\n",
      "batch: 31040/60157............. Loss: 5.5266\n",
      "batch: 31060/60157............. Loss: 5.5274\n",
      "batch: 31080/60157............. Loss: 5.5259\n",
      "batch: 31100/60157............. Loss: 5.5260\n",
      "batch: 31120/60157............. Loss: 5.5289\n",
      "batch: 31140/60157............. Loss: 5.5243\n",
      "batch: 31160/60157............. Loss: 5.5301\n",
      "batch: 31180/60157............. Loss: 5.5243\n",
      "batch: 31200/60157............. Loss: 5.5270\n",
      "batch: 31220/60157............. Loss: 5.5265\n",
      "batch: 31240/60157............. Loss: 5.5238\n",
      "batch: 31260/60157............. Loss: 5.5256\n",
      "batch: 31280/60157............. Loss: 5.5209\n",
      "batch: 31300/60157............. Loss: 5.5295\n",
      "batch: 31320/60157............. Loss: 5.5229\n",
      "batch: 31340/60157............. Loss: 5.5275\n",
      "batch: 31360/60157............. Loss: 5.5236\n",
      "batch: 31380/60157............. Loss: 5.5317\n",
      "batch: 31400/60157............. Loss: 5.5253\n",
      "batch: 31420/60157............. Loss: 5.5254\n",
      "batch: 31440/60157............. Loss: 5.5269\n",
      "batch: 31460/60157............. Loss: 5.5259\n",
      "batch: 31480/60157............. Loss: 5.5206\n",
      "batch: 31500/60157............. Loss: 5.5270\n",
      "batch: 31520/60157............. Loss: 5.5273\n",
      "batch: 31540/60157............. Loss: 5.5276\n",
      "batch: 31560/60157............. Loss: 5.5256\n",
      "batch: 31580/60157............. Loss: 5.5275\n",
      "batch: 31600/60157............. Loss: 5.5266\n",
      "batch: 31620/60157............. Loss: 5.5265\n",
      "batch: 31640/60157............. Loss: 5.5257\n",
      "batch: 31660/60157............. Loss: 5.5228\n",
      "batch: 31680/60157............. Loss: 5.5288\n",
      "batch: 31700/60157............. Loss: 5.5215\n",
      "batch: 31720/60157............. Loss: 5.5246\n",
      "batch: 31740/60157............. Loss: 5.5283\n",
      "batch: 31760/60157............. Loss: 5.5272\n",
      "batch: 31780/60157............. Loss: 5.5288\n",
      "batch: 31800/60157............. Loss: 5.5245\n",
      "batch: 31820/60157............. Loss: 5.5243\n",
      "batch: 31840/60157............. Loss: 5.5265\n",
      "batch: 31860/60157............. Loss: 5.5220\n",
      "batch: 31880/60157............. Loss: 5.5247\n",
      "batch: 31900/60157............. Loss: 5.5208\n",
      "batch: 31920/60157............. Loss: 5.5278\n",
      "batch: 31940/60157............. Loss: 5.5293\n",
      "batch: 31960/60157............. Loss: 5.5264\n",
      "batch: 31980/60157............. Loss: 5.5250\n",
      "batch: 32000/60157............. Loss: 5.5273\n",
      "batch: 32020/60157............. Loss: 5.5255\n",
      "batch: 32040/60157............. Loss: 5.5255\n",
      "batch: 32060/60157............. Loss: 5.5327\n",
      "batch: 32080/60157............. Loss: 5.5267\n",
      "batch: 32100/60157............. Loss: 5.5309\n",
      "batch: 32120/60157............. Loss: 5.5270\n",
      "batch: 32140/60157............. Loss: 5.5299\n",
      "batch: 32160/60157............. Loss: 5.5245\n",
      "batch: 32180/60157............. Loss: 5.5237\n",
      "batch: 32200/60157............. Loss: 5.5260\n",
      "batch: 32220/60157............. Loss: 5.5267\n",
      "batch: 32240/60157............. Loss: 5.5286\n",
      "batch: 32260/60157............. Loss: 5.5281\n",
      "batch: 32280/60157............. Loss: 5.5293\n",
      "batch: 32300/60157............. Loss: 5.5229\n",
      "batch: 32320/60157............. Loss: 5.5286\n",
      "batch: 32340/60157............. Loss: 5.5270\n",
      "batch: 32360/60157............. Loss: 5.5248\n",
      "batch: 32380/60157............. Loss: 5.5241\n",
      "batch: 32400/60157............. Loss: 5.5263\n",
      "batch: 32420/60157............. Loss: 5.5275\n",
      "batch: 32440/60157............. Loss: 5.5268\n",
      "batch: 32460/60157............. Loss: 5.5213\n",
      "batch: 32480/60157............. Loss: 5.5231\n",
      "batch: 32500/60157............. Loss: 5.5238\n",
      "batch: 32520/60157............. Loss: 5.5294\n",
      "batch: 32540/60157............. Loss: 5.5266\n",
      "batch: 32560/60157............. Loss: 5.5296\n",
      "batch: 32580/60157............. Loss: 5.5286\n",
      "batch: 32600/60157............. Loss: 5.5246\n",
      "batch: 32620/60157............. Loss: 5.5287\n",
      "batch: 32640/60157............. Loss: 5.5241\n",
      "batch: 32660/60157............. Loss: 5.5278\n",
      "batch: 32680/60157............. Loss: 5.5290\n",
      "batch: 32700/60157............. Loss: 5.5231\n",
      "batch: 32720/60157............. Loss: 5.5269\n",
      "batch: 32740/60157............. Loss: 5.5224\n",
      "batch: 32760/60157............. Loss: 5.5280\n",
      "batch: 32780/60157............. Loss: 5.5262\n",
      "batch: 32800/60157............. Loss: 5.5283\n",
      "batch: 32820/60157............. Loss: 5.5265\n",
      "batch: 32840/60157............. Loss: 5.5244\n",
      "batch: 32860/60157............. Loss: 5.5273\n",
      "batch: 32880/60157............. Loss: 5.5271\n",
      "batch: 32900/60157............. Loss: 5.5262\n",
      "batch: 32920/60157............. Loss: 5.5265\n",
      "batch: 32940/60157............. Loss: 5.5251\n",
      "batch: 32960/60157............. Loss: 5.5264\n",
      "batch: 32980/60157............. Loss: 5.5282\n",
      "batch: 33000/60157............. Loss: 5.5172\n",
      "batch: 33020/60157............. Loss: 5.5261\n",
      "batch: 33040/60157............. Loss: 5.5299\n",
      "batch: 33060/60157............. Loss: 5.5244\n",
      "batch: 33080/60157............. Loss: 5.5263\n",
      "batch: 33100/60157............. Loss: 5.5264\n",
      "batch: 33120/60157............. Loss: 5.5229\n",
      "batch: 33140/60157............. Loss: 5.5225\n",
      "batch: 33160/60157............. Loss: 5.5302\n",
      "batch: 33180/60157............. Loss: 5.5288\n",
      "batch: 33200/60157............. Loss: 5.5260\n",
      "batch: 33220/60157............. Loss: 5.5253\n",
      "batch: 33240/60157............. Loss: 5.5260\n",
      "batch: 33260/60157............. Loss: 5.5264\n",
      "batch: 33280/60157............. Loss: 5.5255\n",
      "batch: 33300/60157............. Loss: 5.5239\n",
      "batch: 33320/60157............. Loss: 5.5266\n",
      "batch: 33340/60157............. Loss: 5.5254\n",
      "batch: 33360/60157............. Loss: 5.5302\n",
      "batch: 33380/60157............. Loss: 5.5254\n",
      "batch: 33400/60157............. Loss: 5.5270\n",
      "batch: 33420/60157............. Loss: 5.5255\n",
      "batch: 33440/60157............. Loss: 5.5256\n",
      "batch: 33460/60157............. Loss: 5.5271\n",
      "batch: 33480/60157............. Loss: 5.5266\n",
      "batch: 33500/60157............. Loss: 5.5295\n",
      "batch: 33520/60157............. Loss: 5.5239\n",
      "batch: 33540/60157............. Loss: 5.5224\n",
      "batch: 33560/60157............. Loss: 5.5270\n",
      "batch: 33580/60157............. Loss: 5.5248\n",
      "batch: 33600/60157............. Loss: 5.5253\n",
      "batch: 33620/60157............. Loss: 5.5259\n",
      "batch: 33640/60157............. Loss: 5.5284\n",
      "batch: 33660/60157............. Loss: 5.5283\n",
      "batch: 33680/60157............. Loss: 5.5259\n",
      "batch: 33700/60157............. Loss: 5.5207\n",
      "batch: 33720/60157............. Loss: 5.5257\n",
      "batch: 33740/60157............. Loss: 5.5274\n",
      "batch: 33760/60157............. Loss: 5.5253\n",
      "batch: 33780/60157............. Loss: 5.5303\n",
      "batch: 33800/60157............. Loss: 5.5228\n",
      "batch: 33820/60157............. Loss: 5.5261\n",
      "batch: 33840/60157............. Loss: 5.5247\n",
      "batch: 33860/60157............. Loss: 5.5222\n",
      "batch: 33880/60157............. Loss: 5.5270\n",
      "batch: 33900/60157............. Loss: 5.5310\n",
      "batch: 33920/60157............. Loss: 5.5289\n",
      "batch: 33940/60157............. Loss: 5.5270\n",
      "batch: 33960/60157............. Loss: 5.5245\n",
      "batch: 33980/60157............. Loss: 5.5265\n",
      "batch: 34000/60157............. Loss: 5.5241\n",
      "batch: 34020/60157............. Loss: 5.5316\n",
      "batch: 34040/60157............. Loss: 5.5249\n",
      "batch: 34060/60157............. Loss: 5.5235\n",
      "batch: 34080/60157............. Loss: 5.5279\n",
      "batch: 34100/60157............. Loss: 5.5261\n",
      "batch: 34120/60157............. Loss: 5.5257\n",
      "batch: 34140/60157............. Loss: 5.5223\n",
      "batch: 34160/60157............. Loss: 5.5267\n",
      "batch: 34180/60157............. Loss: 5.5287\n",
      "batch: 34200/60157............. Loss: 5.5248\n",
      "batch: 34220/60157............. Loss: 5.5239\n",
      "batch: 34240/60157............. Loss: 5.5264\n",
      "batch: 34260/60157............. Loss: 5.5214\n",
      "batch: 34280/60157............. Loss: 5.5254\n",
      "batch: 34300/60157............. Loss: 5.5261\n",
      "batch: 34320/60157............. Loss: 5.5267\n",
      "batch: 34340/60157............. Loss: 5.5244\n",
      "batch: 34360/60157............. Loss: 5.5277\n",
      "batch: 34380/60157............. Loss: 5.5229\n",
      "batch: 34400/60157............. Loss: 5.5248\n",
      "batch: 34420/60157............. Loss: 5.5276\n",
      "batch: 34440/60157............. Loss: 5.5314\n",
      "batch: 34460/60157............. Loss: 5.5267\n",
      "batch: 34480/60157............. Loss: 5.5259\n",
      "batch: 34500/60157............. Loss: 5.5265\n",
      "batch: 34520/60157............. Loss: 5.5291\n",
      "batch: 34540/60157............. Loss: 5.5304\n",
      "batch: 34560/60157............. Loss: 5.5255\n",
      "batch: 34580/60157............. Loss: 5.5246\n",
      "batch: 34600/60157............. Loss: 5.5260\n",
      "batch: 34620/60157............. Loss: 5.5285\n",
      "batch: 34640/60157............. Loss: 5.5278\n",
      "batch: 34660/60157............. Loss: 5.5312\n",
      "batch: 34680/60157............. Loss: 5.5256\n",
      "batch: 34700/60157............. Loss: 5.5305\n",
      "batch: 34720/60157............. Loss: 5.5249\n",
      "batch: 34740/60157............. Loss: 5.5259\n",
      "batch: 34760/60157............. Loss: 5.5284\n",
      "batch: 34780/60157............. Loss: 5.5290\n",
      "batch: 34800/60157............. Loss: 5.5256\n",
      "batch: 34820/60157............. Loss: 5.5229\n",
      "batch: 34840/60157............. Loss: 5.5212\n",
      "batch: 34860/60157............. Loss: 5.5228\n",
      "batch: 34880/60157............. Loss: 5.5224\n",
      "batch: 34900/60157............. Loss: 5.5210\n",
      "batch: 34920/60157............. Loss: 5.5235\n",
      "batch: 34940/60157............. Loss: 5.5293\n",
      "batch: 34960/60157............. Loss: 5.5244\n",
      "batch: 34980/60157............. Loss: 5.5219\n",
      "batch: 35000/60157............. Loss: 5.5233\n",
      "batch: 35020/60157............. Loss: 5.5277\n",
      "batch: 35040/60157............. Loss: 5.5301\n",
      "batch: 35060/60157............. Loss: 5.5284\n",
      "batch: 35080/60157............. Loss: 5.5260\n",
      "batch: 35100/60157............. Loss: 5.5270\n",
      "batch: 35120/60157............. Loss: 5.5215\n",
      "batch: 35140/60157............. Loss: 5.5282\n",
      "batch: 35160/60157............. Loss: 5.5272\n",
      "batch: 35180/60157............. Loss: 5.5261\n",
      "batch: 35200/60157............. Loss: 5.5239\n",
      "batch: 35220/60157............. Loss: 5.5292\n",
      "batch: 35240/60157............. Loss: 5.5244\n",
      "batch: 35260/60157............. Loss: 5.5252\n",
      "batch: 35280/60157............. Loss: 5.5275\n",
      "batch: 35300/60157............. Loss: 5.5271\n",
      "batch: 35320/60157............. Loss: 5.5293\n",
      "batch: 35340/60157............. Loss: 5.5255\n",
      "batch: 35360/60157............. Loss: 5.5218\n",
      "batch: 35380/60157............. Loss: 5.5320\n",
      "batch: 35400/60157............. Loss: 5.5247\n",
      "batch: 35420/60157............. Loss: 5.5243\n",
      "batch: 35440/60157............. Loss: 5.5263\n",
      "batch: 35460/60157............. Loss: 5.5257\n",
      "batch: 35480/60157............. Loss: 5.5253\n",
      "batch: 35500/60157............. Loss: 5.5232\n",
      "batch: 35520/60157............. Loss: 5.5243\n",
      "batch: 35540/60157............. Loss: 5.5252\n",
      "batch: 35560/60157............. Loss: 5.5232\n",
      "batch: 35580/60157............. Loss: 5.5269\n",
      "batch: 35600/60157............. Loss: 5.5252\n",
      "batch: 35620/60157............. Loss: 5.5246\n",
      "batch: 35640/60157............. Loss: 5.5274\n",
      "batch: 35660/60157............. Loss: 5.5221\n",
      "batch: 35680/60157............. Loss: 5.5246\n",
      "batch: 35700/60157............. Loss: 5.5209\n",
      "batch: 35720/60157............. Loss: 5.5263\n",
      "batch: 35740/60157............. Loss: 5.5242\n",
      "batch: 35760/60157............. Loss: 5.5241\n",
      "batch: 35780/60157............. Loss: 5.5285\n",
      "batch: 35800/60157............. Loss: 5.5250\n",
      "batch: 35820/60157............. Loss: 5.5253\n",
      "batch: 35840/60157............. Loss: 5.5256\n",
      "batch: 35860/60157............. Loss: 5.5236\n",
      "batch: 35880/60157............. Loss: 5.5269\n",
      "batch: 35900/60157............. Loss: 5.5291\n",
      "batch: 35920/60157............. Loss: 5.5276\n",
      "batch: 35940/60157............. Loss: 5.5287\n",
      "batch: 35960/60157............. Loss: 5.5214\n",
      "batch: 35980/60157............. Loss: 5.5278\n",
      "batch: 36000/60157............. Loss: 5.5208\n",
      "batch: 36020/60157............. Loss: 5.5274\n",
      "batch: 36040/60157............. Loss: 5.5231\n",
      "batch: 36060/60157............. Loss: 5.5272\n",
      "batch: 36080/60157............. Loss: 5.5326\n",
      "batch: 36100/60157............. Loss: 5.5248\n",
      "batch: 36120/60157............. Loss: 5.5246\n",
      "batch: 36140/60157............. Loss: 5.5264\n",
      "batch: 36160/60157............. Loss: 5.5272\n",
      "batch: 36180/60157............. Loss: 5.5274\n",
      "batch: 36200/60157............. Loss: 5.5270\n",
      "batch: 36220/60157............. Loss: 5.5271\n",
      "batch: 36240/60157............. Loss: 5.5295\n",
      "batch: 36260/60157............. Loss: 5.5289\n",
      "batch: 36280/60157............. Loss: 5.5278\n",
      "batch: 36300/60157............. Loss: 5.5189\n",
      "batch: 36320/60157............. Loss: 5.5279\n",
      "batch: 36340/60157............. Loss: 5.5248\n",
      "batch: 36360/60157............. Loss: 5.5322\n",
      "batch: 36380/60157............. Loss: 5.5092\n",
      "batch: 36400/60157............. Loss: 5.5263\n",
      "batch: 36420/60157............. Loss: 5.5285\n",
      "batch: 36440/60157............. Loss: 5.5228\n",
      "batch: 36460/60157............. Loss: 5.5305\n",
      "batch: 36480/60157............. Loss: 5.5260\n",
      "batch: 36500/60157............. Loss: 5.5240\n",
      "batch: 36520/60157............. Loss: 5.5256\n",
      "batch: 36540/60157............. Loss: 5.5267\n",
      "batch: 36560/60157............. Loss: 5.5287\n",
      "batch: 36580/60157............. Loss: 5.5256\n",
      "batch: 36600/60157............. Loss: 5.5247\n",
      "batch: 36620/60157............. Loss: 5.5297\n",
      "batch: 36640/60157............. Loss: 5.5244\n",
      "batch: 36660/60157............. Loss: 5.5295\n",
      "batch: 36680/60157............. Loss: 5.5233\n",
      "batch: 36700/60157............. Loss: 5.5285\n",
      "batch: 36720/60157............. Loss: 5.5260\n",
      "batch: 36740/60157............. Loss: 5.5276\n",
      "batch: 36760/60157............. Loss: 5.5245\n",
      "batch: 36780/60157............. Loss: 5.5263\n",
      "batch: 36800/60157............. Loss: 5.5302\n",
      "batch: 36820/60157............. Loss: 5.5280\n",
      "batch: 36840/60157............. Loss: 5.5260\n",
      "batch: 36860/60157............. Loss: 5.5307\n",
      "batch: 36880/60157............. Loss: 5.5274\n",
      "batch: 36900/60157............. Loss: 5.5256\n",
      "batch: 36920/60157............. Loss: 5.5299\n",
      "batch: 36940/60157............. Loss: 5.5268\n",
      "batch: 36960/60157............. Loss: 5.5299\n",
      "batch: 36980/60157............. Loss: 5.5286\n",
      "batch: 37000/60157............. Loss: 5.5255\n",
      "batch: 37020/60157............. Loss: 5.5260\n",
      "batch: 37040/60157............. Loss: 5.5279\n",
      "batch: 37060/60157............. Loss: 5.5275\n",
      "batch: 37080/60157............. Loss: 5.5296\n",
      "batch: 37100/60157............. Loss: 5.5283\n",
      "batch: 37120/60157............. Loss: 5.5236\n",
      "batch: 37140/60157............. Loss: 5.5245\n",
      "batch: 37160/60157............. Loss: 5.5252\n",
      "batch: 37180/60157............. Loss: 5.5273\n",
      "batch: 37200/60157............. Loss: 5.5295\n",
      "batch: 37220/60157............. Loss: 5.5248\n",
      "batch: 37240/60157............. Loss: 5.5244\n",
      "batch: 37260/60157............. Loss: 5.5265\n",
      "batch: 37280/60157............. Loss: 5.5274\n",
      "batch: 37300/60157............. Loss: 5.5272\n",
      "batch: 37320/60157............. Loss: 5.5285\n",
      "batch: 37340/60157............. Loss: 5.5263\n",
      "batch: 37360/60157............. Loss: 5.5240\n",
      "batch: 37380/60157............. Loss: 5.5276\n",
      "batch: 37400/60157............. Loss: 5.5289\n",
      "batch: 37420/60157............. Loss: 5.5274\n",
      "batch: 37440/60157............. Loss: 5.5237\n",
      "batch: 37460/60157............. Loss: 5.5279\n",
      "batch: 37480/60157............. Loss: 5.5261\n",
      "batch: 37500/60157............. Loss: 5.5277\n",
      "batch: 37520/60157............. Loss: 5.5266\n",
      "batch: 37540/60157............. Loss: 5.5264\n",
      "batch: 37560/60157............. Loss: 5.5269\n",
      "batch: 37580/60157............. Loss: 5.5282\n",
      "batch: 37600/60157............. Loss: 5.5230\n",
      "batch: 37620/60157............. Loss: 5.5315\n",
      "batch: 37640/60157............. Loss: 5.5281\n",
      "batch: 37660/60157............. Loss: 5.5240\n",
      "batch: 37680/60157............. Loss: 5.5285\n",
      "batch: 37700/60157............. Loss: 5.5235\n",
      "batch: 37720/60157............. Loss: 5.5284\n",
      "batch: 37740/60157............. Loss: 5.5238\n",
      "batch: 37760/60157............. Loss: 5.5265\n",
      "batch: 37780/60157............. Loss: 5.5286\n",
      "batch: 37800/60157............. Loss: 5.5274\n",
      "batch: 37820/60157............. Loss: 5.5231\n",
      "batch: 37840/60157............. Loss: 5.5264\n",
      "batch: 37860/60157............. Loss: 5.5245\n",
      "batch: 37880/60157............. Loss: 5.5230\n",
      "batch: 37900/60157............. Loss: 5.5248\n",
      "batch: 37920/60157............. Loss: 5.5265\n",
      "batch: 37940/60157............. Loss: 5.5257\n",
      "batch: 37960/60157............. Loss: 5.5292\n",
      "batch: 37980/60157............. Loss: 5.5252\n",
      "batch: 38000/60157............. Loss: 5.5238\n",
      "batch: 38020/60157............. Loss: 5.5251\n",
      "batch: 38040/60157............. Loss: 5.5241\n",
      "batch: 38060/60157............. Loss: 5.5312\n",
      "batch: 38080/60157............. Loss: 5.5272\n",
      "batch: 38100/60157............. Loss: 5.5277\n",
      "batch: 38120/60157............. Loss: 5.5258\n",
      "batch: 38140/60157............. Loss: 5.5271\n",
      "batch: 38160/60157............. Loss: 5.5221\n",
      "batch: 38180/60157............. Loss: 5.5264\n",
      "batch: 38200/60157............. Loss: 5.5279\n",
      "batch: 38220/60157............. Loss: 5.5305\n",
      "batch: 38240/60157............. Loss: 5.5258\n",
      "batch: 38260/60157............. Loss: 5.5227\n",
      "batch: 38280/60157............. Loss: 5.5296\n",
      "batch: 38300/60157............. Loss: 5.5292\n",
      "batch: 38320/60157............. Loss: 5.5292\n",
      "batch: 38340/60157............. Loss: 5.5238\n",
      "batch: 38360/60157............. Loss: 5.5249\n",
      "batch: 38380/60157............. Loss: 5.5298\n",
      "batch: 38400/60157............. Loss: 5.5255\n",
      "batch: 38420/60157............. Loss: 5.5293\n",
      "batch: 38440/60157............. Loss: 5.5220\n",
      "batch: 38460/60157............. Loss: 5.5275\n",
      "batch: 38480/60157............. Loss: 5.5246\n",
      "batch: 38500/60157............. Loss: 5.5254\n",
      "batch: 38520/60157............. Loss: 5.5231\n",
      "batch: 38540/60157............. Loss: 5.5261\n",
      "batch: 38560/60157............. Loss: 5.5251\n",
      "batch: 38580/60157............. Loss: 5.5227\n",
      "batch: 38600/60157............. Loss: 5.5250\n",
      "batch: 38620/60157............. Loss: 5.5259\n",
      "batch: 38640/60157............. Loss: 5.5255\n",
      "batch: 38660/60157............. Loss: 5.5226\n",
      "batch: 38680/60157............. Loss: 5.5249\n",
      "batch: 38700/60157............. Loss: 5.5262\n",
      "batch: 38720/60157............. Loss: 5.5184\n",
      "batch: 38740/60157............. Loss: 5.5265\n",
      "batch: 38760/60157............. Loss: 5.5250\n",
      "batch: 38780/60157............. Loss: 5.5280\n",
      "batch: 38800/60157............. Loss: 5.5251\n",
      "batch: 38820/60157............. Loss: 5.5293\n",
      "batch: 38840/60157............. Loss: 5.5334\n",
      "batch: 38860/60157............. Loss: 5.5285\n",
      "batch: 38880/60157............. Loss: 5.5262\n",
      "batch: 38900/60157............. Loss: 5.5307\n",
      "batch: 38920/60157............. Loss: 5.5278\n",
      "batch: 38940/60157............. Loss: 5.5227\n",
      "batch: 38960/60157............. Loss: 5.5280\n",
      "batch: 38980/60157............. Loss: 5.5291\n",
      "batch: 39000/60157............. Loss: 5.5222\n",
      "batch: 39020/60157............. Loss: 5.5282\n",
      "batch: 39040/60157............. Loss: 5.5275\n",
      "batch: 39060/60157............. Loss: 5.5261\n",
      "batch: 39080/60157............. Loss: 5.5247\n",
      "batch: 39100/60157............. Loss: 5.5280\n",
      "batch: 39120/60157............. Loss: 5.5260\n",
      "batch: 39140/60157............. Loss: 5.5270\n",
      "batch: 39160/60157............. Loss: 5.5235\n",
      "batch: 39180/60157............. Loss: 5.5272\n",
      "batch: 39200/60157............. Loss: 5.5279\n",
      "batch: 39220/60157............. Loss: 5.5309\n",
      "batch: 39240/60157............. Loss: 5.5278\n",
      "batch: 39260/60157............. Loss: 5.5296\n",
      "batch: 39280/60157............. Loss: 5.5304\n",
      "batch: 39300/60157............. Loss: 5.5233\n",
      "batch: 39320/60157............. Loss: 5.5308\n",
      "batch: 39340/60157............. Loss: 5.5259\n",
      "batch: 39360/60157............. Loss: 5.5242\n",
      "batch: 39380/60157............. Loss: 5.5288\n",
      "batch: 39400/60157............. Loss: 5.5247\n",
      "batch: 39420/60157............. Loss: 5.5263\n",
      "batch: 39440/60157............. Loss: 5.5275\n",
      "batch: 39460/60157............. Loss: 5.5268\n",
      "batch: 39480/60157............. Loss: 5.5240\n",
      "batch: 39500/60157............. Loss: 5.5292\n",
      "batch: 39520/60157............. Loss: 5.5244\n",
      "batch: 39540/60157............. Loss: 5.5283\n",
      "batch: 39560/60157............. Loss: 5.5275\n",
      "batch: 39580/60157............. Loss: 5.5264\n",
      "batch: 39600/60157............. Loss: 5.5302\n",
      "batch: 39620/60157............. Loss: 5.5166\n",
      "batch: 39640/60157............. Loss: 5.5249\n",
      "batch: 39660/60157............. Loss: 5.5226\n",
      "batch: 39680/60157............. Loss: 5.5265\n",
      "batch: 39700/60157............. Loss: 5.5312\n",
      "batch: 39720/60157............. Loss: 5.5250\n",
      "batch: 39740/60157............. Loss: 5.5264\n",
      "batch: 39760/60157............. Loss: 5.5261\n",
      "batch: 39780/60157............. Loss: 5.5274\n",
      "batch: 39800/60157............. Loss: 5.5262\n",
      "batch: 39820/60157............. Loss: 5.5230\n",
      "batch: 39840/60157............. Loss: 5.5303\n",
      "batch: 39860/60157............. Loss: 5.5301\n",
      "batch: 39880/60157............. Loss: 5.5326\n",
      "batch: 39900/60157............. Loss: 5.5263\n",
      "batch: 39920/60157............. Loss: 5.5319\n",
      "batch: 39940/60157............. Loss: 5.5287\n",
      "batch: 39960/60157............. Loss: 5.5267\n",
      "batch: 39980/60157............. Loss: 5.5293\n",
      "batch: 40000/60157............. Loss: 5.5299\n",
      "batch: 40020/60157............. Loss: 5.5250\n",
      "batch: 40040/60157............. Loss: 5.5164\n",
      "batch: 40060/60157............. Loss: 5.5246\n",
      "batch: 40080/60157............. Loss: 5.5279\n",
      "batch: 40100/60157............. Loss: 5.5272\n",
      "batch: 40120/60157............. Loss: 5.5275\n",
      "batch: 40140/60157............. Loss: 5.5253\n",
      "batch: 40160/60157............. Loss: 5.5252\n",
      "batch: 40180/60157............. Loss: 5.5254\n",
      "batch: 40200/60157............. Loss: 5.5257\n",
      "batch: 40220/60157............. Loss: 5.5281\n",
      "batch: 40240/60157............. Loss: 5.5269\n",
      "batch: 40260/60157............. Loss: 5.5244\n",
      "batch: 40280/60157............. Loss: 5.5262\n",
      "batch: 40300/60157............. Loss: 5.5226\n",
      "batch: 40320/60157............. Loss: 5.5256\n",
      "batch: 40340/60157............. Loss: 5.5250\n",
      "batch: 40360/60157............. Loss: 5.5275\n",
      "batch: 40380/60157............. Loss: 5.5288\n",
      "batch: 40400/60157............. Loss: 5.5294\n",
      "batch: 40420/60157............. Loss: 5.5284\n",
      "batch: 40440/60157............. Loss: 5.5312\n",
      "batch: 40460/60157............. Loss: 5.5292\n",
      "batch: 40480/60157............. Loss: 5.5292\n",
      "batch: 40500/60157............. Loss: 5.5260\n",
      "batch: 40520/60157............. Loss: 5.5256\n",
      "batch: 40540/60157............. Loss: 5.5259\n",
      "batch: 40560/60157............. Loss: 5.5259\n",
      "batch: 40580/60157............. Loss: 5.5263\n",
      "batch: 40600/60157............. Loss: 5.5240\n",
      "batch: 40620/60157............. Loss: 5.5278\n",
      "batch: 40640/60157............. Loss: 5.5271\n",
      "batch: 40660/60157............. Loss: 5.5256\n",
      "batch: 40680/60157............. Loss: 5.5287\n",
      "batch: 40700/60157............. Loss: 5.5289\n",
      "batch: 40720/60157............. Loss: 5.5284\n",
      "batch: 40740/60157............. Loss: 5.5278\n",
      "batch: 40760/60157............. Loss: 5.5274\n",
      "batch: 40780/60157............. Loss: 5.5251\n",
      "batch: 40800/60157............. Loss: 5.5227\n",
      "batch: 40820/60157............. Loss: 5.5275\n",
      "batch: 40840/60157............. Loss: 5.5275\n",
      "batch: 40860/60157............. Loss: 5.5301\n",
      "batch: 40880/60157............. Loss: 5.5226\n",
      "batch: 40900/60157............. Loss: 5.5255\n",
      "batch: 40920/60157............. Loss: 5.5253\n",
      "batch: 40940/60157............. Loss: 5.5271\n",
      "batch: 40960/60157............. Loss: 5.5231\n",
      "batch: 40980/60157............. Loss: 5.5270\n",
      "batch: 41000/60157............. Loss: 5.5267\n",
      "batch: 41020/60157............. Loss: 5.5274\n",
      "batch: 41040/60157............. Loss: 5.5306\n",
      "batch: 41060/60157............. Loss: 5.5251\n",
      "batch: 41080/60157............. Loss: 5.5268\n",
      "batch: 41100/60157............. Loss: 5.5234\n",
      "batch: 41120/60157............. Loss: 5.5252\n",
      "batch: 41140/60157............. Loss: 5.5251\n",
      "batch: 41160/60157............. Loss: 5.5228\n",
      "batch: 41180/60157............. Loss: 5.5302\n",
      "batch: 41200/60157............. Loss: 5.5247\n",
      "batch: 41220/60157............. Loss: 5.5272\n",
      "batch: 41240/60157............. Loss: 5.5308\n",
      "batch: 41260/60157............. Loss: 5.5260\n",
      "batch: 41280/60157............. Loss: 5.5307\n",
      "batch: 41300/60157............. Loss: 5.5281\n",
      "batch: 41320/60157............. Loss: 5.5246\n",
      "batch: 41340/60157............. Loss: 5.5236\n",
      "batch: 41360/60157............. Loss: 5.5254\n",
      "batch: 41380/60157............. Loss: 5.5252\n",
      "batch: 41400/60157............. Loss: 5.5270\n",
      "batch: 41420/60157............. Loss: 5.5275\n",
      "batch: 41440/60157............. Loss: 5.5268\n",
      "batch: 41460/60157............. Loss: 5.5256\n",
      "batch: 41480/60157............. Loss: 5.5264\n",
      "batch: 41500/60157............. Loss: 5.5264\n",
      "batch: 41520/60157............. Loss: 5.5290\n",
      "batch: 41540/60157............. Loss: 5.5236\n",
      "batch: 41560/60157............. Loss: 5.5221\n",
      "batch: 41580/60157............. Loss: 5.5292\n",
      "batch: 41600/60157............. Loss: 5.5265\n",
      "batch: 41620/60157............. Loss: 5.5279\n",
      "batch: 41640/60157............. Loss: 5.5201\n",
      "batch: 41660/60157............. Loss: 5.5263\n",
      "batch: 41680/60157............. Loss: 5.5237\n",
      "batch: 41700/60157............. Loss: 5.5231\n",
      "batch: 41720/60157............. Loss: 5.5262\n",
      "batch: 41740/60157............. Loss: 5.5248\n",
      "batch: 41760/60157............. Loss: 5.5227\n",
      "batch: 41780/60157............. Loss: 5.5268\n",
      "batch: 41800/60157............. Loss: 5.5252\n",
      "batch: 41820/60157............. Loss: 5.5281\n",
      "batch: 41840/60157............. Loss: 5.5241\n",
      "batch: 41860/60157............. Loss: 5.5252\n",
      "batch: 41880/60157............. Loss: 5.5269\n",
      "batch: 41900/60157............. Loss: 5.5311\n",
      "batch: 41920/60157............. Loss: 5.5282\n",
      "batch: 41940/60157............. Loss: 5.5240\n",
      "batch: 41960/60157............. Loss: 5.5303\n",
      "batch: 41980/60157............. Loss: 5.5277\n",
      "batch: 42000/60157............. Loss: 5.5267\n",
      "batch: 42020/60157............. Loss: 5.5263\n",
      "batch: 42040/60157............. Loss: 5.5279\n",
      "batch: 42060/60157............. Loss: 5.5287\n",
      "batch: 42080/60157............. Loss: 5.5260\n",
      "batch: 42100/60157............. Loss: 5.5208\n",
      "batch: 42120/60157............. Loss: 5.5237\n",
      "batch: 42140/60157............. Loss: 5.5268\n",
      "batch: 42160/60157............. Loss: 5.5214\n",
      "batch: 42180/60157............. Loss: 5.5224\n",
      "batch: 42200/60157............. Loss: 5.5227\n",
      "batch: 42220/60157............. Loss: 5.5186\n",
      "batch: 42240/60157............. Loss: 5.5269\n",
      "batch: 42260/60157............. Loss: 5.5228\n",
      "batch: 42280/60157............. Loss: 5.5241\n",
      "batch: 42300/60157............. Loss: 5.5252\n",
      "batch: 42320/60157............. Loss: 5.5268\n",
      "batch: 42340/60157............. Loss: 5.5268\n",
      "batch: 42360/60157............. Loss: 5.5255\n",
      "batch: 42380/60157............. Loss: 5.5257\n",
      "batch: 42400/60157............. Loss: 5.5265\n",
      "batch: 42420/60157............. Loss: 5.5272\n",
      "batch: 42440/60157............. Loss: 5.5256\n",
      "batch: 42460/60157............. Loss: 5.5278\n",
      "batch: 42480/60157............. Loss: 5.5255\n",
      "batch: 42500/60157............. Loss: 5.5297\n",
      "batch: 42520/60157............. Loss: 5.5228\n",
      "batch: 42540/60157............. Loss: 5.5276\n",
      "batch: 42560/60157............. Loss: 5.5241\n",
      "batch: 42580/60157............. Loss: 5.5240\n",
      "batch: 42600/60157............. Loss: 5.5229\n",
      "batch: 42620/60157............. Loss: 5.5242\n",
      "batch: 42640/60157............. Loss: 5.5171\n",
      "batch: 42660/60157............. Loss: 5.5205\n",
      "batch: 42680/60157............. Loss: 5.5248\n",
      "batch: 42700/60157............. Loss: 5.5270\n",
      "batch: 42720/60157............. Loss: 5.5269\n",
      "batch: 42740/60157............. Loss: 5.5279\n",
      "batch: 42760/60157............. Loss: 5.5247\n",
      "batch: 42780/60157............. Loss: 5.5204\n",
      "batch: 42800/60157............. Loss: 5.5261\n",
      "batch: 42820/60157............. Loss: 5.5282\n",
      "batch: 42840/60157............. Loss: 5.5265\n",
      "batch: 42860/60157............. Loss: 5.5231\n",
      "batch: 42880/60157............. Loss: 5.5306\n",
      "batch: 42900/60157............. Loss: 5.5231\n",
      "batch: 42920/60157............. Loss: 5.5263\n",
      "batch: 42940/60157............. Loss: 5.5268\n",
      "batch: 42960/60157............. Loss: 5.5234\n",
      "batch: 42980/60157............. Loss: 5.5254\n",
      "batch: 43000/60157............. Loss: 5.5221\n",
      "batch: 43020/60157............. Loss: 5.5253\n",
      "batch: 43040/60157............. Loss: 5.5271\n",
      "batch: 43060/60157............. Loss: 5.5215\n",
      "batch: 43080/60157............. Loss: 5.5298\n",
      "batch: 43100/60157............. Loss: 5.5254\n",
      "batch: 43120/60157............. Loss: 5.5250\n",
      "batch: 43140/60157............. Loss: 5.5239\n",
      "batch: 43160/60157............. Loss: 5.5281\n",
      "batch: 43180/60157............. Loss: 5.5235\n",
      "batch: 43200/60157............. Loss: 5.5239\n",
      "batch: 43220/60157............. Loss: 5.5278\n",
      "batch: 43240/60157............. Loss: 5.5279\n",
      "batch: 43260/60157............. Loss: 5.5235\n",
      "batch: 43280/60157............. Loss: 5.5267\n",
      "batch: 43300/60157............. Loss: 5.5253\n",
      "batch: 43320/60157............. Loss: 5.5261\n",
      "batch: 43340/60157............. Loss: 5.5219\n",
      "batch: 43360/60157............. Loss: 5.5271\n",
      "batch: 43380/60157............. Loss: 5.5251\n",
      "batch: 43400/60157............. Loss: 5.5276\n",
      "batch: 43420/60157............. Loss: 5.5269\n",
      "batch: 43440/60157............. Loss: 5.5235\n",
      "batch: 43460/60157............. Loss: 5.5236\n",
      "batch: 43480/60157............. Loss: 5.5222\n",
      "batch: 43500/60157............. Loss: 5.5283\n",
      "batch: 43520/60157............. Loss: 5.5300\n",
      "batch: 43540/60157............. Loss: 5.5212\n",
      "batch: 43560/60157............. Loss: 5.5313\n",
      "batch: 43580/60157............. Loss: 5.5285\n",
      "batch: 43600/60157............. Loss: 5.5258\n",
      "batch: 43620/60157............. Loss: 5.5275\n",
      "batch: 43640/60157............. Loss: 5.5284\n",
      "batch: 43660/60157............. Loss: 5.5239\n",
      "batch: 43680/60157............. Loss: 5.5247\n",
      "batch: 43700/60157............. Loss: 5.5295\n",
      "batch: 43720/60157............. Loss: 5.5208\n",
      "batch: 43740/60157............. Loss: 5.5255\n",
      "batch: 43760/60157............. Loss: 5.5310\n",
      "batch: 43780/60157............. Loss: 5.5275\n",
      "batch: 43800/60157............. Loss: 5.5294\n",
      "batch: 43820/60157............. Loss: 5.5271\n",
      "batch: 43840/60157............. Loss: 5.5246\n",
      "batch: 43860/60157............. Loss: 5.5224\n",
      "batch: 43880/60157............. Loss: 5.5258\n",
      "batch: 43900/60157............. Loss: 5.5237\n",
      "batch: 43920/60157............. Loss: 5.5283\n",
      "batch: 43940/60157............. Loss: 5.5248\n",
      "batch: 43960/60157............. Loss: 5.5268\n",
      "batch: 43980/60157............. Loss: 5.5294\n",
      "batch: 44000/60157............. Loss: 5.5260\n",
      "batch: 44020/60157............. Loss: 5.5262\n",
      "batch: 44040/60157............. Loss: 5.5290\n",
      "batch: 44060/60157............. Loss: 5.5213\n",
      "batch: 44080/60157............. Loss: 5.5249\n",
      "batch: 44100/60157............. Loss: 5.5249\n",
      "batch: 44120/60157............. Loss: 5.5267\n",
      "batch: 44140/60157............. Loss: 5.5208\n",
      "batch: 44160/60157............. Loss: 5.5238\n",
      "batch: 44180/60157............. Loss: 5.5277\n",
      "batch: 44200/60157............. Loss: 5.5267\n",
      "batch: 44220/60157............. Loss: 5.5239\n",
      "batch: 44240/60157............. Loss: 5.5289\n",
      "batch: 44260/60157............. Loss: 5.5262\n",
      "batch: 44280/60157............. Loss: 5.5237\n",
      "batch: 44300/60157............. Loss: 5.5236\n",
      "batch: 44320/60157............. Loss: 5.5298\n",
      "batch: 44340/60157............. Loss: 5.5278\n",
      "batch: 44360/60157............. Loss: 5.5247\n",
      "batch: 44380/60157............. Loss: 5.5243\n",
      "batch: 44400/60157............. Loss: 5.5200\n",
      "batch: 44420/60157............. Loss: 5.5281\n",
      "batch: 44440/60157............. Loss: 5.5232\n",
      "batch: 44460/60157............. Loss: 5.5273\n",
      "batch: 44480/60157............. Loss: 5.5254\n",
      "batch: 44500/60157............. Loss: 5.5257\n",
      "batch: 44520/60157............. Loss: 5.5311\n",
      "batch: 44540/60157............. Loss: 5.5267\n",
      "batch: 44560/60157............. Loss: 5.5259\n",
      "batch: 44580/60157............. Loss: 5.5240\n",
      "batch: 44600/60157............. Loss: 5.5230\n",
      "batch: 44620/60157............. Loss: 5.5244\n",
      "batch: 44640/60157............. Loss: 5.5280\n",
      "batch: 44660/60157............. Loss: 5.5266\n",
      "batch: 44680/60157............. Loss: 5.5270\n",
      "batch: 44700/60157............. Loss: 5.5253\n",
      "batch: 44720/60157............. Loss: 5.5243\n",
      "batch: 44740/60157............. Loss: 5.5209\n",
      "batch: 44760/60157............. Loss: 5.5194\n",
      "batch: 44780/60157............. Loss: 5.5189\n",
      "batch: 44800/60157............. Loss: 5.5302\n",
      "batch: 44820/60157............. Loss: 5.5268\n",
      "batch: 44840/60157............. Loss: 5.5249\n",
      "batch: 44860/60157............. Loss: 5.5261\n",
      "batch: 44880/60157............. Loss: 5.5202\n",
      "batch: 44900/60157............. Loss: 5.5238\n",
      "batch: 44920/60157............. Loss: 5.5215\n",
      "batch: 44940/60157............. Loss: 5.5227\n",
      "batch: 44960/60157............. Loss: 5.5268\n",
      "batch: 44980/60157............. Loss: 5.5248\n",
      "batch: 45000/60157............. Loss: 5.5263\n",
      "batch: 45020/60157............. Loss: 5.5256\n",
      "batch: 45040/60157............. Loss: 5.5261\n",
      "batch: 45060/60157............. Loss: 5.5267\n",
      "batch: 45080/60157............. Loss: 5.5244\n",
      "batch: 45100/60157............. Loss: 5.5225\n",
      "batch: 45120/60157............. Loss: 5.5220\n",
      "batch: 45140/60157............. Loss: 5.5266\n",
      "batch: 45160/60157............. Loss: 5.5252\n",
      "batch: 45180/60157............. Loss: 5.5275\n",
      "batch: 45200/60157............. Loss: 5.5232\n",
      "batch: 45220/60157............. Loss: 5.5266\n",
      "batch: 45240/60157............. Loss: 5.5293\n",
      "batch: 45260/60157............. Loss: 5.5278\n",
      "batch: 45280/60157............. Loss: 5.5265\n",
      "batch: 45300/60157............. Loss: 5.5275\n",
      "batch: 45320/60157............. Loss: 5.5281\n",
      "batch: 45340/60157............. Loss: 5.5227\n",
      "batch: 45360/60157............. Loss: 5.5250\n",
      "batch: 45380/60157............. Loss: 5.5246\n",
      "batch: 45400/60157............. Loss: 5.5267\n",
      "batch: 45420/60157............. Loss: 5.5221\n",
      "batch: 45440/60157............. Loss: 5.5250\n",
      "batch: 45460/60157............. Loss: 5.5278\n",
      "batch: 45480/60157............. Loss: 5.5285\n",
      "batch: 45500/60157............. Loss: 5.5174\n",
      "batch: 45520/60157............. Loss: 5.5229\n",
      "batch: 45540/60157............. Loss: 5.5274\n",
      "batch: 45560/60157............. Loss: 5.5262\n",
      "batch: 45580/60157............. Loss: 5.5224\n",
      "batch: 45600/60157............. Loss: 5.5244\n",
      "batch: 45620/60157............. Loss: 5.5236\n",
      "batch: 45640/60157............. Loss: 5.5273\n",
      "batch: 45660/60157............. Loss: 5.5264\n",
      "batch: 45680/60157............. Loss: 5.5248\n",
      "batch: 45700/60157............. Loss: 5.5206\n",
      "batch: 45720/60157............. Loss: 5.5295\n",
      "batch: 45740/60157............. Loss: 5.5222\n",
      "batch: 45760/60157............. Loss: 5.5291\n",
      "batch: 45780/60157............. Loss: 5.5243\n",
      "batch: 45800/60157............. Loss: 5.5278\n",
      "batch: 45820/60157............. Loss: 5.5229\n",
      "batch: 45840/60157............. Loss: 5.5260\n",
      "batch: 45860/60157............. Loss: 5.5243\n",
      "batch: 45880/60157............. Loss: 5.5268\n",
      "batch: 45900/60157............. Loss: 5.5202\n",
      "batch: 45920/60157............. Loss: 5.5226\n",
      "batch: 45940/60157............. Loss: 5.5250\n",
      "batch: 45960/60157............. Loss: 5.5247\n",
      "batch: 45980/60157............. Loss: 5.5284\n",
      "batch: 46000/60157............. Loss: 5.5294\n",
      "batch: 46020/60157............. Loss: 5.5251\n",
      "batch: 46040/60157............. Loss: 5.5195\n",
      "batch: 46060/60157............. Loss: 5.5219\n",
      "batch: 46080/60157............. Loss: 5.5214\n",
      "batch: 46100/60157............. Loss: 5.5242\n",
      "batch: 46120/60157............. Loss: 5.5264\n",
      "batch: 46140/60157............. Loss: 5.5257\n",
      "batch: 46160/60157............. Loss: 5.5282\n",
      "batch: 46180/60157............. Loss: 5.5252\n",
      "batch: 46200/60157............. Loss: 5.5297\n",
      "batch: 46220/60157............. Loss: 5.5250\n",
      "batch: 46240/60157............. Loss: 5.5254\n",
      "batch: 46260/60157............. Loss: 5.5232\n",
      "batch: 46280/60157............. Loss: 5.5243\n",
      "batch: 46300/60157............. Loss: 5.5260\n",
      "batch: 46320/60157............. Loss: 5.5269\n",
      "batch: 46340/60157............. Loss: 5.5296\n",
      "batch: 46360/60157............. Loss: 5.5242\n",
      "batch: 46380/60157............. Loss: 5.5237\n",
      "batch: 46400/60157............. Loss: 5.5267\n",
      "batch: 46420/60157............. Loss: 5.5224\n",
      "batch: 46440/60157............. Loss: 5.5257\n",
      "batch: 46460/60157............. Loss: 5.5277\n",
      "batch: 46480/60157............. Loss: 5.5240\n",
      "batch: 46500/60157............. Loss: 5.5280\n",
      "batch: 46520/60157............. Loss: 5.5269\n",
      "batch: 46540/60157............. Loss: 5.5240\n",
      "batch: 46560/60157............. Loss: 5.5247\n",
      "batch: 46580/60157............. Loss: 5.5254\n",
      "batch: 46600/60157............. Loss: 5.5236\n",
      "batch: 46620/60157............. Loss: 5.5275\n",
      "batch: 46640/60157............. Loss: 5.5261\n",
      "batch: 46660/60157............. Loss: 5.5280\n",
      "batch: 46680/60157............. Loss: 5.5242\n",
      "batch: 46700/60157............. Loss: 5.5229\n",
      "batch: 46720/60157............. Loss: 5.5265\n",
      "batch: 46740/60157............. Loss: 5.5269\n",
      "batch: 46760/60157............. Loss: 5.5235\n",
      "batch: 46780/60157............. Loss: 5.5270\n",
      "batch: 46800/60157............. Loss: 5.5232\n",
      "batch: 46820/60157............. Loss: 5.5273\n",
      "batch: 46840/60157............. Loss: 5.5230\n",
      "batch: 46860/60157............. Loss: 5.5253\n",
      "batch: 46880/60157............. Loss: 5.5248\n",
      "batch: 46900/60157............. Loss: 5.5197\n",
      "batch: 46920/60157............. Loss: 5.5221\n",
      "batch: 46940/60157............. Loss: 5.5266\n",
      "batch: 46960/60157............. Loss: 5.5277\n",
      "batch: 46980/60157............. Loss: 5.5236\n",
      "batch: 47000/60157............. Loss: 5.5227\n",
      "batch: 47020/60157............. Loss: 5.5260\n",
      "batch: 47040/60157............. Loss: 5.5263\n",
      "batch: 47060/60157............. Loss: 5.5224\n",
      "batch: 47080/60157............. Loss: 5.5242\n",
      "batch: 47100/60157............. Loss: 5.5263\n",
      "batch: 47120/60157............. Loss: 5.5247\n",
      "batch: 47140/60157............. Loss: 5.5231\n",
      "batch: 47160/60157............. Loss: 5.5235\n",
      "batch: 47180/60157............. Loss: 5.5200\n",
      "batch: 47200/60157............. Loss: 5.5250\n",
      "batch: 47220/60157............. Loss: 5.5190\n",
      "batch: 47240/60157............. Loss: 5.5241\n",
      "batch: 47260/60157............. Loss: 5.5238\n",
      "batch: 47280/60157............. Loss: 5.5199\n",
      "batch: 47300/60157............. Loss: 5.5266\n",
      "batch: 47320/60157............. Loss: 5.5245\n",
      "batch: 47340/60157............. Loss: 5.5253\n",
      "batch: 47360/60157............. Loss: 5.5272\n",
      "batch: 47380/60157............. Loss: 5.5246\n",
      "batch: 47400/60157............. Loss: 5.5179\n",
      "batch: 47420/60157............. Loss: 5.5202\n",
      "batch: 47440/60157............. Loss: 5.5190\n",
      "batch: 47460/60157............. Loss: 5.5259\n",
      "batch: 47480/60157............. Loss: 5.5283\n",
      "batch: 47500/60157............. Loss: 5.5264\n",
      "batch: 47520/60157............. Loss: 5.5234\n",
      "batch: 47540/60157............. Loss: 5.5236\n",
      "batch: 47560/60157............. Loss: 5.5164\n",
      "batch: 47580/60157............. Loss: 5.5268\n",
      "batch: 47600/60157............. Loss: 5.5259\n",
      "batch: 47620/60157............. Loss: 5.5206\n",
      "batch: 47640/60157............. Loss: 5.5243\n",
      "batch: 47660/60157............. Loss: 5.5244\n",
      "batch: 47680/60157............. Loss: 5.5275\n",
      "batch: 47700/60157............. Loss: 5.5261\n",
      "batch: 47720/60157............. Loss: 5.5274\n",
      "batch: 47740/60157............. Loss: 5.5249\n",
      "batch: 47760/60157............. Loss: 5.5202\n",
      "batch: 47780/60157............. Loss: 5.5293\n",
      "batch: 47800/60157............. Loss: 5.5237\n",
      "batch: 47820/60157............. Loss: 5.5258\n",
      "batch: 47840/60157............. Loss: 5.5225\n",
      "batch: 47860/60157............. Loss: 5.5187\n",
      "batch: 47880/60157............. Loss: 5.5306\n",
      "batch: 47900/60157............. Loss: 5.5310\n",
      "batch: 47920/60157............. Loss: 5.5180\n",
      "batch: 47940/60157............. Loss: 5.5249\n",
      "batch: 47960/60157............. Loss: 5.5246\n",
      "batch: 47980/60157............. Loss: 5.5246\n",
      "batch: 48000/60157............. Loss: 5.5274\n",
      "batch: 48020/60157............. Loss: 5.5199\n",
      "batch: 48040/60157............. Loss: 5.5252\n",
      "batch: 48060/60157............. Loss: 5.5239\n",
      "batch: 48080/60157............. Loss: 5.5215\n",
      "batch: 48100/60157............. Loss: 5.5249\n",
      "batch: 48120/60157............. Loss: 5.5263\n",
      "batch: 48140/60157............. Loss: 5.5245\n",
      "batch: 48160/60157............. Loss: 5.5264\n",
      "batch: 48180/60157............. Loss: 5.5280\n",
      "batch: 48200/60157............. Loss: 5.5276\n",
      "batch: 48220/60157............. Loss: 5.5256\n",
      "batch: 48240/60157............. Loss: 5.5273\n",
      "batch: 48260/60157............. Loss: 5.5241\n",
      "batch: 48280/60157............. Loss: 5.5274\n",
      "batch: 48300/60157............. Loss: 5.5256\n",
      "batch: 48320/60157............. Loss: 5.5253\n",
      "batch: 48340/60157............. Loss: 5.5250\n",
      "batch: 48360/60157............. Loss: 5.5235\n",
      "batch: 48380/60157............. Loss: 5.5240\n",
      "batch: 48400/60157............. Loss: 5.5231\n",
      "batch: 48420/60157............. Loss: 5.5262\n",
      "batch: 48440/60157............. Loss: 5.5250\n",
      "batch: 48460/60157............. Loss: 5.5249\n",
      "batch: 48480/60157............. Loss: 5.5220\n",
      "batch: 48500/60157............. Loss: 5.5229\n",
      "batch: 48520/60157............. Loss: 5.5266\n",
      "batch: 48540/60157............. Loss: 5.5268\n",
      "batch: 48560/60157............. Loss: 5.5268\n",
      "batch: 48580/60157............. Loss: 5.5222\n",
      "batch: 48600/60157............. Loss: 5.5267\n",
      "batch: 48620/60157............. Loss: 5.5294\n",
      "batch: 48640/60157............. Loss: 5.5307\n",
      "batch: 48660/60157............. Loss: 5.5215\n",
      "batch: 48680/60157............. Loss: 5.5274\n",
      "batch: 48700/60157............. Loss: 5.5239\n",
      "batch: 48720/60157............. Loss: 5.5266\n",
      "batch: 48740/60157............. Loss: 5.5258\n",
      "batch: 48760/60157............. Loss: 5.5271\n",
      "batch: 48780/60157............. Loss: 5.5225\n",
      "batch: 48800/60157............. Loss: 5.5274\n",
      "batch: 48820/60157............. Loss: 5.5316\n",
      "batch: 48840/60157............. Loss: 5.5240\n",
      "batch: 48860/60157............. Loss: 5.5247\n",
      "batch: 48880/60157............. Loss: 5.5214\n",
      "batch: 48900/60157............. Loss: 5.5266\n",
      "batch: 48920/60157............. Loss: 5.5288\n",
      "batch: 48940/60157............. Loss: 5.5292\n",
      "batch: 48960/60157............. Loss: 5.5289\n",
      "batch: 48980/60157............. Loss: 5.5270\n",
      "batch: 49000/60157............. Loss: 5.5222\n",
      "batch: 49020/60157............. Loss: 5.5259\n",
      "batch: 49040/60157............. Loss: 5.5291\n",
      "batch: 49060/60157............. Loss: 5.5270\n",
      "batch: 49080/60157............. Loss: 5.5247\n",
      "batch: 49100/60157............. Loss: 5.5189\n",
      "batch: 49120/60157............. Loss: 5.5296\n",
      "batch: 49140/60157............. Loss: 5.5266\n",
      "batch: 49160/60157............. Loss: 5.5249\n",
      "batch: 49180/60157............. Loss: 5.5292\n",
      "batch: 49200/60157............. Loss: 5.5247\n",
      "batch: 49220/60157............. Loss: 5.5287\n",
      "batch: 49240/60157............. Loss: 5.5264\n",
      "batch: 49260/60157............. Loss: 5.5316\n",
      "batch: 49280/60157............. Loss: 5.5213\n",
      "batch: 49300/60157............. Loss: 5.5254\n",
      "batch: 49320/60157............. Loss: 5.5251\n",
      "batch: 49340/60157............. Loss: 5.5262\n",
      "batch: 49360/60157............. Loss: 5.5248\n",
      "batch: 49380/60157............. Loss: 5.5243\n",
      "batch: 49400/60157............. Loss: 5.5255\n",
      "batch: 49420/60157............. Loss: 5.5245\n",
      "batch: 49440/60157............. Loss: 5.5247\n",
      "batch: 49460/60157............. Loss: 5.5232\n",
      "batch: 49480/60157............. Loss: 5.5278\n",
      "batch: 49500/60157............. Loss: 5.5247\n",
      "batch: 49520/60157............. Loss: 5.5291\n",
      "batch: 49540/60157............. Loss: 5.5228\n",
      "batch: 49560/60157............. Loss: 5.5282\n",
      "batch: 49580/60157............. Loss: 5.5247\n",
      "batch: 49600/60157............. Loss: 5.5263\n",
      "batch: 49620/60157............. Loss: 5.5276\n",
      "batch: 49640/60157............. Loss: 5.5151\n",
      "batch: 49660/60157............. Loss: 5.5267\n",
      "batch: 49680/60157............. Loss: 5.5279\n",
      "batch: 49700/60157............. Loss: 5.5241\n",
      "batch: 49720/60157............. Loss: 5.5249\n",
      "batch: 49740/60157............. Loss: 5.5290\n",
      "batch: 49760/60157............. Loss: 5.5262\n",
      "batch: 49780/60157............. Loss: 5.5231\n",
      "batch: 49800/60157............. Loss: 5.5243\n",
      "batch: 49820/60157............. Loss: 5.5244\n",
      "batch: 49840/60157............. Loss: 5.5265\n",
      "batch: 49860/60157............. Loss: 5.5252\n",
      "batch: 49880/60157............. Loss: 5.5261\n",
      "batch: 49900/60157............. Loss: 5.5249\n",
      "batch: 49920/60157............. Loss: 5.5296\n",
      "batch: 49940/60157............. Loss: 5.5278\n",
      "batch: 49960/60157............. Loss: 5.5251\n",
      "batch: 49980/60157............. Loss: 5.5238\n",
      "batch: 50000/60157............. Loss: 5.5277\n",
      "batch: 50020/60157............. Loss: 5.5184\n",
      "batch: 50040/60157............. Loss: 5.5284\n",
      "batch: 50060/60157............. Loss: 5.5273\n",
      "batch: 50080/60157............. Loss: 5.5276\n",
      "batch: 50100/60157............. Loss: 5.5201\n",
      "batch: 50120/60157............. Loss: 5.5289\n",
      "batch: 50140/60157............. Loss: 5.5278\n",
      "batch: 50160/60157............. Loss: 5.5219\n",
      "batch: 50180/60157............. Loss: 5.5286\n",
      "batch: 50200/60157............. Loss: 5.5244\n",
      "batch: 50220/60157............. Loss: 5.5247\n",
      "batch: 50240/60157............. Loss: 5.5258\n",
      "batch: 50260/60157............. Loss: 5.5260\n",
      "batch: 50280/60157............. Loss: 5.5241\n",
      "batch: 50300/60157............. Loss: 5.5235\n",
      "batch: 50320/60157............. Loss: 5.5259\n",
      "batch: 50340/60157............. Loss: 5.5199\n",
      "batch: 50360/60157............. Loss: 5.5268\n",
      "batch: 50380/60157............. Loss: 5.5263\n",
      "batch: 50400/60157............. Loss: 5.5256\n",
      "batch: 50420/60157............. Loss: 5.5253\n",
      "batch: 50440/60157............. Loss: 5.5267\n",
      "batch: 50460/60157............. Loss: 5.5294\n",
      "batch: 50480/60157............. Loss: 5.5221\n",
      "batch: 50500/60157............. Loss: 5.5259\n",
      "batch: 50520/60157............. Loss: 5.5242\n",
      "batch: 50540/60157............. Loss: 5.5272\n",
      "batch: 50560/60157............. Loss: 5.5224\n",
      "batch: 50580/60157............. Loss: 5.5264\n",
      "batch: 50600/60157............. Loss: 5.5256\n",
      "batch: 50620/60157............. Loss: 5.5278\n",
      "batch: 50640/60157............. Loss: 5.5203\n",
      "batch: 50660/60157............. Loss: 5.5279\n",
      "batch: 50680/60157............. Loss: 5.5218\n",
      "batch: 50700/60157............. Loss: 5.5222\n",
      "batch: 50720/60157............. Loss: 5.5238\n",
      "batch: 50740/60157............. Loss: 5.5278\n",
      "batch: 50760/60157............. Loss: 5.5241\n",
      "batch: 50780/60157............. Loss: 5.5214\n",
      "batch: 50800/60157............. Loss: 5.5253\n",
      "batch: 50820/60157............. Loss: 5.5299\n",
      "batch: 50840/60157............. Loss: 5.5279\n",
      "batch: 50860/60157............. Loss: 5.5252\n",
      "batch: 50880/60157............. Loss: 5.5263\n",
      "batch: 50900/60157............. Loss: 5.5230\n",
      "batch: 50920/60157............. Loss: 5.5245\n",
      "batch: 50940/60157............. Loss: 5.5239\n",
      "batch: 50960/60157............. Loss: 5.5248\n",
      "batch: 50980/60157............. Loss: 5.5245\n",
      "batch: 51000/60157............. Loss: 5.5215\n",
      "batch: 51020/60157............. Loss: 5.5223\n",
      "batch: 51040/60157............. Loss: 5.5214\n",
      "batch: 51060/60157............. Loss: 5.5239\n",
      "batch: 51080/60157............. Loss: 5.5256\n",
      "batch: 51100/60157............. Loss: 5.5293\n",
      "batch: 51120/60157............. Loss: 5.5278\n",
      "batch: 51140/60157............. Loss: 5.5267\n",
      "batch: 51160/60157............. Loss: 5.5211\n",
      "batch: 51180/60157............. Loss: 5.5258\n",
      "batch: 51200/60157............. Loss: 5.5227\n",
      "batch: 51220/60157............. Loss: 5.5266\n",
      "batch: 51240/60157............. Loss: 5.5252\n",
      "batch: 51260/60157............. Loss: 5.5279\n",
      "batch: 51280/60157............. Loss: 5.5279\n",
      "batch: 51300/60157............. Loss: 5.5250\n",
      "batch: 51320/60157............. Loss: 5.5272\n",
      "batch: 51340/60157............. Loss: 5.5254\n",
      "batch: 51360/60157............. Loss: 5.5220\n",
      "batch: 51380/60157............. Loss: 5.5231\n",
      "batch: 51400/60157............. Loss: 5.5269\n",
      "batch: 51420/60157............. Loss: 5.5230\n",
      "batch: 51440/60157............. Loss: 5.5253\n",
      "batch: 51460/60157............. Loss: 5.5261\n",
      "batch: 51480/60157............. Loss: 5.5291\n",
      "batch: 51500/60157............. Loss: 5.5252\n",
      "batch: 51520/60157............. Loss: 5.5273\n",
      "batch: 51540/60157............. Loss: 5.5276\n",
      "batch: 51560/60157............. Loss: 5.5263\n",
      "batch: 51580/60157............. Loss: 5.5200\n",
      "batch: 51600/60157............. Loss: 5.5249\n",
      "batch: 51620/60157............. Loss: 5.5298\n",
      "batch: 51640/60157............. Loss: 5.5292\n",
      "batch: 51660/60157............. Loss: 5.5255\n",
      "batch: 51680/60157............. Loss: 5.5255\n",
      "batch: 51700/60157............. Loss: 5.5262\n",
      "batch: 51720/60157............. Loss: 5.5226\n",
      "batch: 51740/60157............. Loss: 5.5227\n",
      "batch: 51760/60157............. Loss: 5.5276\n",
      "batch: 51780/60157............. Loss: 5.5240\n",
      "batch: 51800/60157............. Loss: 5.5278\n",
      "batch: 51820/60157............. Loss: 5.5236\n",
      "batch: 51840/60157............. Loss: 5.5272\n",
      "batch: 51860/60157............. Loss: 5.5256\n",
      "batch: 51880/60157............. Loss: 5.5243\n",
      "batch: 51900/60157............. Loss: 5.5248\n",
      "batch: 51920/60157............. Loss: 5.5238\n",
      "batch: 51940/60157............. Loss: 5.5239\n",
      "batch: 51960/60157............. Loss: 5.5238\n",
      "batch: 51980/60157............. Loss: 5.5280\n",
      "batch: 52000/60157............. Loss: 5.5287\n",
      "batch: 52020/60157............. Loss: 5.5256\n",
      "batch: 52040/60157............. Loss: 5.5249\n",
      "batch: 52060/60157............. Loss: 5.5265\n",
      "batch: 52080/60157............. Loss: 5.5234\n",
      "batch: 52100/60157............. Loss: 5.5260\n",
      "batch: 52120/60157............. Loss: 5.5271\n",
      "batch: 52140/60157............. Loss: 5.5287\n",
      "batch: 52160/60157............. Loss: 5.5250\n",
      "batch: 52180/60157............. Loss: 5.5284\n",
      "batch: 52200/60157............. Loss: 5.5245\n",
      "batch: 52220/60157............. Loss: 5.5268\n",
      "batch: 52240/60157............. Loss: 5.5279\n",
      "batch: 52260/60157............. Loss: 5.5206\n",
      "batch: 52280/60157............. Loss: 5.5239\n",
      "batch: 52300/60157............. Loss: 5.5246\n",
      "batch: 52320/60157............. Loss: 5.5237\n",
      "batch: 52340/60157............. Loss: 5.5226\n",
      "batch: 52360/60157............. Loss: 5.5225\n",
      "batch: 52380/60157............. Loss: 5.5233\n",
      "batch: 52400/60157............. Loss: 5.5258\n",
      "batch: 52420/60157............. Loss: 5.5233\n",
      "batch: 52440/60157............. Loss: 5.5275\n",
      "batch: 52460/60157............. Loss: 5.5262\n",
      "batch: 52480/60157............. Loss: 5.5261\n",
      "batch: 52500/60157............. Loss: 5.5273\n",
      "batch: 52520/60157............. Loss: 5.5271\n",
      "batch: 52540/60157............. Loss: 5.5199\n",
      "batch: 52560/60157............. Loss: 5.5234\n",
      "batch: 52580/60157............. Loss: 5.5168\n",
      "batch: 52600/60157............. Loss: 5.5265\n",
      "batch: 52620/60157............. Loss: 5.5259\n",
      "batch: 52640/60157............. Loss: 5.5281\n",
      "batch: 52660/60157............. Loss: 5.5281\n",
      "batch: 52680/60157............. Loss: 5.5292\n",
      "batch: 52700/60157............. Loss: 5.5257\n",
      "batch: 52720/60157............. Loss: 5.5237\n",
      "batch: 52740/60157............. Loss: 5.5256\n",
      "batch: 52760/60157............. Loss: 5.5275\n",
      "batch: 52780/60157............. Loss: 5.5251\n",
      "batch: 52800/60157............. Loss: 5.5203\n",
      "batch: 52820/60157............. Loss: 5.5229\n",
      "batch: 52840/60157............. Loss: 5.5238\n",
      "batch: 52860/60157............. Loss: 5.5311\n",
      "batch: 52880/60157............. Loss: 5.5266\n",
      "batch: 52900/60157............. Loss: 5.5278\n",
      "batch: 52920/60157............. Loss: 5.5304\n",
      "batch: 52940/60157............. Loss: 5.5249\n",
      "batch: 52960/60157............. Loss: 5.5230\n",
      "batch: 52980/60157............. Loss: 5.5284\n",
      "batch: 53000/60157............. Loss: 5.5267\n",
      "batch: 53020/60157............. Loss: 5.5228\n",
      "batch: 53040/60157............. Loss: 5.5237\n",
      "batch: 53060/60157............. Loss: 5.5270\n",
      "batch: 53080/60157............. Loss: 5.5262\n",
      "batch: 53100/60157............. Loss: 5.5256\n",
      "batch: 53120/60157............. Loss: 5.5218\n",
      "batch: 53140/60157............. Loss: 5.5314\n",
      "batch: 53160/60157............. Loss: 5.5255\n",
      "batch: 53180/60157............. Loss: 5.5293\n",
      "batch: 53200/60157............. Loss: 5.5217\n",
      "batch: 53220/60157............. Loss: 5.5240\n",
      "batch: 53240/60157............. Loss: 5.5217\n",
      "batch: 53260/60157............. Loss: 5.5290\n",
      "batch: 53280/60157............. Loss: 5.5261\n",
      "batch: 53300/60157............. Loss: 5.5278\n",
      "batch: 53320/60157............. Loss: 5.5215\n",
      "batch: 53340/60157............. Loss: 5.5231\n",
      "batch: 53360/60157............. Loss: 5.5261\n",
      "batch: 53380/60157............. Loss: 5.5221\n",
      "batch: 53400/60157............. Loss: 5.5281\n",
      "batch: 53420/60157............. Loss: 5.5245\n",
      "batch: 53440/60157............. Loss: 5.5238\n",
      "batch: 53460/60157............. Loss: 5.5192\n",
      "batch: 53480/60157............. Loss: 5.5259\n",
      "batch: 53500/60157............. Loss: 5.5262\n",
      "batch: 53520/60157............. Loss: 5.5304\n",
      "batch: 53540/60157............. Loss: 5.5269\n",
      "batch: 53560/60157............. Loss: 5.5239\n",
      "batch: 53580/60157............. Loss: 5.5246\n",
      "batch: 53600/60157............. Loss: 5.5232\n",
      "batch: 53620/60157............. Loss: 5.5221\n",
      "batch: 53640/60157............. Loss: 5.5246\n",
      "batch: 53660/60157............. Loss: 5.5293\n",
      "batch: 53680/60157............. Loss: 5.5267\n",
      "batch: 53700/60157............. Loss: 5.5257\n",
      "batch: 53720/60157............. Loss: 5.5257\n",
      "batch: 53740/60157............. Loss: 5.5243\n",
      "batch: 53760/60157............. Loss: 5.5248\n",
      "batch: 53780/60157............. Loss: 5.5284\n",
      "batch: 53800/60157............. Loss: 5.5238\n",
      "batch: 53820/60157............. Loss: 5.5257\n",
      "batch: 53840/60157............. Loss: 5.5254\n",
      "batch: 53860/60157............. Loss: 5.5230\n",
      "batch: 53880/60157............. Loss: 5.5194\n",
      "batch: 53900/60157............. Loss: 5.5265\n",
      "batch: 53920/60157............. Loss: 5.5235\n",
      "batch: 53940/60157............. Loss: 5.5215\n",
      "batch: 53960/60157............. Loss: 5.5231\n",
      "batch: 53980/60157............. Loss: 5.5268\n",
      "batch: 54000/60157............. Loss: 5.5254\n",
      "batch: 54020/60157............. Loss: 5.5271\n",
      "batch: 54040/60157............. Loss: 5.5193\n",
      "batch: 54060/60157............. Loss: 5.5262\n",
      "batch: 54080/60157............. Loss: 5.5261\n",
      "batch: 54100/60157............. Loss: 5.5263\n",
      "batch: 54120/60157............. Loss: 5.5235\n",
      "batch: 54140/60157............. Loss: 5.5229\n",
      "batch: 54160/60157............. Loss: 5.5239\n",
      "batch: 54180/60157............. Loss: 5.5265\n",
      "batch: 54200/60157............. Loss: 5.5303\n",
      "batch: 54220/60157............. Loss: 5.5254\n",
      "batch: 54240/60157............. Loss: 5.5250\n",
      "batch: 54260/60157............. Loss: 5.5196\n",
      "batch: 54280/60157............. Loss: 5.5290\n",
      "batch: 54300/60157............. Loss: 5.5283\n",
      "batch: 54320/60157............. Loss: 5.5274\n",
      "batch: 54340/60157............. Loss: 5.5279\n",
      "batch: 54360/60157............. Loss: 5.5246\n",
      "batch: 54380/60157............. Loss: 5.5243\n",
      "batch: 54400/60157............. Loss: 5.5286\n",
      "batch: 54420/60157............. Loss: 5.5241\n",
      "batch: 54440/60157............. Loss: 5.5258\n",
      "batch: 54460/60157............. Loss: 5.5292\n",
      "batch: 54480/60157............. Loss: 5.5247\n",
      "batch: 54500/60157............. Loss: 5.5239\n",
      "batch: 54520/60157............. Loss: 5.5196\n",
      "batch: 54540/60157............. Loss: 5.5264\n",
      "batch: 54560/60157............. Loss: 5.5240\n",
      "batch: 54580/60157............. Loss: 5.5264\n",
      "batch: 54600/60157............. Loss: 5.5208\n",
      "batch: 54620/60157............. Loss: 5.5269\n",
      "batch: 54640/60157............. Loss: 5.5262\n",
      "batch: 54660/60157............. Loss: 5.5285\n",
      "batch: 54680/60157............. Loss: 5.5236\n",
      "batch: 54700/60157............. Loss: 5.5240\n",
      "batch: 54720/60157............. Loss: 5.5233\n",
      "batch: 54740/60157............. Loss: 5.5244\n",
      "batch: 54760/60157............. Loss: 5.5253\n",
      "batch: 54780/60157............. Loss: 5.5194\n",
      "batch: 54800/60157............. Loss: 5.5293\n",
      "batch: 54820/60157............. Loss: 5.5278\n",
      "batch: 54840/60157............. Loss: 5.5238\n",
      "batch: 54860/60157............. Loss: 5.5269\n",
      "batch: 54880/60157............. Loss: 5.5266\n",
      "batch: 54900/60157............. Loss: 5.5269\n",
      "batch: 54920/60157............. Loss: 5.5252\n",
      "batch: 54940/60157............. Loss: 5.5262\n",
      "batch: 54960/60157............. Loss: 5.5229\n",
      "batch: 54980/60157............. Loss: 5.5258\n",
      "batch: 55000/60157............. Loss: 5.5263\n",
      "batch: 55020/60157............. Loss: 5.5222\n",
      "batch: 55040/60157............. Loss: 5.5258\n",
      "batch: 55060/60157............. Loss: 5.5254\n",
      "batch: 55080/60157............. Loss: 5.5218\n",
      "batch: 55100/60157............. Loss: 5.5235\n",
      "batch: 55120/60157............. Loss: 5.5255\n",
      "batch: 55140/60157............. Loss: 5.5282\n",
      "batch: 55160/60157............. Loss: 5.5287\n",
      "batch: 55180/60157............. Loss: 5.5257\n",
      "batch: 55200/60157............. Loss: 5.5284\n",
      "batch: 55220/60157............. Loss: 5.5270\n",
      "batch: 55240/60157............. Loss: 5.5267\n",
      "batch: 55260/60157............. Loss: 5.5281\n",
      "batch: 55280/60157............. Loss: 5.5217\n",
      "batch: 55300/60157............. Loss: 5.5267\n",
      "batch: 55320/60157............. Loss: 5.5251\n",
      "batch: 55340/60157............. Loss: 5.5228\n",
      "batch: 55360/60157............. Loss: 5.5272\n",
      "batch: 55380/60157............. Loss: 5.5273\n",
      "batch: 55400/60157............. Loss: 5.5245\n",
      "batch: 55420/60157............. Loss: 5.5255\n",
      "batch: 55440/60157............. Loss: 5.5242\n",
      "batch: 55460/60157............. Loss: 5.5263\n",
      "batch: 55480/60157............. Loss: 5.5238\n",
      "batch: 55500/60157............. Loss: 5.5285\n",
      "batch: 55520/60157............. Loss: 5.5223\n",
      "batch: 55540/60157............. Loss: 5.5269\n",
      "batch: 55560/60157............. Loss: 5.5300\n",
      "batch: 55580/60157............. Loss: 5.5247\n",
      "batch: 55600/60157............. Loss: 5.5273\n",
      "batch: 55620/60157............. Loss: 5.5229\n",
      "batch: 55640/60157............. Loss: 5.5180\n",
      "batch: 55660/60157............. Loss: 5.5221\n",
      "batch: 55680/60157............. Loss: 5.5223\n",
      "batch: 55700/60157............. Loss: 5.5254\n",
      "batch: 55720/60157............. Loss: 5.5213\n",
      "batch: 55740/60157............. Loss: 5.5312\n",
      "batch: 55760/60157............. Loss: 5.5248\n",
      "batch: 55780/60157............. Loss: 5.5311\n",
      "batch: 55800/60157............. Loss: 5.5286\n",
      "batch: 55820/60157............. Loss: 5.5266\n",
      "batch: 55840/60157............. Loss: 5.5273\n",
      "batch: 55860/60157............. Loss: 5.5215\n",
      "batch: 55880/60157............. Loss: 5.5253\n",
      "batch: 55900/60157............. Loss: 5.5244\n",
      "batch: 55920/60157............. Loss: 5.5215\n",
      "batch: 55940/60157............. Loss: 5.5252\n",
      "batch: 55960/60157............. Loss: 5.5177\n",
      "batch: 55980/60157............. Loss: 5.5263\n",
      "batch: 56000/60157............. Loss: 5.5250\n",
      "batch: 56020/60157............. Loss: 5.5280\n",
      "batch: 56040/60157............. Loss: 5.5183\n",
      "batch: 56060/60157............. Loss: 5.5244\n",
      "batch: 56080/60157............. Loss: 5.5237\n",
      "batch: 56100/60157............. Loss: 5.5237\n",
      "batch: 56120/60157............. Loss: 5.5226\n",
      "batch: 56140/60157............. Loss: 5.5242\n",
      "batch: 56160/60157............. Loss: 5.5243\n",
      "batch: 56180/60157............. Loss: 5.5296\n",
      "batch: 56200/60157............. Loss: 5.5244\n",
      "batch: 56220/60157............. Loss: 5.5284\n",
      "batch: 56240/60157............. Loss: 5.5285\n",
      "batch: 56260/60157............. Loss: 5.5204\n",
      "batch: 56280/60157............. Loss: 5.5298\n",
      "batch: 56300/60157............. Loss: 5.5260\n",
      "batch: 56320/60157............. Loss: 5.5267\n",
      "batch: 56340/60157............. Loss: 5.5234\n",
      "batch: 56360/60157............. Loss: 5.5218\n",
      "batch: 56380/60157............. Loss: 5.5208\n",
      "batch: 56400/60157............. Loss: 5.5253\n",
      "batch: 56420/60157............. Loss: 5.5256\n",
      "batch: 56440/60157............. Loss: 5.5260\n",
      "batch: 56460/60157............. Loss: 5.5212\n",
      "batch: 56480/60157............. Loss: 5.5229\n",
      "batch: 56500/60157............. Loss: 5.5266\n",
      "batch: 56520/60157............. Loss: 5.5263\n",
      "batch: 56540/60157............. Loss: 5.5280\n",
      "batch: 56560/60157............. Loss: 5.5242\n",
      "batch: 56580/60157............. Loss: 5.5284\n",
      "batch: 56600/60157............. Loss: 5.5267\n",
      "batch: 56620/60157............. Loss: 5.5273\n",
      "batch: 56640/60157............. Loss: 5.5267\n",
      "batch: 56660/60157............. Loss: 5.5299\n",
      "batch: 56680/60157............. Loss: 5.5214\n",
      "batch: 56700/60157............. Loss: 5.5232\n",
      "batch: 56720/60157............. Loss: 5.5287\n",
      "batch: 56740/60157............. Loss: 5.5256\n",
      "batch: 56760/60157............. Loss: 5.5254\n",
      "batch: 56780/60157............. Loss: 5.5244\n",
      "batch: 56800/60157............. Loss: 5.5224\n",
      "batch: 56820/60157............. Loss: 5.5237\n",
      "batch: 56840/60157............. Loss: 5.5290\n",
      "batch: 56860/60157............. Loss: 5.5271\n",
      "batch: 56880/60157............. Loss: 5.5245\n",
      "batch: 56900/60157............. Loss: 5.5253\n",
      "batch: 56920/60157............. Loss: 5.5209\n",
      "batch: 56940/60157............. Loss: 5.5255\n",
      "batch: 56960/60157............. Loss: 5.5216\n",
      "batch: 56980/60157............. Loss: 5.5229\n",
      "batch: 57000/60157............. Loss: 5.5286\n",
      "batch: 57020/60157............. Loss: 5.5238\n",
      "batch: 57040/60157............. Loss: 5.5278\n",
      "batch: 57060/60157............. Loss: 5.5237\n",
      "batch: 57080/60157............. Loss: 5.5275\n",
      "batch: 57100/60157............. Loss: 5.5211\n",
      "batch: 57120/60157............. Loss: 5.5243\n",
      "batch: 57140/60157............. Loss: 5.5241\n",
      "batch: 57160/60157............. Loss: 5.5251\n",
      "batch: 57180/60157............. Loss: 5.5294\n",
      "batch: 57200/60157............. Loss: 5.5282\n",
      "batch: 57220/60157............. Loss: 5.5224\n",
      "batch: 57240/60157............. Loss: 5.5250\n",
      "batch: 57260/60157............. Loss: 5.5244\n",
      "batch: 57280/60157............. Loss: 5.5259\n",
      "batch: 57300/60157............. Loss: 5.5248\n",
      "batch: 57320/60157............. Loss: 5.5210\n",
      "batch: 57340/60157............. Loss: 5.5252\n",
      "batch: 57360/60157............. Loss: 5.5251\n",
      "batch: 57380/60157............. Loss: 5.5220\n",
      "batch: 57400/60157............. Loss: 5.5223\n",
      "batch: 57420/60157............. Loss: 5.5271\n",
      "batch: 57440/60157............. Loss: 5.5258\n",
      "batch: 57460/60157............. Loss: 5.5291\n",
      "batch: 57480/60157............. Loss: 5.5234\n",
      "batch: 57500/60157............. Loss: 5.5228\n",
      "batch: 57520/60157............. Loss: 5.5278\n",
      "batch: 57540/60157............. Loss: 5.5230\n",
      "batch: 57560/60157............. Loss: 5.5225\n",
      "batch: 57580/60157............. Loss: 5.5244\n",
      "batch: 57600/60157............. Loss: 5.5273\n",
      "batch: 57620/60157............. Loss: 5.5262\n",
      "batch: 57640/60157............. Loss: 5.5270\n",
      "batch: 57660/60157............. Loss: 5.5252\n",
      "batch: 57680/60157............. Loss: 5.5219\n",
      "batch: 57700/60157............. Loss: 5.5239\n",
      "batch: 57720/60157............. Loss: 5.5296\n",
      "batch: 57740/60157............. Loss: 5.5228\n",
      "batch: 57760/60157............. Loss: 5.5294\n",
      "batch: 57780/60157............. Loss: 5.5263\n",
      "batch: 57800/60157............. Loss: 5.5226\n",
      "batch: 57820/60157............. Loss: 5.5264\n",
      "batch: 57840/60157............. Loss: 5.5260\n",
      "batch: 57860/60157............. Loss: 5.5256\n",
      "batch: 57880/60157............. Loss: 5.5248\n",
      "batch: 57900/60157............. Loss: 5.5229\n",
      "batch: 57920/60157............. Loss: 5.5217\n",
      "batch: 57940/60157............. Loss: 5.5251\n",
      "batch: 57960/60157............. Loss: 5.5291\n",
      "batch: 57980/60157............. Loss: 5.5281\n",
      "batch: 58000/60157............. Loss: 5.5214\n",
      "batch: 58020/60157............. Loss: 5.5233\n",
      "batch: 58040/60157............. Loss: 5.5265\n",
      "batch: 58060/60157............. Loss: 5.5239\n",
      "batch: 58080/60157............. Loss: 5.5250\n",
      "batch: 58100/60157............. Loss: 5.5304\n",
      "batch: 58120/60157............. Loss: 5.5257\n",
      "batch: 58140/60157............. Loss: 5.5225\n",
      "batch: 58160/60157............. Loss: 5.5223\n",
      "batch: 58180/60157............. Loss: 5.5255\n",
      "batch: 58200/60157............. Loss: 5.5226\n",
      "batch: 58220/60157............. Loss: 5.5216\n",
      "batch: 58240/60157............. Loss: 5.5246\n",
      "batch: 58260/60157............. Loss: 5.5214\n",
      "batch: 58280/60157............. Loss: 5.5268\n",
      "batch: 58300/60157............. Loss: 5.5246\n",
      "batch: 58320/60157............. Loss: 5.5281\n",
      "batch: 58340/60157............. Loss: 5.5225\n",
      "batch: 58360/60157............. Loss: 5.5244\n",
      "batch: 58380/60157............. Loss: 5.5223\n",
      "batch: 58400/60157............. Loss: 5.5257\n",
      "batch: 58420/60157............. Loss: 5.5233\n",
      "batch: 58440/60157............. Loss: 5.5230\n",
      "batch: 58460/60157............. Loss: 5.5256\n",
      "batch: 58480/60157............. Loss: 5.5291\n",
      "batch: 58500/60157............. Loss: 5.5250\n",
      "batch: 58520/60157............. Loss: 5.5273\n",
      "batch: 58540/60157............. Loss: 5.5288\n",
      "batch: 58560/60157............. Loss: 5.5239\n",
      "batch: 58580/60157............. Loss: 5.5276\n",
      "batch: 58600/60157............. Loss: 5.5204\n",
      "batch: 58620/60157............. Loss: 5.5207\n",
      "batch: 58640/60157............. Loss: 5.5257\n",
      "batch: 58660/60157............. Loss: 5.5263\n",
      "batch: 58680/60157............. Loss: 5.5195\n",
      "batch: 58700/60157............. Loss: 5.5278\n",
      "batch: 58720/60157............. Loss: 5.5262\n",
      "batch: 58740/60157............. Loss: 5.5254\n",
      "batch: 58760/60157............. Loss: 5.5247\n",
      "batch: 58780/60157............. Loss: 5.5262\n",
      "batch: 58800/60157............. Loss: 5.5259\n",
      "batch: 58820/60157............. Loss: 5.5249\n",
      "batch: 58840/60157............. Loss: 5.5227\n",
      "batch: 58860/60157............. Loss: 5.5252\n",
      "batch: 58880/60157............. Loss: 5.5283\n",
      "batch: 58900/60157............. Loss: 5.5262\n",
      "batch: 58920/60157............. Loss: 5.5283\n",
      "batch: 58940/60157............. Loss: 5.5251\n",
      "batch: 58960/60157............. Loss: 5.5216\n",
      "batch: 58980/60157............. Loss: 5.5239\n",
      "batch: 59000/60157............. Loss: 5.5245\n",
      "batch: 59020/60157............. Loss: 5.5258\n",
      "batch: 59040/60157............. Loss: 5.5241\n",
      "batch: 59060/60157............. Loss: 5.5254\n",
      "batch: 59080/60157............. Loss: 5.5276\n",
      "batch: 59100/60157............. Loss: 5.5282\n",
      "batch: 59120/60157............. Loss: 5.5274\n",
      "batch: 59140/60157............. Loss: 5.5285\n",
      "batch: 59160/60157............. Loss: 5.5296\n",
      "batch: 59180/60157............. Loss: 5.5291\n",
      "batch: 59200/60157............. Loss: 5.5235\n",
      "batch: 59220/60157............. Loss: 5.5276\n",
      "batch: 59240/60157............. Loss: 5.5262\n",
      "batch: 59260/60157............. Loss: 5.5294\n",
      "batch: 59280/60157............. Loss: 5.5253\n",
      "batch: 59300/60157............. Loss: 5.5237\n",
      "batch: 59320/60157............. Loss: 5.5243\n",
      "batch: 59340/60157............. Loss: 5.5250\n",
      "batch: 59360/60157............. Loss: 5.5273\n",
      "batch: 59380/60157............. Loss: 5.5237\n",
      "batch: 59400/60157............. Loss: 5.5261\n",
      "batch: 59420/60157............. Loss: 5.5227\n",
      "batch: 59440/60157............. Loss: 5.5241\n",
      "batch: 59460/60157............. Loss: 5.5247\n",
      "batch: 59480/60157............. Loss: 5.5227\n",
      "batch: 59500/60157............. Loss: 5.5240\n",
      "batch: 59520/60157............. Loss: 5.5279\n",
      "batch: 59540/60157............. Loss: 5.5215\n",
      "batch: 59560/60157............. Loss: 5.5299\n",
      "batch: 59580/60157............. Loss: 5.5280\n",
      "batch: 59600/60157............. Loss: 5.5259\n",
      "batch: 59620/60157............. Loss: 5.5263\n",
      "batch: 59640/60157............. Loss: 5.5243\n",
      "batch: 59660/60157............. Loss: 5.5254\n",
      "batch: 59680/60157............. Loss: 5.5289\n",
      "batch: 59700/60157............. Loss: 5.5281\n",
      "batch: 59720/60157............. Loss: 5.5289\n",
      "batch: 59740/60157............. Loss: 5.5247\n",
      "batch: 59760/60157............. Loss: 5.5238\n",
      "batch: 59780/60157............. Loss: 5.5269\n",
      "batch: 59800/60157............. Loss: 5.5227\n",
      "batch: 59820/60157............. Loss: 5.5234\n",
      "batch: 59840/60157............. Loss: 5.5242\n",
      "batch: 59860/60157............. Loss: 5.5288\n",
      "batch: 59880/60157............. Loss: 5.5271\n",
      "batch: 59900/60157............. Loss: 5.5261\n",
      "batch: 59920/60157............. Loss: 5.5241\n",
      "batch: 59940/60157............. Loss: 5.5271\n",
      "batch: 59960/60157............. Loss: 5.5269\n",
      "batch: 59980/60157............. Loss: 5.5286\n",
      "batch: 60000/60157............. Loss: 5.5247\n",
      "batch: 60020/60157............. Loss: 5.5280\n",
      "batch: 60040/60157............. Loss: 5.5237\n",
      "batch: 60060/60157............. Loss: 5.5227\n",
      "batch: 60080/60157............. Loss: 5.5248\n",
      "batch: 60100/60157............. Loss: 5.5210\n",
      "batch: 60120/60157............. Loss: 5.5244\n",
      "batch: 60140/60157............. Loss: 5.5258\n",
      "batch: 60160/60157............. Loss: 5.5266\n",
      "Epoch: 1/1............. Loss: 5.5266\n",
      "CPU times: user 3h 45min 33s, sys: 21min 43s, total: 4h 7min 16s\n",
      "Wall time: 3h 14min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs=1\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad()\n",
    "        input_seq = input_seq.cuda()\n",
    "        target_seq = target_seq.cuda()\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_batch += BATCH_SIZE\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fdbbdc-aa80-4a68-96aa-a139bff2feea",
   "metadata": {},
   "source": [
    "Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1f837-1c66-4509-b50d-557cabcaa2de",
   "metadata": {},
   "source": [
    "torch.save(model, \"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac19436-32bb-4008-9161-2324ec5e0b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46, device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14295/988621426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14295/2951704310.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(input_seq, target_seq)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mn_value\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "evaluation(input_seq, target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e967a-bb3b-47bc-ad70-8613b3d89344",
   "metadata": {},
   "source": [
    "## **2. LSTM con audio como input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee769bf5-5333-4e03-b20e-5b0283beb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalVideoDatasetAprox1(set_selected=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fa384d-0bcf-4e84-93ea-8393b6b82b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con 60157 instancias con las que poder trabajar\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar\"%(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405f186-3ce7-40c3-8a1e-56604ea32d03",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9f558f-3413-4fd9-80ff-30d378c620e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e576d54-8a0b-4aaa-a6dd-d73d9f4bd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox2(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(0)\n",
    "model.cuda()\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eca6e2-6389-4f3c-9935-8ed6248d764d",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea3ac52-4bc7-4cbc-bf0b-f901ce396dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa79e4-4946-4043-8ef4-61048ed10494",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc24871-7806-46a0-ad67-f0a5d7a722ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos_mds/train/../src/Dataset.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sound_frames = torch.tensor(sound_frames, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 20/60157............. Loss: 5.5457\n",
      "batch: 40/60157............. Loss: 5.5453\n",
      "batch: 60/60157............. Loss: 5.5450\n",
      "batch: 80/60157............. Loss: 5.5440\n",
      "batch: 100/60157............. Loss: 5.5442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid new backstep -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 120/60157............. Loss: 5.5423\n",
      "batch: 140/60157............. Loss: 5.5408\n",
      "batch: 160/60157............. Loss: 5.5385\n",
      "batch: 180/60157............. Loss: 5.5395\n",
      "batch: 200/60157............. Loss: 5.5384\n",
      "batch: 220/60157............. Loss: 5.5370\n",
      "batch: 240/60157............. Loss: 5.5396\n",
      "batch: 260/60157............. Loss: 5.5374\n",
      "batch: 280/60157............. Loss: 5.5378\n",
      "batch: 300/60157............. Loss: 5.5340\n",
      "batch: 320/60157............. Loss: 5.5372\n",
      "batch: 340/60157............. Loss: 5.5355\n",
      "batch: 360/60157............. Loss: 5.5370\n",
      "batch: 380/60157............. Loss: 5.5327\n",
      "batch: 400/60157............. Loss: 5.5349\n",
      "batch: 420/60157............. Loss: 5.5348\n",
      "batch: 440/60157............. Loss: 5.5351\n",
      "batch: 460/60157............. Loss: 5.5338\n",
      "batch: 480/60157............. Loss: 5.5357\n",
      "batch: 500/60157............. Loss: 5.5306\n",
      "batch: 520/60157............. Loss: 5.5338\n",
      "batch: 540/60157............. Loss: 5.5319\n",
      "batch: 560/60157............. Loss: 5.5372\n",
      "batch: 580/60157............. Loss: 5.5314\n",
      "batch: 600/60157............. Loss: 5.5325\n",
      "batch: 620/60157............. Loss: 5.5326\n",
      "batch: 640/60157............. Loss: 5.5319\n",
      "batch: 660/60157............. Loss: 5.5314\n",
      "batch: 680/60157............. Loss: 5.5321\n",
      "batch: 700/60157............. Loss: 5.5319\n",
      "batch: 720/60157............. Loss: 5.5320\n",
      "batch: 740/60157............. Loss: 5.5299\n",
      "batch: 760/60157............. Loss: 5.5333\n",
      "batch: 780/60157............. Loss: 5.5319\n",
      "batch: 800/60157............. Loss: 5.5295\n",
      "batch: 820/60157............. Loss: 5.5310\n",
      "batch: 840/60157............. Loss: 5.5135\n",
      "batch: 860/60157............. Loss: 5.5262\n",
      "batch: 880/60157............. Loss: 5.5282\n",
      "batch: 900/60157............. Loss: 5.5298\n",
      "batch: 920/60157............. Loss: 5.5233\n",
      "batch: 940/60157............. Loss: 5.5314\n",
      "batch: 960/60157............. Loss: 5.5301\n",
      "batch: 980/60157............. Loss: 5.5273\n",
      "batch: 1000/60157............. Loss: 5.5256\n",
      "batch: 1020/60157............. Loss: 5.5287\n",
      "batch: 1040/60157............. Loss: 5.5162\n",
      "batch: 1060/60157............. Loss: 5.5227\n",
      "batch: 1080/60157............. Loss: 5.5122\n",
      "batch: 1100/60157............. Loss: 5.4857\n",
      "batch: 1120/60157............. Loss: 5.5262\n",
      "batch: 1140/60157............. Loss: 5.5063\n",
      "batch: 1160/60157............. Loss: 5.5266\n",
      "batch: 1180/60157............. Loss: 5.5305\n",
      "batch: 1200/60157............. Loss: 5.5282\n",
      "batch: 1220/60157............. Loss: 5.4713\n",
      "batch: 1240/60157............. Loss: 5.5302\n",
      "batch: 1260/60157............. Loss: 5.5252\n",
      "batch: 1280/60157............. Loss: 5.5100\n",
      "batch: 1300/60157............. Loss: 5.5193\n",
      "batch: 1320/60157............. Loss: 5.5306\n",
      "batch: 1340/60157............. Loss: 5.5225\n",
      "batch: 1360/60157............. Loss: 5.5291\n",
      "batch: 1380/60157............. Loss: 5.5262\n",
      "batch: 1400/60157............. Loss: 5.5307\n",
      "batch: 1420/60157............. Loss: 5.5324\n",
      "batch: 1440/60157............. Loss: 5.5274\n",
      "batch: 1460/60157............. Loss: 5.5233\n",
      "batch: 1480/60157............. Loss: 5.5176\n",
      "batch: 1500/60157............. Loss: 5.5269\n",
      "batch: 1520/60157............. Loss: 5.5283\n",
      "batch: 1540/60157............. Loss: 5.5255\n",
      "batch: 1560/60157............. Loss: 5.5276\n",
      "batch: 1580/60157............. Loss: 5.5277\n",
      "batch: 1600/60157............. Loss: 5.5190\n",
      "batch: 1620/60157............. Loss: 5.5261\n",
      "batch: 1640/60157............. Loss: 5.5219\n",
      "batch: 1660/60157............. Loss: 5.5196\n",
      "batch: 1680/60157............. Loss: 5.5279\n",
      "batch: 1700/60157............. Loss: 5.5253\n",
      "batch: 1720/60157............. Loss: 5.5300\n",
      "batch: 1740/60157............. Loss: 5.5223\n",
      "batch: 1760/60157............. Loss: 5.5257\n",
      "batch: 1780/60157............. Loss: 5.5266\n",
      "batch: 1800/60157............. Loss: 5.5221\n",
      "batch: 1820/60157............. Loss: 5.5272\n",
      "batch: 1840/60157............. Loss: 5.5283\n",
      "batch: 1860/60157............. Loss: 5.5255\n",
      "batch: 1880/60157............. Loss: 5.5066\n",
      "batch: 1900/60157............. Loss: 5.5247\n",
      "batch: 1920/60157............. Loss: 5.5044\n",
      "batch: 1940/60157............. Loss: 5.5267\n",
      "batch: 1960/60157............. Loss: 5.5181\n",
      "batch: 1980/60157............. Loss: 5.5256\n",
      "batch: 2000/60157............. Loss: 5.5255\n",
      "batch: 2020/60157............. Loss: 5.5257\n",
      "batch: 2040/60157............. Loss: 5.5256\n",
      "batch: 2060/60157............. Loss: 5.5251\n",
      "batch: 2080/60157............. Loss: 5.5092\n",
      "batch: 2100/60157............. Loss: 5.4986\n",
      "batch: 2120/60157............. Loss: 5.5230\n",
      "batch: 2140/60157............. Loss: 5.5223\n",
      "batch: 2160/60157............. Loss: 5.5251\n",
      "batch: 2180/60157............. Loss: 5.5157\n",
      "batch: 2200/60157............. Loss: 5.5282\n",
      "batch: 2220/60157............. Loss: 5.5266\n",
      "batch: 2240/60157............. Loss: 5.5158\n",
      "batch: 2260/60157............. Loss: 5.5201\n",
      "batch: 2280/60157............. Loss: 5.5116\n",
      "batch: 2300/60157............. Loss: 5.5234\n",
      "batch: 2320/60157............. Loss: 5.5262\n",
      "batch: 2340/60157............. Loss: 5.5252\n",
      "batch: 2360/60157............. Loss: 5.5282\n",
      "batch: 2380/60157............. Loss: 5.4948\n",
      "batch: 2400/60157............. Loss: 5.5228\n",
      "batch: 2420/60157............. Loss: 5.5257\n",
      "batch: 2440/60157............. Loss: 5.5247\n",
      "batch: 2460/60157............. Loss: 5.5260\n",
      "batch: 2480/60157............. Loss: 5.4974\n",
      "batch: 2500/60157............. Loss: 5.5187\n",
      "batch: 2520/60157............. Loss: 5.5262\n",
      "batch: 2540/60157............. Loss: 5.5212\n",
      "batch: 2560/60157............. Loss: 5.5169\n",
      "batch: 2580/60157............. Loss: 5.4801\n",
      "batch: 2600/60157............. Loss: 5.5283\n",
      "batch: 2620/60157............. Loss: 5.4925\n",
      "batch: 2640/60157............. Loss: 5.5275\n",
      "batch: 2660/60157............. Loss: 5.5266\n",
      "batch: 2680/60157............. Loss: 5.4802\n",
      "batch: 2700/60157............. Loss: 5.5086\n",
      "batch: 2720/60157............. Loss: 5.5204\n",
      "batch: 2740/60157............. Loss: 5.4733\n",
      "batch: 2760/60157............. Loss: 5.5286\n",
      "batch: 2780/60157............. Loss: 5.5235\n",
      "batch: 2800/60157............. Loss: 5.5249\n",
      "batch: 2820/60157............. Loss: 5.4827\n",
      "batch: 2840/60157............. Loss: 5.5230\n",
      "batch: 2860/60157............. Loss: 5.5308\n",
      "batch: 2880/60157............. Loss: 5.5279\n",
      "batch: 2900/60157............. Loss: 5.5167\n",
      "batch: 2920/60157............. Loss: 5.5211\n",
      "batch: 2940/60157............. Loss: 5.4781\n",
      "batch: 2960/60157............. Loss: 5.5276\n",
      "batch: 2980/60157............. Loss: 5.5189\n",
      "batch: 3000/60157............. Loss: 5.5218\n",
      "batch: 3020/60157............. Loss: 5.5224\n",
      "batch: 3040/60157............. Loss: 5.5269\n",
      "batch: 3060/60157............. Loss: 5.5260\n",
      "batch: 3080/60157............. Loss: 5.5235\n",
      "batch: 3100/60157............. Loss: 5.5253\n",
      "batch: 3120/60157............. Loss: 5.5254\n",
      "batch: 3140/60157............. Loss: 5.5212\n",
      "batch: 3160/60157............. Loss: 5.5246\n",
      "batch: 3180/60157............. Loss: 5.5221\n",
      "batch: 3200/60157............. Loss: 5.4814\n",
      "batch: 3220/60157............. Loss: 5.5268\n",
      "batch: 3240/60157............. Loss: 5.5131\n",
      "batch: 3260/60157............. Loss: 5.5257\n",
      "batch: 3280/60157............. Loss: 5.5205\n",
      "batch: 3300/60157............. Loss: 5.5238\n",
      "batch: 3320/60157............. Loss: 5.5239\n",
      "batch: 3340/60157............. Loss: 5.5209\n",
      "batch: 3360/60157............. Loss: 5.4755\n",
      "batch: 3380/60157............. Loss: 5.5225\n",
      "batch: 3400/60157............. Loss: 5.5230\n",
      "batch: 3420/60157............. Loss: 5.5110\n",
      "batch: 3440/60157............. Loss: 5.5247\n",
      "batch: 3460/60157............. Loss: 5.5259\n",
      "batch: 3480/60157............. Loss: 5.5047\n",
      "batch: 3500/60157............. Loss: 5.5227\n",
      "batch: 3520/60157............. Loss: 5.5066\n",
      "batch: 3540/60157............. Loss: 5.5253\n",
      "batch: 3560/60157............. Loss: 5.5195\n",
      "batch: 3580/60157............. Loss: 5.5146\n",
      "batch: 3600/60157............. Loss: 5.5286\n",
      "batch: 3620/60157............. Loss: 5.5219\n",
      "batch: 3640/60157............. Loss: 5.5227\n",
      "batch: 3660/60157............. Loss: 5.5242\n",
      "batch: 3680/60157............. Loss: 5.5265\n",
      "batch: 3700/60157............. Loss: 5.5137\n",
      "batch: 3720/60157............. Loss: 5.5074\n",
      "batch: 3740/60157............. Loss: 5.5128\n",
      "batch: 3760/60157............. Loss: 5.5227\n",
      "batch: 3780/60157............. Loss: 5.4842\n",
      "batch: 3800/60157............. Loss: 5.5197\n",
      "batch: 3820/60157............. Loss: 5.5178\n",
      "batch: 3840/60157............. Loss: 5.5183\n",
      "batch: 3860/60157............. Loss: 5.4767\n",
      "batch: 3880/60157............. Loss: 5.5222\n",
      "batch: 3900/60157............. Loss: 5.5204\n",
      "batch: 3920/60157............. Loss: 5.5174\n",
      "batch: 3940/60157............. Loss: 5.5197\n",
      "batch: 3960/60157............. Loss: 5.4882\n",
      "batch: 3980/60157............. Loss: 5.5240\n",
      "batch: 4000/60157............. Loss: 5.5068\n",
      "batch: 4020/60157............. Loss: 5.5161\n",
      "batch: 4040/60157............. Loss: 5.5180\n",
      "batch: 4060/60157............. Loss: 5.4810\n",
      "batch: 4080/60157............. Loss: 5.5195\n",
      "batch: 4100/60157............. Loss: 5.5198\n",
      "batch: 4120/60157............. Loss: 5.5248\n",
      "batch: 4140/60157............. Loss: 5.5151\n",
      "batch: 4160/60157............. Loss: 5.5180\n",
      "batch: 4180/60157............. Loss: 5.5228\n",
      "batch: 4200/60157............. Loss: 5.5278\n",
      "batch: 4220/60157............. Loss: 5.5165\n",
      "batch: 4240/60157............. Loss: 5.5194\n",
      "batch: 4260/60157............. Loss: 5.5278\n",
      "batch: 4280/60157............. Loss: 5.5010\n",
      "batch: 4300/60157............. Loss: 5.5067\n",
      "batch: 4320/60157............. Loss: 5.4917\n",
      "batch: 4340/60157............. Loss: 5.5268\n",
      "batch: 4360/60157............. Loss: 5.5275\n",
      "batch: 4380/60157............. Loss: 5.5233\n",
      "batch: 4400/60157............. Loss: 5.5257\n",
      "batch: 4420/60157............. Loss: 5.5244\n",
      "batch: 4440/60157............. Loss: 5.5261\n",
      "batch: 4460/60157............. Loss: 5.5213\n",
      "batch: 4480/60157............. Loss: 5.4761\n",
      "batch: 4500/60157............. Loss: 5.5261\n",
      "batch: 4520/60157............. Loss: 5.5187\n",
      "batch: 4540/60157............. Loss: 5.5245\n",
      "batch: 4560/60157............. Loss: 5.5186\n",
      "batch: 4580/60157............. Loss: 5.5199\n",
      "batch: 4600/60157............. Loss: 5.5211\n",
      "batch: 4620/60157............. Loss: 5.5279\n",
      "batch: 4640/60157............. Loss: 5.5210\n",
      "batch: 4660/60157............. Loss: 5.5144\n",
      "batch: 4680/60157............. Loss: 5.5144\n",
      "batch: 4700/60157............. Loss: 5.5255\n",
      "batch: 4720/60157............. Loss: 5.5152\n",
      "batch: 4740/60157............. Loss: 5.5259\n",
      "batch: 4760/60157............. Loss: 5.4921\n",
      "batch: 4780/60157............. Loss: 5.5265\n",
      "batch: 4800/60157............. Loss: 5.5121\n",
      "batch: 4820/60157............. Loss: 5.5214\n",
      "batch: 4840/60157............. Loss: 5.5164\n",
      "batch: 4860/60157............. Loss: 5.5268\n",
      "batch: 4880/60157............. Loss: 5.4992\n",
      "batch: 4900/60157............. Loss: 5.4793\n",
      "batch: 4920/60157............. Loss: 5.5180\n",
      "batch: 4940/60157............. Loss: 5.5211\n",
      "batch: 4960/60157............. Loss: 5.5247\n",
      "batch: 4980/60157............. Loss: 5.5267\n",
      "batch: 5000/60157............. Loss: 5.5172\n",
      "batch: 5020/60157............. Loss: 5.5220\n",
      "batch: 5040/60157............. Loss: 5.5148\n",
      "batch: 5060/60157............. Loss: 5.5017\n",
      "batch: 5080/60157............. Loss: 5.5237\n",
      "batch: 5100/60157............. Loss: 5.5033\n",
      "batch: 5120/60157............. Loss: 5.5196\n",
      "batch: 5140/60157............. Loss: 5.5174\n",
      "batch: 5160/60157............. Loss: 5.5250\n",
      "batch: 5180/60157............. Loss: 5.5091\n",
      "batch: 5200/60157............. Loss: 5.5283\n",
      "batch: 5220/60157............. Loss: 5.5176\n",
      "batch: 5240/60157............. Loss: 5.4984\n",
      "batch: 5260/60157............. Loss: 5.5183\n",
      "batch: 5280/60157............. Loss: 5.5246\n",
      "batch: 5300/60157............. Loss: 5.5236\n",
      "batch: 5320/60157............. Loss: 5.5174\n",
      "batch: 5340/60157............. Loss: 5.5246\n",
      "batch: 5360/60157............. Loss: 5.5182\n",
      "batch: 5380/60157............. Loss: 5.5254\n",
      "batch: 5400/60157............. Loss: 5.5197\n",
      "batch: 5420/60157............. Loss: 5.4855\n",
      "batch: 5440/60157............. Loss: 5.5229\n",
      "batch: 5460/60157............. Loss: 5.5208\n",
      "batch: 5480/60157............. Loss: 5.5222\n",
      "batch: 5500/60157............. Loss: 5.5210\n",
      "batch: 5520/60157............. Loss: 5.4992\n",
      "batch: 5540/60157............. Loss: 5.4920\n",
      "batch: 5560/60157............. Loss: 5.4876\n",
      "batch: 5580/60157............. Loss: 5.5202\n",
      "batch: 5600/60157............. Loss: 5.5219\n",
      "batch: 5620/60157............. Loss: 5.5244\n",
      "batch: 5640/60157............. Loss: 5.5190\n",
      "batch: 5660/60157............. Loss: 5.5188\n",
      "batch: 5680/60157............. Loss: 5.5232\n",
      "batch: 5700/60157............. Loss: 5.5237\n",
      "batch: 5720/60157............. Loss: 5.5221\n",
      "batch: 5740/60157............. Loss: 5.5182\n",
      "batch: 5760/60157............. Loss: 5.5137\n",
      "batch: 5780/60157............. Loss: 5.5262\n",
      "batch: 5800/60157............. Loss: 5.5236\n",
      "batch: 5820/60157............. Loss: 5.5210\n",
      "batch: 5840/60157............. Loss: 5.5223\n",
      "batch: 5860/60157............. Loss: 5.4805\n",
      "batch: 5880/60157............. Loss: 5.4946\n",
      "batch: 5900/60157............. Loss: 5.5205\n",
      "batch: 5920/60157............. Loss: 5.5181\n",
      "batch: 5940/60157............. Loss: 5.5216\n",
      "batch: 5960/60157............. Loss: 5.5241\n",
      "batch: 5980/60157............. Loss: 5.4876\n",
      "batch: 6000/60157............. Loss: 5.5265\n",
      "batch: 6020/60157............. Loss: 5.5199\n",
      "batch: 6040/60157............. Loss: 5.5180\n",
      "batch: 6060/60157............. Loss: 5.5191\n",
      "batch: 6080/60157............. Loss: 5.5244\n",
      "batch: 6100/60157............. Loss: 5.5226\n",
      "batch: 6120/60157............. Loss: 5.5039\n",
      "batch: 6140/60157............. Loss: 5.4929\n",
      "batch: 6160/60157............. Loss: 5.5051\n",
      "batch: 6180/60157............. Loss: 5.5198\n",
      "batch: 6200/60157............. Loss: 5.5185\n",
      "batch: 6220/60157............. Loss: 5.5122\n",
      "batch: 6240/60157............. Loss: 5.5206\n",
      "batch: 6260/60157............. Loss: 5.5134\n",
      "batch: 6280/60157............. Loss: 5.5015\n",
      "batch: 6300/60157............. Loss: 5.5219\n",
      "batch: 6320/60157............. Loss: 5.4995\n",
      "batch: 6340/60157............. Loss: 5.5089\n",
      "batch: 6360/60157............. Loss: 5.4934\n",
      "batch: 6380/60157............. Loss: 5.5141\n",
      "batch: 6400/60157............. Loss: 5.5109\n",
      "batch: 6420/60157............. Loss: 5.5177\n",
      "batch: 6440/60157............. Loss: 5.5201\n",
      "batch: 6460/60157............. Loss: 5.4972\n",
      "batch: 6480/60157............. Loss: 5.5261\n",
      "batch: 6500/60157............. Loss: 5.5207\n",
      "batch: 6520/60157............. Loss: 5.5251\n",
      "batch: 6540/60157............. Loss: 5.5209\n",
      "batch: 6560/60157............. Loss: 5.5216\n",
      "batch: 6580/60157............. Loss: 5.5031\n",
      "batch: 6600/60157............. Loss: 5.5215\n",
      "batch: 6620/60157............. Loss: 5.5108\n",
      "batch: 6640/60157............. Loss: 5.5212\n",
      "batch: 6660/60157............. Loss: 5.5187\n",
      "batch: 6680/60157............. Loss: 5.5137\n",
      "batch: 6700/60157............. Loss: 5.5213\n",
      "batch: 6720/60157............. Loss: 5.4892\n",
      "batch: 6740/60157............. Loss: 5.5258\n",
      "batch: 6760/60157............. Loss: 5.5061\n",
      "batch: 6780/60157............. Loss: 5.5269\n",
      "batch: 6800/60157............. Loss: 5.5232\n",
      "batch: 6820/60157............. Loss: 5.5183\n",
      "batch: 6840/60157............. Loss: 5.4812\n",
      "batch: 6860/60157............. Loss: 5.4894\n",
      "batch: 6880/60157............. Loss: 5.5176\n",
      "batch: 6900/60157............. Loss: 5.5193\n",
      "batch: 6920/60157............. Loss: 5.5045\n",
      "batch: 6940/60157............. Loss: 5.4257\n",
      "batch: 6960/60157............. Loss: 5.5192\n",
      "batch: 6980/60157............. Loss: 5.5220\n",
      "batch: 7000/60157............. Loss: 5.5234\n",
      "batch: 7020/60157............. Loss: 5.5194\n",
      "batch: 7040/60157............. Loss: 5.5175\n",
      "batch: 7060/60157............. Loss: 5.5184\n",
      "batch: 7080/60157............. Loss: 5.5249\n",
      "batch: 7100/60157............. Loss: 5.5198\n",
      "batch: 7120/60157............. Loss: 5.5230\n",
      "batch: 7140/60157............. Loss: 5.5165\n",
      "batch: 7160/60157............. Loss: 5.5222\n",
      "batch: 7180/60157............. Loss: 5.5190\n",
      "batch: 7200/60157............. Loss: 5.5224\n",
      "batch: 7220/60157............. Loss: 5.5251\n",
      "batch: 7240/60157............. Loss: 5.5220\n",
      "batch: 7260/60157............. Loss: 5.5204\n",
      "batch: 7280/60157............. Loss: 5.5247\n",
      "batch: 7300/60157............. Loss: 5.5116\n",
      "batch: 7320/60157............. Loss: 5.5179\n",
      "batch: 7340/60157............. Loss: 5.5034\n",
      "batch: 7360/60157............. Loss: 5.5178\n",
      "batch: 7380/60157............. Loss: 5.5231\n",
      "batch: 7400/60157............. Loss: 5.5183\n",
      "batch: 7420/60157............. Loss: 5.5242\n",
      "batch: 7440/60157............. Loss: 5.5221\n",
      "batch: 7460/60157............. Loss: 5.5193\n",
      "batch: 7480/60157............. Loss: 5.5175\n",
      "batch: 7500/60157............. Loss: 5.5246\n",
      "batch: 7520/60157............. Loss: 5.5213\n",
      "batch: 7540/60157............. Loss: 5.5229\n",
      "batch: 7560/60157............. Loss: 5.5201\n",
      "batch: 7580/60157............. Loss: 5.4946\n",
      "batch: 7600/60157............. Loss: 5.5223\n",
      "batch: 7620/60157............. Loss: 5.5212\n",
      "batch: 7640/60157............. Loss: 5.4963\n",
      "batch: 7660/60157............. Loss: 5.5177\n",
      "batch: 7680/60157............. Loss: 5.4998\n",
      "batch: 7700/60157............. Loss: 5.5145\n",
      "batch: 7720/60157............. Loss: 5.5129\n",
      "batch: 7740/60157............. Loss: 5.5251\n",
      "batch: 7760/60157............. Loss: 5.5170\n",
      "batch: 7780/60157............. Loss: 5.5254\n",
      "batch: 7800/60157............. Loss: 5.5213\n",
      "batch: 7820/60157............. Loss: 5.5235\n",
      "batch: 7840/60157............. Loss: 5.5218\n",
      "batch: 7860/60157............. Loss: 5.5220\n",
      "batch: 7880/60157............. Loss: 5.5200\n",
      "batch: 7900/60157............. Loss: 5.5052\n",
      "batch: 7920/60157............. Loss: 5.5232\n",
      "batch: 7940/60157............. Loss: 5.5080\n",
      "batch: 7960/60157............. Loss: 5.4964\n",
      "batch: 7980/60157............. Loss: 5.4798\n",
      "batch: 8000/60157............. Loss: 5.4809\n",
      "batch: 8020/60157............. Loss: 5.5119\n",
      "batch: 8040/60157............. Loss: 5.5186\n",
      "batch: 8060/60157............. Loss: 5.5163\n",
      "batch: 8080/60157............. Loss: 5.5215\n",
      "batch: 8100/60157............. Loss: 5.4773\n",
      "batch: 8120/60157............. Loss: 5.5228\n",
      "batch: 8140/60157............. Loss: 5.5173\n",
      "batch: 8160/60157............. Loss: 5.5138\n",
      "batch: 8180/60157............. Loss: 5.5250\n",
      "batch: 8200/60157............. Loss: 5.5250\n",
      "batch: 8220/60157............. Loss: 5.5194\n",
      "batch: 8240/60157............. Loss: 5.5237\n",
      "batch: 8260/60157............. Loss: 5.5194\n",
      "batch: 8280/60157............. Loss: 5.5195\n",
      "batch: 8300/60157............. Loss: 5.5178\n",
      "batch: 8320/60157............. Loss: 5.5183\n",
      "batch: 8340/60157............. Loss: 5.4852\n",
      "batch: 8360/60157............. Loss: 5.5016\n",
      "batch: 8380/60157............. Loss: 5.5203\n",
      "batch: 8400/60157............. Loss: 5.4942\n",
      "batch: 8420/60157............. Loss: 5.5226\n",
      "batch: 8440/60157............. Loss: 5.5208\n",
      "batch: 8460/60157............. Loss: 5.5219\n",
      "batch: 8480/60157............. Loss: 5.5160\n",
      "batch: 8500/60157............. Loss: 5.5222\n",
      "batch: 8520/60157............. Loss: 5.5226\n",
      "batch: 8540/60157............. Loss: 5.5259\n",
      "batch: 8560/60157............. Loss: 5.5228\n",
      "batch: 8580/60157............. Loss: 5.5171\n",
      "batch: 8600/60157............. Loss: 5.5211\n",
      "batch: 8620/60157............. Loss: 5.5209\n",
      "batch: 8640/60157............. Loss: 5.5087\n",
      "batch: 8660/60157............. Loss: 5.5004\n",
      "batch: 8680/60157............. Loss: 5.5104\n",
      "batch: 8700/60157............. Loss: 5.5163\n",
      "batch: 8720/60157............. Loss: 5.5246\n",
      "batch: 8740/60157............. Loss: 5.4819\n",
      "batch: 8760/60157............. Loss: 5.5203\n",
      "batch: 8780/60157............. Loss: 5.5166\n",
      "batch: 8800/60157............. Loss: 5.4861\n",
      "batch: 8820/60157............. Loss: 5.5257\n",
      "batch: 8840/60157............. Loss: 5.5184\n",
      "batch: 8860/60157............. Loss: 5.5256\n",
      "batch: 8880/60157............. Loss: 5.5150\n",
      "batch: 8900/60157............. Loss: 5.5249\n",
      "batch: 8920/60157............. Loss: 5.5223\n",
      "batch: 8940/60157............. Loss: 5.5222\n",
      "batch: 8960/60157............. Loss: 5.5098\n",
      "batch: 8980/60157............. Loss: 5.5196\n",
      "batch: 9000/60157............. Loss: 5.4909\n",
      "batch: 9020/60157............. Loss: 5.5255\n",
      "batch: 9040/60157............. Loss: 5.5123\n",
      "batch: 9060/60157............. Loss: 5.4823\n",
      "batch: 9080/60157............. Loss: 5.5295\n",
      "batch: 9100/60157............. Loss: 5.5211\n",
      "batch: 9120/60157............. Loss: 5.5171\n",
      "batch: 9140/60157............. Loss: 5.4906\n",
      "batch: 9160/60157............. Loss: 5.5231\n",
      "batch: 9180/60157............. Loss: 5.5229\n",
      "batch: 9200/60157............. Loss: 5.5163\n",
      "batch: 9220/60157............. Loss: 5.5176\n",
      "batch: 9240/60157............. Loss: 5.5149\n",
      "batch: 9260/60157............. Loss: 5.5161\n",
      "batch: 9280/60157............. Loss: 5.5194\n",
      "batch: 9300/60157............. Loss: 5.5244\n",
      "batch: 9320/60157............. Loss: 5.5234\n",
      "batch: 9340/60157............. Loss: 5.5177\n",
      "batch: 9360/60157............. Loss: 5.5040\n",
      "batch: 9380/60157............. Loss: 5.5177\n",
      "batch: 9400/60157............. Loss: 5.5037\n",
      "batch: 9420/60157............. Loss: 5.5013\n",
      "batch: 9440/60157............. Loss: 5.5159\n",
      "batch: 9460/60157............. Loss: 5.4928\n",
      "batch: 9480/60157............. Loss: 5.5250\n",
      "batch: 9500/60157............. Loss: 5.5201\n",
      "batch: 9520/60157............. Loss: 5.5188\n",
      "batch: 9540/60157............. Loss: 5.5179\n",
      "batch: 9560/60157............. Loss: 5.5180\n",
      "batch: 9580/60157............. Loss: 5.5168\n",
      "batch: 9600/60157............. Loss: 5.5168\n",
      "batch: 9620/60157............. Loss: 5.5188\n",
      "batch: 9640/60157............. Loss: 5.5189\n",
      "batch: 9660/60157............. Loss: 5.5171\n",
      "batch: 9680/60157............. Loss: 5.5197\n",
      "batch: 9700/60157............. Loss: 5.5220\n",
      "batch: 9720/60157............. Loss: 5.5261\n",
      "batch: 9740/60157............. Loss: 5.5190\n",
      "batch: 9760/60157............. Loss: 5.5147\n",
      "batch: 9780/60157............. Loss: 5.5218\n",
      "batch: 9800/60157............. Loss: 5.4860\n",
      "batch: 9820/60157............. Loss: 5.5174\n",
      "batch: 9840/60157............. Loss: 5.5218\n",
      "batch: 9860/60157............. Loss: 5.4573\n",
      "batch: 9880/60157............. Loss: 5.5163\n",
      "batch: 9900/60157............. Loss: 5.4953\n",
      "batch: 9920/60157............. Loss: 5.5182\n",
      "batch: 9940/60157............. Loss: 5.5184\n",
      "batch: 9960/60157............. Loss: 5.5098\n",
      "batch: 9980/60157............. Loss: 5.5164\n",
      "batch: 10000/60157............. Loss: 5.5146\n",
      "batch: 10020/60157............. Loss: 5.5186\n",
      "batch: 10040/60157............. Loss: 5.5182\n",
      "batch: 10060/60157............. Loss: 5.5192\n",
      "batch: 10080/60157............. Loss: 5.5132\n",
      "batch: 10100/60157............. Loss: 5.5222\n",
      "batch: 10120/60157............. Loss: 5.5181\n",
      "batch: 10140/60157............. Loss: 5.4788\n",
      "batch: 10160/60157............. Loss: 5.5238\n",
      "batch: 10180/60157............. Loss: 5.5171\n",
      "batch: 10200/60157............. Loss: 5.5224\n",
      "batch: 10220/60157............. Loss: 5.5255\n",
      "batch: 10240/60157............. Loss: 5.4865\n",
      "batch: 10260/60157............. Loss: 5.5163\n",
      "batch: 10280/60157............. Loss: 5.4614\n",
      "batch: 10300/60157............. Loss: 5.5130\n",
      "batch: 10320/60157............. Loss: 5.5222\n",
      "batch: 10340/60157............. Loss: 5.5158\n",
      "batch: 10360/60157............. Loss: 5.5188\n",
      "batch: 10380/60157............. Loss: 5.5078\n",
      "batch: 10400/60157............. Loss: 5.5237\n",
      "batch: 10420/60157............. Loss: 5.5194\n",
      "batch: 10440/60157............. Loss: 5.5211\n",
      "batch: 10460/60157............. Loss: 5.5217\n",
      "batch: 10480/60157............. Loss: 5.5148\n",
      "batch: 10500/60157............. Loss: 5.5231\n",
      "batch: 10520/60157............. Loss: 5.5219\n",
      "batch: 10540/60157............. Loss: 5.5000\n",
      "batch: 10560/60157............. Loss: 5.5106\n",
      "batch: 10580/60157............. Loss: 5.5210\n",
      "batch: 10600/60157............. Loss: 5.5140\n",
      "batch: 10620/60157............. Loss: 5.5068\n",
      "batch: 10640/60157............. Loss: 5.5244\n",
      "batch: 10660/60157............. Loss: 5.5231\n",
      "batch: 10680/60157............. Loss: 5.5194\n",
      "batch: 10700/60157............. Loss: 5.4398\n",
      "batch: 10720/60157............. Loss: 5.5214\n",
      "batch: 10740/60157............. Loss: 5.5204\n",
      "batch: 10760/60157............. Loss: 5.5225\n",
      "batch: 10780/60157............. Loss: 5.5133\n",
      "batch: 10800/60157............. Loss: 5.5194\n",
      "batch: 10820/60157............. Loss: 5.5147\n",
      "batch: 10840/60157............. Loss: 5.5171\n",
      "batch: 10860/60157............. Loss: 5.5203\n",
      "batch: 10880/60157............. Loss: 5.5255\n",
      "batch: 10900/60157............. Loss: 5.5268\n",
      "batch: 10920/60157............. Loss: 5.5221\n",
      "batch: 10940/60157............. Loss: 5.5211\n",
      "batch: 10960/60157............. Loss: 5.5224\n",
      "batch: 10980/60157............. Loss: 5.5215\n",
      "batch: 11000/60157............. Loss: 5.5212\n",
      "batch: 11020/60157............. Loss: 5.5118\n",
      "batch: 11040/60157............. Loss: 5.5186\n",
      "batch: 11060/60157............. Loss: 5.5178\n",
      "batch: 11080/60157............. Loss: 5.5181\n",
      "batch: 11100/60157............. Loss: 5.5183\n",
      "batch: 11120/60157............. Loss: 5.5081\n",
      "batch: 11140/60157............. Loss: 5.5074\n",
      "batch: 11160/60157............. Loss: 5.5233\n",
      "batch: 11180/60157............. Loss: 5.5212\n",
      "batch: 11200/60157............. Loss: 5.5048\n",
      "batch: 11220/60157............. Loss: 5.5220\n",
      "batch: 11240/60157............. Loss: 5.5214\n",
      "batch: 11260/60157............. Loss: 5.5241\n",
      "batch: 11280/60157............. Loss: 5.5273\n",
      "batch: 11300/60157............. Loss: 5.5205\n",
      "batch: 11320/60157............. Loss: 5.5166\n",
      "batch: 11340/60157............. Loss: 5.5229\n",
      "batch: 11360/60157............. Loss: 5.4570\n",
      "batch: 11380/60157............. Loss: 5.5277\n",
      "batch: 11400/60157............. Loss: 5.5180\n",
      "batch: 11420/60157............. Loss: 5.5111\n",
      "batch: 11440/60157............. Loss: 5.5218\n",
      "batch: 11460/60157............. Loss: 5.5182\n",
      "batch: 11480/60157............. Loss: 5.5130\n",
      "batch: 11500/60157............. Loss: 5.5152\n",
      "batch: 11520/60157............. Loss: 5.5142\n",
      "batch: 11540/60157............. Loss: 5.5171\n",
      "batch: 11560/60157............. Loss: 5.5183\n",
      "batch: 11580/60157............. Loss: 5.5209\n",
      "batch: 11600/60157............. Loss: 5.5210\n",
      "batch: 11620/60157............. Loss: 5.5199\n",
      "batch: 11640/60157............. Loss: 5.5218\n",
      "batch: 11660/60157............. Loss: 5.5276\n",
      "batch: 11680/60157............. Loss: 5.5104\n",
      "batch: 11700/60157............. Loss: 5.5149\n",
      "batch: 11720/60157............. Loss: 5.4991\n",
      "batch: 11740/60157............. Loss: 5.5162\n",
      "batch: 11760/60157............. Loss: 5.5169\n",
      "batch: 11780/60157............. Loss: 5.5173\n",
      "batch: 11800/60157............. Loss: 5.5127\n",
      "batch: 11820/60157............. Loss: 5.5187\n",
      "batch: 11840/60157............. Loss: 5.5195\n",
      "batch: 11860/60157............. Loss: 5.5104\n",
      "batch: 11880/60157............. Loss: 5.5169\n",
      "batch: 11900/60157............. Loss: 5.5206\n",
      "batch: 11920/60157............. Loss: 5.5025\n",
      "batch: 11940/60157............. Loss: 5.5230\n",
      "batch: 11960/60157............. Loss: 5.5169\n",
      "batch: 11980/60157............. Loss: 5.5163\n",
      "batch: 12000/60157............. Loss: 5.5141\n",
      "batch: 12020/60157............. Loss: 5.5227\n",
      "batch: 12040/60157............. Loss: 5.5195\n",
      "batch: 12060/60157............. Loss: 5.4996\n",
      "batch: 12080/60157............. Loss: 5.5234\n",
      "batch: 12100/60157............. Loss: 5.5239\n",
      "batch: 12120/60157............. Loss: 5.4740\n",
      "batch: 12140/60157............. Loss: 5.4647\n",
      "batch: 12160/60157............. Loss: 5.5049\n",
      "batch: 12180/60157............. Loss: 5.5167\n",
      "batch: 12200/60157............. Loss: 5.5157\n",
      "batch: 12220/60157............. Loss: 5.5104\n",
      "batch: 12240/60157............. Loss: 5.5028\n",
      "batch: 12260/60157............. Loss: 5.5118\n",
      "batch: 12280/60157............. Loss: 5.5192\n",
      "batch: 12300/60157............. Loss: 5.5028\n",
      "batch: 12320/60157............. Loss: 5.5186\n",
      "batch: 12340/60157............. Loss: 5.4946\n",
      "batch: 12360/60157............. Loss: 5.5212\n",
      "batch: 12380/60157............. Loss: 5.5091\n",
      "batch: 12400/60157............. Loss: 5.5207\n",
      "batch: 12420/60157............. Loss: 5.5146\n",
      "batch: 12440/60157............. Loss: 5.5179\n",
      "batch: 12460/60157............. Loss: 5.5038\n",
      "batch: 12480/60157............. Loss: 5.5115\n",
      "batch: 12500/60157............. Loss: 5.5173\n",
      "batch: 12520/60157............. Loss: 5.4622\n",
      "batch: 12540/60157............. Loss: 5.5106\n",
      "batch: 12560/60157............. Loss: 5.4962\n",
      "batch: 12580/60157............. Loss: 5.5216\n",
      "batch: 12600/60157............. Loss: 5.4916\n",
      "batch: 12620/60157............. Loss: 5.5042\n",
      "batch: 12640/60157............. Loss: 5.5283\n",
      "batch: 12660/60157............. Loss: 5.5211\n",
      "batch: 12680/60157............. Loss: 5.5261\n",
      "batch: 12700/60157............. Loss: 5.5180\n",
      "batch: 12720/60157............. Loss: 5.5139\n",
      "batch: 12740/60157............. Loss: 5.5184\n",
      "batch: 12760/60157............. Loss: 5.4895\n",
      "batch: 12780/60157............. Loss: 5.5215\n",
      "batch: 12800/60157............. Loss: 5.5147\n",
      "batch: 12820/60157............. Loss: 5.5080\n",
      "batch: 12840/60157............. Loss: 5.4787\n",
      "batch: 12860/60157............. Loss: 5.4983\n",
      "batch: 12880/60157............. Loss: 5.4920\n",
      "batch: 12900/60157............. Loss: 5.4434\n",
      "batch: 12920/60157............. Loss: 5.5146\n",
      "batch: 12940/60157............. Loss: 5.4907\n",
      "batch: 12960/60157............. Loss: 5.5226\n",
      "batch: 12980/60157............. Loss: 5.5169\n",
      "batch: 13000/60157............. Loss: 5.5153\n",
      "batch: 13020/60157............. Loss: 5.5191\n",
      "batch: 13040/60157............. Loss: 5.5033\n",
      "batch: 13060/60157............. Loss: 5.5171\n",
      "batch: 13080/60157............. Loss: 5.5132\n",
      "batch: 13100/60157............. Loss: 5.5193\n",
      "batch: 13120/60157............. Loss: 5.5227\n",
      "batch: 13140/60157............. Loss: 5.5185\n",
      "batch: 13160/60157............. Loss: 5.5150\n",
      "batch: 13180/60157............. Loss: 5.5229\n",
      "batch: 13200/60157............. Loss: 5.5261\n",
      "batch: 13220/60157............. Loss: 5.5163\n",
      "batch: 13240/60157............. Loss: 5.5156\n",
      "batch: 13260/60157............. Loss: 5.5140\n",
      "batch: 13280/60157............. Loss: 5.5183\n",
      "batch: 13300/60157............. Loss: 5.5213\n",
      "batch: 13320/60157............. Loss: 5.5186\n",
      "batch: 13340/60157............. Loss: 5.5204\n",
      "batch: 13360/60157............. Loss: 5.5214\n",
      "batch: 13380/60157............. Loss: 5.5214\n",
      "batch: 13400/60157............. Loss: 5.5231\n",
      "batch: 13420/60157............. Loss: 5.5025\n",
      "batch: 13440/60157............. Loss: 5.5191\n",
      "batch: 13460/60157............. Loss: 5.5200\n",
      "batch: 13480/60157............. Loss: 5.5107\n",
      "batch: 13500/60157............. Loss: 5.5184\n",
      "batch: 13520/60157............. Loss: 5.5167\n",
      "batch: 13540/60157............. Loss: 5.5167\n",
      "batch: 13560/60157............. Loss: 5.5122\n",
      "batch: 13580/60157............. Loss: 5.5123\n",
      "batch: 13600/60157............. Loss: 5.5143\n",
      "batch: 13620/60157............. Loss: 5.5271\n",
      "batch: 13640/60157............. Loss: 5.5223\n",
      "batch: 13660/60157............. Loss: 5.5165\n",
      "batch: 13680/60157............. Loss: 5.5188\n",
      "batch: 13700/60157............. Loss: 5.5218\n",
      "batch: 13720/60157............. Loss: 5.5225\n",
      "batch: 13740/60157............. Loss: 5.5200\n",
      "batch: 13760/60157............. Loss: 5.5197\n",
      "batch: 13780/60157............. Loss: 5.5040\n",
      "batch: 13800/60157............. Loss: 5.5194\n",
      "batch: 13820/60157............. Loss: 5.5207\n",
      "batch: 13840/60157............. Loss: 5.5188\n",
      "batch: 13860/60157............. Loss: 5.5222\n",
      "batch: 13880/60157............. Loss: 5.5224\n",
      "batch: 13900/60157............. Loss: 5.5236\n",
      "batch: 13920/60157............. Loss: 5.5138\n",
      "batch: 13940/60157............. Loss: 5.5094\n",
      "batch: 13960/60157............. Loss: 5.5111\n",
      "batch: 13980/60157............. Loss: 5.5149\n",
      "batch: 14000/60157............. Loss: 5.5200\n",
      "batch: 14020/60157............. Loss: 5.5233\n",
      "batch: 14040/60157............. Loss: 5.5167\n",
      "batch: 14060/60157............. Loss: 5.5200\n",
      "batch: 14080/60157............. Loss: 5.5195\n",
      "batch: 14100/60157............. Loss: 5.4706\n",
      "batch: 14120/60157............. Loss: 5.5219\n",
      "batch: 14140/60157............. Loss: 5.5245\n",
      "batch: 14160/60157............. Loss: 5.4938\n",
      "batch: 14180/60157............. Loss: 5.5201\n",
      "batch: 14200/60157............. Loss: 5.4995\n",
      "batch: 14220/60157............. Loss: 5.4924\n",
      "batch: 14240/60157............. Loss: 5.5185\n",
      "batch: 14260/60157............. Loss: 5.5192\n",
      "batch: 14280/60157............. Loss: 5.5208\n",
      "batch: 14300/60157............. Loss: 5.4889\n",
      "batch: 14320/60157............. Loss: 5.5178\n",
      "batch: 14340/60157............. Loss: 5.5159\n",
      "batch: 14360/60157............. Loss: 5.5113\n",
      "batch: 14380/60157............. Loss: 5.5192\n",
      "batch: 14400/60157............. Loss: 5.5185\n",
      "batch: 14420/60157............. Loss: 5.5204\n",
      "batch: 14440/60157............. Loss: 5.5248\n",
      "batch: 14460/60157............. Loss: 5.5103\n",
      "batch: 14480/60157............. Loss: 5.5165\n",
      "batch: 14500/60157............. Loss: 5.5171\n",
      "batch: 14520/60157............. Loss: 5.5165\n",
      "batch: 14540/60157............. Loss: 5.5209\n",
      "batch: 14560/60157............. Loss: 5.5161\n",
      "batch: 14580/60157............. Loss: 5.5247\n",
      "batch: 14600/60157............. Loss: 5.5189\n",
      "batch: 14620/60157............. Loss: 5.5193\n",
      "batch: 14640/60157............. Loss: 5.5230\n",
      "batch: 14660/60157............. Loss: 5.5190\n",
      "batch: 14680/60157............. Loss: 5.5188\n",
      "batch: 14700/60157............. Loss: 5.5261\n",
      "batch: 14720/60157............. Loss: 5.5015\n",
      "batch: 14740/60157............. Loss: 5.5178\n",
      "batch: 14760/60157............. Loss: 5.5058\n",
      "batch: 14780/60157............. Loss: 5.5246\n",
      "batch: 14800/60157............. Loss: 5.5156\n",
      "batch: 14820/60157............. Loss: 5.4916\n",
      "batch: 14840/60157............. Loss: 5.5211\n",
      "batch: 14860/60157............. Loss: 5.5174\n",
      "batch: 14880/60157............. Loss: 5.5139\n",
      "batch: 14900/60157............. Loss: 5.5176\n",
      "batch: 14920/60157............. Loss: 5.5191\n",
      "batch: 14940/60157............. Loss: 5.5060\n",
      "batch: 14960/60157............. Loss: 5.5124\n",
      "batch: 14980/60157............. Loss: 5.5150\n",
      "batch: 15000/60157............. Loss: 5.5216\n",
      "batch: 15020/60157............. Loss: 5.5203\n",
      "batch: 15040/60157............. Loss: 5.5207\n",
      "batch: 15060/60157............. Loss: 5.5215\n",
      "batch: 15080/60157............. Loss: 5.5138\n",
      "batch: 15100/60157............. Loss: 5.5178\n",
      "batch: 15120/60157............. Loss: 5.5171\n",
      "batch: 15140/60157............. Loss: 5.5154\n",
      "batch: 15160/60157............. Loss: 5.5184\n",
      "batch: 15180/60157............. Loss: 5.5044\n",
      "batch: 15200/60157............. Loss: 5.5256\n",
      "batch: 15220/60157............. Loss: 5.5038\n",
      "batch: 15240/60157............. Loss: 5.5205\n",
      "batch: 15260/60157............. Loss: 5.5245\n",
      "batch: 15280/60157............. Loss: 5.5204\n",
      "batch: 15300/60157............. Loss: 5.5223\n",
      "batch: 15320/60157............. Loss: 5.5193\n",
      "batch: 15340/60157............. Loss: 5.4962\n",
      "batch: 15360/60157............. Loss: 5.5186\n",
      "batch: 15380/60157............. Loss: 5.4984\n",
      "batch: 15400/60157............. Loss: 5.4961\n",
      "batch: 15420/60157............. Loss: 5.4997\n",
      "batch: 15440/60157............. Loss: 5.5225\n",
      "batch: 15460/60157............. Loss: 5.5201\n",
      "batch: 15480/60157............. Loss: 5.5129\n",
      "batch: 15500/60157............. Loss: 5.5172\n",
      "batch: 15520/60157............. Loss: 5.5217\n",
      "batch: 15540/60157............. Loss: 5.4852\n",
      "batch: 15560/60157............. Loss: 5.5233\n",
      "batch: 15580/60157............. Loss: 5.5148\n",
      "batch: 15600/60157............. Loss: 5.5176\n",
      "batch: 15620/60157............. Loss: 5.5152\n",
      "batch: 15640/60157............. Loss: 5.5176\n",
      "batch: 15660/60157............. Loss: 5.5168\n",
      "batch: 15680/60157............. Loss: 5.5186\n",
      "batch: 15700/60157............. Loss: 5.5234\n",
      "batch: 15720/60157............. Loss: 5.5182\n",
      "batch: 15740/60157............. Loss: 5.5259\n",
      "batch: 15760/60157............. Loss: 5.5203\n",
      "batch: 15780/60157............. Loss: 5.5187\n",
      "batch: 15800/60157............. Loss: 5.5236\n",
      "batch: 15820/60157............. Loss: 5.4744\n",
      "batch: 15840/60157............. Loss: 5.5215\n",
      "batch: 15860/60157............. Loss: 5.4940\n",
      "batch: 15880/60157............. Loss: 5.5103\n",
      "batch: 15900/60157............. Loss: 5.4977\n",
      "batch: 15920/60157............. Loss: 5.5191\n",
      "batch: 15940/60157............. Loss: 5.5209\n",
      "batch: 15960/60157............. Loss: 5.5241\n",
      "batch: 15980/60157............. Loss: 5.5159\n",
      "batch: 16000/60157............. Loss: 5.5160\n",
      "batch: 16020/60157............. Loss: 5.5239\n",
      "batch: 16040/60157............. Loss: 5.5122\n",
      "batch: 16060/60157............. Loss: 5.5234\n",
      "batch: 16080/60157............. Loss: 5.5190\n",
      "batch: 16100/60157............. Loss: 5.5134\n",
      "batch: 16120/60157............. Loss: 5.5238\n",
      "batch: 16140/60157............. Loss: 5.4993\n",
      "batch: 16160/60157............. Loss: 5.5012\n",
      "batch: 16180/60157............. Loss: 5.4956\n",
      "batch: 16200/60157............. Loss: 5.5229\n",
      "batch: 16220/60157............. Loss: 5.4945\n",
      "batch: 16240/60157............. Loss: 5.5164\n",
      "batch: 16260/60157............. Loss: 5.5195\n",
      "batch: 16280/60157............. Loss: 5.5231\n",
      "batch: 16300/60157............. Loss: 5.5158\n",
      "batch: 16320/60157............. Loss: 5.5208\n",
      "batch: 16340/60157............. Loss: 5.5130\n",
      "batch: 16360/60157............. Loss: 5.5192\n",
      "batch: 16380/60157............. Loss: 5.5018\n",
      "batch: 16400/60157............. Loss: 5.5177\n",
      "batch: 16420/60157............. Loss: 5.5219\n",
      "batch: 16440/60157............. Loss: 5.5190\n",
      "batch: 16460/60157............. Loss: 5.5190\n",
      "batch: 16480/60157............. Loss: 5.5201\n",
      "batch: 16500/60157............. Loss: 5.5234\n",
      "batch: 16520/60157............. Loss: 5.5212\n",
      "batch: 16540/60157............. Loss: 5.5163\n",
      "batch: 16560/60157............. Loss: 5.5226\n",
      "batch: 16580/60157............. Loss: 5.5151\n",
      "batch: 16600/60157............. Loss: 5.5211\n",
      "batch: 16620/60157............. Loss: 5.5216\n",
      "batch: 16640/60157............. Loss: 5.4897\n",
      "batch: 16660/60157............. Loss: 5.5208\n",
      "batch: 16680/60157............. Loss: 5.5151\n",
      "batch: 16700/60157............. Loss: 5.5202\n",
      "batch: 16720/60157............. Loss: 5.5240\n",
      "batch: 16740/60157............. Loss: 5.5106\n",
      "batch: 16760/60157............. Loss: 5.5225\n",
      "batch: 16780/60157............. Loss: 5.4995\n",
      "batch: 16800/60157............. Loss: 5.5163\n",
      "batch: 16820/60157............. Loss: 5.5101\n",
      "batch: 16840/60157............. Loss: 5.5235\n",
      "batch: 16860/60157............. Loss: 5.4994\n",
      "batch: 16880/60157............. Loss: 5.5242\n",
      "batch: 16900/60157............. Loss: 5.5161\n",
      "batch: 16920/60157............. Loss: 5.5174\n",
      "batch: 16940/60157............. Loss: 5.5239\n",
      "batch: 16960/60157............. Loss: 5.4978\n",
      "batch: 16980/60157............. Loss: 5.5152\n",
      "batch: 17000/60157............. Loss: 5.4836\n",
      "batch: 17020/60157............. Loss: 5.5179\n",
      "batch: 17040/60157............. Loss: 5.4948\n",
      "batch: 17060/60157............. Loss: 5.5067\n",
      "batch: 17080/60157............. Loss: 5.5087\n",
      "batch: 17100/60157............. Loss: 5.5193\n",
      "batch: 17120/60157............. Loss: 5.5210\n",
      "batch: 17140/60157............. Loss: 5.4974\n",
      "batch: 17160/60157............. Loss: 5.5245\n",
      "batch: 17180/60157............. Loss: 5.5072\n",
      "batch: 17200/60157............. Loss: 5.5160\n",
      "batch: 17220/60157............. Loss: 5.5013\n",
      "batch: 17240/60157............. Loss: 5.5223\n",
      "batch: 17260/60157............. Loss: 5.4875\n",
      "batch: 17280/60157............. Loss: 5.5184\n",
      "batch: 17300/60157............. Loss: 5.5167\n",
      "batch: 17320/60157............. Loss: 5.5202\n",
      "batch: 17340/60157............. Loss: 5.5227\n",
      "batch: 17360/60157............. Loss: 5.5064\n",
      "batch: 17380/60157............. Loss: 5.5271\n",
      "batch: 17400/60157............. Loss: 5.5211\n",
      "batch: 17420/60157............. Loss: 5.5172\n",
      "batch: 17440/60157............. Loss: 5.5095\n",
      "batch: 17460/60157............. Loss: 5.5241\n",
      "batch: 17480/60157............. Loss: 5.5193\n",
      "batch: 17500/60157............. Loss: 5.4949\n",
      "batch: 17520/60157............. Loss: 5.5147\n",
      "batch: 17540/60157............. Loss: 5.5179\n",
      "batch: 17560/60157............. Loss: 5.4908\n",
      "batch: 17580/60157............. Loss: 5.5194\n",
      "batch: 17600/60157............. Loss: 5.5141\n",
      "batch: 17620/60157............. Loss: 5.4778\n",
      "batch: 17640/60157............. Loss: 5.5157\n",
      "batch: 17660/60157............. Loss: 5.4961\n",
      "batch: 17680/60157............. Loss: 5.5217\n",
      "batch: 17700/60157............. Loss: 5.5191\n",
      "batch: 17720/60157............. Loss: 5.4892\n",
      "batch: 17740/60157............. Loss: 5.5164\n",
      "batch: 17760/60157............. Loss: 5.5240\n",
      "batch: 17780/60157............. Loss: 5.5211\n",
      "batch: 17800/60157............. Loss: 5.5252\n",
      "batch: 17820/60157............. Loss: 5.5234\n",
      "batch: 17840/60157............. Loss: 5.5244\n",
      "batch: 17860/60157............. Loss: 5.4880\n",
      "batch: 17880/60157............. Loss: 5.5209\n",
      "batch: 17900/60157............. Loss: 5.5176\n",
      "batch: 17920/60157............. Loss: 5.5292\n",
      "batch: 17940/60157............. Loss: 5.4863\n",
      "batch: 17960/60157............. Loss: 5.5197\n",
      "batch: 17980/60157............. Loss: 5.4944\n",
      "batch: 18000/60157............. Loss: 5.4792\n",
      "batch: 18020/60157............. Loss: 5.5266\n",
      "batch: 18040/60157............. Loss: 5.5149\n",
      "batch: 18060/60157............. Loss: 5.5202\n",
      "batch: 18080/60157............. Loss: 5.5210\n",
      "batch: 18100/60157............. Loss: 5.5240\n",
      "batch: 18120/60157............. Loss: 5.5186\n",
      "batch: 18140/60157............. Loss: 5.5225\n",
      "batch: 18160/60157............. Loss: 5.5207\n",
      "batch: 18180/60157............. Loss: 5.5072\n",
      "batch: 18200/60157............. Loss: 5.5174\n",
      "batch: 18220/60157............. Loss: 5.5151\n",
      "batch: 18240/60157............. Loss: 5.5092\n",
      "batch: 18260/60157............. Loss: 5.5214\n",
      "batch: 18280/60157............. Loss: 5.5185\n",
      "batch: 18300/60157............. Loss: 5.5272\n",
      "batch: 18320/60157............. Loss: 5.5194\n",
      "batch: 18340/60157............. Loss: 5.5220\n",
      "batch: 18360/60157............. Loss: 5.5290\n",
      "batch: 18380/60157............. Loss: 5.5154\n",
      "batch: 18400/60157............. Loss: 5.5216\n",
      "batch: 18420/60157............. Loss: 5.5269\n",
      "batch: 18440/60157............. Loss: 5.5205\n",
      "batch: 18460/60157............. Loss: 5.5216\n",
      "batch: 18480/60157............. Loss: 5.5126\n",
      "batch: 18500/60157............. Loss: 5.5246\n",
      "batch: 18520/60157............. Loss: 5.5161\n",
      "batch: 18540/60157............. Loss: 5.5270\n",
      "batch: 18560/60157............. Loss: 5.5123\n",
      "batch: 18580/60157............. Loss: 5.5129\n",
      "batch: 18600/60157............. Loss: 5.5204\n",
      "batch: 18620/60157............. Loss: 5.5235\n",
      "batch: 18640/60157............. Loss: 5.5179\n",
      "batch: 18660/60157............. Loss: 5.5276\n",
      "batch: 18680/60157............. Loss: 5.5027\n",
      "batch: 18700/60157............. Loss: 5.5115\n",
      "batch: 18720/60157............. Loss: 5.5139\n",
      "batch: 18740/60157............. Loss: 5.5235\n",
      "batch: 18760/60157............. Loss: 5.5284\n",
      "batch: 18780/60157............. Loss: 5.5256\n",
      "batch: 18800/60157............. Loss: 5.5258\n",
      "batch: 18820/60157............. Loss: 5.5217\n",
      "batch: 18840/60157............. Loss: 5.5199\n",
      "batch: 18860/60157............. Loss: 5.5204\n",
      "batch: 18880/60157............. Loss: 5.5134\n",
      "batch: 18900/60157............. Loss: 5.5175\n",
      "batch: 18920/60157............. Loss: 5.5186\n",
      "batch: 18940/60157............. Loss: 5.4980\n",
      "batch: 18960/60157............. Loss: 5.5159\n",
      "batch: 18980/60157............. Loss: 5.5260\n",
      "batch: 19000/60157............. Loss: 5.5212\n",
      "batch: 19020/60157............. Loss: 5.4860\n",
      "batch: 19040/60157............. Loss: 5.4961\n",
      "batch: 19060/60157............. Loss: 5.5220\n",
      "batch: 19080/60157............. Loss: 5.5185\n",
      "batch: 19100/60157............. Loss: 5.5224\n",
      "batch: 19120/60157............. Loss: 5.5200\n",
      "batch: 19140/60157............. Loss: 5.5214\n",
      "batch: 19160/60157............. Loss: 5.5222\n",
      "batch: 19180/60157............. Loss: 5.5184\n",
      "batch: 19200/60157............. Loss: 5.5220\n",
      "batch: 19220/60157............. Loss: 5.5245\n",
      "batch: 19240/60157............. Loss: 5.5223\n",
      "batch: 19260/60157............. Loss: 5.5135\n",
      "batch: 19280/60157............. Loss: 5.5262\n",
      "batch: 19300/60157............. Loss: 5.5146\n",
      "batch: 19320/60157............. Loss: 5.5203\n",
      "batch: 19340/60157............. Loss: 5.4897\n",
      "batch: 19360/60157............. Loss: 5.5010\n",
      "batch: 19380/60157............. Loss: 5.5032\n",
      "batch: 19400/60157............. Loss: 5.5196\n",
      "batch: 19420/60157............. Loss: 5.5200\n",
      "batch: 19440/60157............. Loss: 5.5236\n",
      "batch: 19460/60157............. Loss: 5.5179\n",
      "batch: 19480/60157............. Loss: 5.5115\n",
      "batch: 19500/60157............. Loss: 5.5194\n",
      "batch: 19520/60157............. Loss: 5.5188\n",
      "batch: 19540/60157............. Loss: 5.5247\n",
      "batch: 19560/60157............. Loss: 5.5152\n",
      "batch: 19580/60157............. Loss: 5.4836\n",
      "batch: 19600/60157............. Loss: 5.5251\n",
      "batch: 19620/60157............. Loss: 5.5187\n",
      "batch: 19640/60157............. Loss: 5.5216\n",
      "batch: 19660/60157............. Loss: 5.4731\n",
      "batch: 19680/60157............. Loss: 5.5143\n",
      "batch: 19700/60157............. Loss: 5.5098\n",
      "batch: 19720/60157............. Loss: 5.5031\n",
      "batch: 19740/60157............. Loss: 5.5237\n",
      "batch: 19760/60157............. Loss: 5.5259\n",
      "batch: 19780/60157............. Loss: 5.5182\n",
      "batch: 19800/60157............. Loss: 5.5261\n",
      "batch: 19820/60157............. Loss: 5.5110\n",
      "batch: 19840/60157............. Loss: 5.5229\n",
      "batch: 19860/60157............. Loss: 5.5170\n",
      "batch: 19880/60157............. Loss: 5.4807\n",
      "batch: 19900/60157............. Loss: 5.5265\n",
      "batch: 19920/60157............. Loss: 5.5174\n",
      "batch: 19940/60157............. Loss: 5.5252\n",
      "batch: 19960/60157............. Loss: 5.4970\n",
      "batch: 19980/60157............. Loss: 5.4599\n",
      "batch: 20000/60157............. Loss: 5.4832\n",
      "batch: 20020/60157............. Loss: 5.5189\n",
      "batch: 20040/60157............. Loss: 5.5216\n",
      "batch: 20060/60157............. Loss: 5.5133\n",
      "batch: 20080/60157............. Loss: 5.4385\n",
      "batch: 20100/60157............. Loss: 5.5085\n",
      "batch: 20120/60157............. Loss: 5.4883\n",
      "batch: 20140/60157............. Loss: 5.5234\n",
      "batch: 20160/60157............. Loss: 5.5222\n",
      "batch: 20180/60157............. Loss: 5.5115\n",
      "batch: 20200/60157............. Loss: 5.5108\n",
      "batch: 20220/60157............. Loss: 5.5224\n",
      "batch: 20240/60157............. Loss: 5.5148\n",
      "batch: 20260/60157............. Loss: 5.4952\n",
      "batch: 20280/60157............. Loss: 5.5176\n",
      "batch: 20300/60157............. Loss: 5.5197\n",
      "batch: 20320/60157............. Loss: 5.4976\n",
      "batch: 20340/60157............. Loss: 5.5239\n",
      "batch: 20360/60157............. Loss: 5.5047\n",
      "batch: 20380/60157............. Loss: 5.5218\n",
      "batch: 20400/60157............. Loss: 5.5238\n",
      "batch: 20420/60157............. Loss: 5.5072\n",
      "batch: 20440/60157............. Loss: 5.4900\n",
      "batch: 20460/60157............. Loss: 5.4559\n",
      "batch: 20480/60157............. Loss: 5.5183\n",
      "batch: 20500/60157............. Loss: 5.5267\n",
      "batch: 20520/60157............. Loss: 5.5100\n",
      "batch: 20540/60157............. Loss: 5.4826\n",
      "batch: 20560/60157............. Loss: 5.5234\n",
      "batch: 20580/60157............. Loss: 5.5225\n",
      "batch: 20600/60157............. Loss: 5.5195\n",
      "batch: 20620/60157............. Loss: 5.5240\n",
      "batch: 20640/60157............. Loss: 5.5167\n",
      "batch: 20660/60157............. Loss: 5.5210\n",
      "batch: 20680/60157............. Loss: 5.5174\n",
      "batch: 20700/60157............. Loss: 5.4756\n",
      "batch: 20720/60157............. Loss: 5.5219\n",
      "batch: 20740/60157............. Loss: 5.5087\n",
      "batch: 20760/60157............. Loss: 5.5000\n",
      "batch: 20780/60157............. Loss: 5.5169\n",
      "batch: 20800/60157............. Loss: 5.5117\n",
      "batch: 20820/60157............. Loss: 5.5018\n",
      "batch: 20840/60157............. Loss: 5.5143\n",
      "batch: 20860/60157............. Loss: 5.5122\n",
      "batch: 20880/60157............. Loss: 5.5251\n",
      "batch: 20900/60157............. Loss: 5.5110\n",
      "batch: 20920/60157............. Loss: 5.5177\n",
      "batch: 20940/60157............. Loss: 5.5060\n",
      "batch: 20960/60157............. Loss: 5.5062\n",
      "batch: 20980/60157............. Loss: 5.5182\n",
      "batch: 21000/60157............. Loss: 5.5229\n",
      "batch: 21020/60157............. Loss: 5.5185\n",
      "batch: 21040/60157............. Loss: 5.5189\n",
      "batch: 21060/60157............. Loss: 5.5161\n",
      "batch: 21080/60157............. Loss: 5.4802\n",
      "batch: 21100/60157............. Loss: 5.4983\n",
      "batch: 21120/60157............. Loss: 5.5201\n",
      "batch: 21140/60157............. Loss: 5.5018\n",
      "batch: 21160/60157............. Loss: 5.4986\n",
      "batch: 21180/60157............. Loss: 5.5149\n",
      "batch: 21200/60157............. Loss: 5.5254\n",
      "batch: 21220/60157............. Loss: 5.5148\n",
      "batch: 21240/60157............. Loss: 5.5202\n",
      "batch: 21260/60157............. Loss: 5.5232\n",
      "batch: 21280/60157............. Loss: 5.4716\n",
      "batch: 21300/60157............. Loss: 5.5187\n",
      "batch: 21320/60157............. Loss: 5.5180\n",
      "batch: 21340/60157............. Loss: 5.5164\n",
      "batch: 21360/60157............. Loss: 5.5205\n",
      "batch: 21380/60157............. Loss: 5.5208\n",
      "batch: 21400/60157............. Loss: 5.5194\n",
      "batch: 21420/60157............. Loss: 5.5194\n",
      "batch: 21440/60157............. Loss: 5.5111\n",
      "batch: 21460/60157............. Loss: 5.5152\n",
      "batch: 21480/60157............. Loss: 5.5163\n",
      "batch: 21500/60157............. Loss: 5.5165\n",
      "batch: 21520/60157............. Loss: 5.5218\n",
      "batch: 21540/60157............. Loss: 5.5225\n",
      "batch: 21560/60157............. Loss: 5.5075\n",
      "batch: 21580/60157............. Loss: 5.5173\n",
      "batch: 21600/60157............. Loss: 5.5127\n",
      "batch: 21620/60157............. Loss: 5.5125\n",
      "batch: 21640/60157............. Loss: 5.5163\n",
      "batch: 21660/60157............. Loss: 5.5188\n",
      "batch: 21680/60157............. Loss: 5.5124\n",
      "batch: 21700/60157............. Loss: 5.5251\n",
      "batch: 21720/60157............. Loss: 5.5175\n",
      "batch: 21740/60157............. Loss: 5.5231\n",
      "batch: 21760/60157............. Loss: 5.5211\n",
      "batch: 21780/60157............. Loss: 5.5228\n",
      "batch: 21800/60157............. Loss: 5.5162\n",
      "batch: 21820/60157............. Loss: 5.5158\n",
      "batch: 21840/60157............. Loss: 5.5125\n",
      "batch: 21860/60157............. Loss: 5.5126\n",
      "batch: 21880/60157............. Loss: 5.5176\n",
      "batch: 21900/60157............. Loss: 5.5226\n",
      "batch: 21920/60157............. Loss: 5.5153\n",
      "batch: 21940/60157............. Loss: 5.5038\n",
      "batch: 21960/60157............. Loss: 5.5214\n",
      "batch: 21980/60157............. Loss: 5.5159\n",
      "batch: 22000/60157............. Loss: 5.5215\n",
      "batch: 22020/60157............. Loss: 5.4754\n",
      "batch: 22040/60157............. Loss: 5.5142\n",
      "batch: 22060/60157............. Loss: 5.5209\n",
      "batch: 22080/60157............. Loss: 5.5171\n",
      "batch: 22100/60157............. Loss: 5.5116\n",
      "batch: 22120/60157............. Loss: 5.5117\n",
      "batch: 22140/60157............. Loss: 5.5231\n",
      "batch: 22160/60157............. Loss: 5.5181\n",
      "batch: 22180/60157............. Loss: 5.5093\n",
      "batch: 22200/60157............. Loss: 5.5158\n",
      "batch: 22220/60157............. Loss: 5.5175\n",
      "batch: 22240/60157............. Loss: 5.5076\n",
      "batch: 22260/60157............. Loss: 5.5155\n",
      "batch: 22280/60157............. Loss: 5.5189\n",
      "batch: 22300/60157............. Loss: 5.5221\n",
      "batch: 22320/60157............. Loss: 5.5193\n",
      "batch: 22340/60157............. Loss: 5.5071\n",
      "batch: 22360/60157............. Loss: 5.5129\n",
      "batch: 22380/60157............. Loss: 5.5211\n",
      "batch: 22400/60157............. Loss: 5.4862\n",
      "batch: 22420/60157............. Loss: 5.5092\n",
      "batch: 22440/60157............. Loss: 5.4623\n",
      "batch: 22460/60157............. Loss: 5.5097\n",
      "batch: 22480/60157............. Loss: 5.5207\n",
      "batch: 22500/60157............. Loss: 5.5237\n",
      "batch: 22520/60157............. Loss: 5.5210\n",
      "batch: 22540/60157............. Loss: 5.5124\n",
      "batch: 22560/60157............. Loss: 5.5233\n",
      "batch: 22580/60157............. Loss: 5.5221\n",
      "batch: 22600/60157............. Loss: 5.5158\n",
      "batch: 22620/60157............. Loss: 5.5106\n",
      "batch: 22640/60157............. Loss: 5.5196\n",
      "batch: 22660/60157............. Loss: 5.5193\n",
      "batch: 22680/60157............. Loss: 5.5059\n",
      "batch: 22700/60157............. Loss: 5.5238\n",
      "batch: 22720/60157............. Loss: 5.5190\n",
      "batch: 22740/60157............. Loss: 5.5183\n",
      "batch: 22760/60157............. Loss: 5.5155\n",
      "batch: 22780/60157............. Loss: 5.5030\n",
      "batch: 22800/60157............. Loss: 5.5170\n",
      "batch: 22820/60157............. Loss: 5.5191\n",
      "batch: 22840/60157............. Loss: 5.5181\n",
      "batch: 22860/60157............. Loss: 5.5128\n",
      "batch: 22880/60157............. Loss: 5.5192\n",
      "batch: 22900/60157............. Loss: 5.5198\n",
      "batch: 22920/60157............. Loss: 5.5229\n",
      "batch: 22940/60157............. Loss: 5.5112\n",
      "batch: 22960/60157............. Loss: 5.5212\n",
      "batch: 22980/60157............. Loss: 5.5122\n",
      "batch: 23000/60157............. Loss: 5.5208\n",
      "batch: 23020/60157............. Loss: 5.5160\n",
      "batch: 23040/60157............. Loss: 5.5207\n",
      "batch: 23060/60157............. Loss: 5.5164\n",
      "batch: 23080/60157............. Loss: 5.5025\n",
      "batch: 23100/60157............. Loss: 5.5236\n",
      "batch: 23120/60157............. Loss: 5.5128\n",
      "batch: 23140/60157............. Loss: 5.5172\n",
      "batch: 23160/60157............. Loss: 5.5216\n",
      "batch: 23180/60157............. Loss: 5.5192\n",
      "batch: 23200/60157............. Loss: 5.5233\n",
      "batch: 23220/60157............. Loss: 5.5171\n",
      "batch: 23240/60157............. Loss: 5.5206\n",
      "batch: 23260/60157............. Loss: 5.5134\n",
      "batch: 23280/60157............. Loss: 5.4890\n",
      "batch: 23300/60157............. Loss: 5.5207\n",
      "batch: 23320/60157............. Loss: 5.5083\n",
      "batch: 23340/60157............. Loss: 5.5208\n",
      "batch: 23360/60157............. Loss: 5.4974\n",
      "batch: 23380/60157............. Loss: 5.4946\n",
      "batch: 23400/60157............. Loss: 5.5233\n",
      "batch: 23420/60157............. Loss: 5.5219\n",
      "batch: 23440/60157............. Loss: 5.5109\n",
      "batch: 23460/60157............. Loss: 5.5175\n",
      "batch: 23480/60157............. Loss: 5.5203\n",
      "batch: 23500/60157............. Loss: 5.5191\n",
      "batch: 23520/60157............. Loss: 5.5155\n",
      "batch: 23540/60157............. Loss: 5.4865\n",
      "batch: 23560/60157............. Loss: 5.5120\n",
      "batch: 23580/60157............. Loss: 5.5168\n",
      "batch: 23600/60157............. Loss: 5.5258\n",
      "batch: 23620/60157............. Loss: 5.5176\n",
      "batch: 23640/60157............. Loss: 5.5158\n",
      "batch: 23660/60157............. Loss: 5.5220\n",
      "batch: 23680/60157............. Loss: 5.5166\n",
      "batch: 23700/60157............. Loss: 5.5131\n",
      "batch: 23720/60157............. Loss: 5.5117\n",
      "batch: 23740/60157............. Loss: 5.5168\n",
      "batch: 23760/60157............. Loss: 5.5171\n",
      "batch: 23780/60157............. Loss: 5.5240\n",
      "batch: 23800/60157............. Loss: 5.5174\n",
      "batch: 23820/60157............. Loss: 5.5194\n",
      "batch: 23840/60157............. Loss: 5.5173\n",
      "batch: 23860/60157............. Loss: 5.5186\n",
      "batch: 23880/60157............. Loss: 5.4781\n",
      "batch: 23900/60157............. Loss: 5.5136\n",
      "batch: 23920/60157............. Loss: 5.5064\n",
      "batch: 23940/60157............. Loss: 5.5115\n",
      "batch: 23960/60157............. Loss: 5.5268\n",
      "batch: 23980/60157............. Loss: 5.5097\n",
      "batch: 24000/60157............. Loss: 5.5234\n",
      "batch: 24020/60157............. Loss: 5.5183\n",
      "batch: 24040/60157............. Loss: 5.5253\n",
      "batch: 24060/60157............. Loss: 5.5236\n",
      "batch: 24080/60157............. Loss: 5.5147\n",
      "batch: 24100/60157............. Loss: 5.5205\n",
      "batch: 24120/60157............. Loss: 5.5001\n",
      "batch: 24140/60157............. Loss: 5.5208\n",
      "batch: 24160/60157............. Loss: 5.4717\n",
      "batch: 24180/60157............. Loss: 5.5231\n",
      "batch: 24200/60157............. Loss: 5.4898\n",
      "batch: 24220/60157............. Loss: 5.5153\n",
      "batch: 24240/60157............. Loss: 5.5231\n",
      "batch: 24260/60157............. Loss: 5.5206\n",
      "batch: 24280/60157............. Loss: 5.5089\n",
      "batch: 24300/60157............. Loss: 5.5217\n",
      "batch: 24320/60157............. Loss: 5.5208\n",
      "batch: 24340/60157............. Loss: 5.5216\n",
      "batch: 24360/60157............. Loss: 5.5159\n",
      "batch: 24380/60157............. Loss: 5.5210\n",
      "batch: 24400/60157............. Loss: 5.5180\n",
      "batch: 24420/60157............. Loss: 5.5058\n",
      "batch: 24440/60157............. Loss: 5.5137\n",
      "batch: 24460/60157............. Loss: 5.4982\n",
      "batch: 24480/60157............. Loss: 5.5220\n",
      "batch: 24500/60157............. Loss: 5.5047\n",
      "batch: 24520/60157............. Loss: 5.4688\n",
      "batch: 24540/60157............. Loss: 5.5154\n",
      "batch: 24560/60157............. Loss: 5.5147\n",
      "batch: 24580/60157............. Loss: 5.5208\n",
      "batch: 24600/60157............. Loss: 5.5155\n",
      "batch: 24620/60157............. Loss: 5.5146\n",
      "batch: 24640/60157............. Loss: 5.5190\n",
      "batch: 24660/60157............. Loss: 5.5161\n",
      "batch: 24680/60157............. Loss: 5.4973\n",
      "batch: 24700/60157............. Loss: 5.5160\n",
      "batch: 24720/60157............. Loss: 5.5166\n",
      "batch: 24740/60157............. Loss: 5.5174\n",
      "batch: 24760/60157............. Loss: 5.5181\n",
      "batch: 24780/60157............. Loss: 5.5223\n",
      "batch: 24800/60157............. Loss: 5.5232\n",
      "batch: 24820/60157............. Loss: 5.5004\n",
      "batch: 24840/60157............. Loss: 5.5210\n",
      "batch: 24860/60157............. Loss: 5.5190\n",
      "batch: 24880/60157............. Loss: 5.5085\n",
      "batch: 24900/60157............. Loss: 5.4961\n",
      "batch: 24920/60157............. Loss: 5.5231\n",
      "batch: 24940/60157............. Loss: 5.4984\n",
      "batch: 24960/60157............. Loss: 5.5158\n",
      "batch: 24980/60157............. Loss: 5.5167\n",
      "batch: 25000/60157............. Loss: 5.5209\n",
      "batch: 25020/60157............. Loss: 5.5168\n",
      "batch: 25040/60157............. Loss: 5.5116\n",
      "batch: 25060/60157............. Loss: 5.5153\n",
      "batch: 25080/60157............. Loss: 5.5154\n",
      "batch: 25100/60157............. Loss: 5.5146\n",
      "batch: 25120/60157............. Loss: 5.5183\n",
      "batch: 25140/60157............. Loss: 5.5208\n",
      "batch: 25160/60157............. Loss: 5.5030\n",
      "batch: 25180/60157............. Loss: 5.4859\n",
      "batch: 25200/60157............. Loss: 5.4956\n",
      "batch: 25220/60157............. Loss: 5.5175\n",
      "batch: 25240/60157............. Loss: 5.5141\n",
      "batch: 25260/60157............. Loss: 5.4988\n",
      "batch: 25280/60157............. Loss: 5.5178\n",
      "batch: 25300/60157............. Loss: 5.4823\n",
      "batch: 25320/60157............. Loss: 5.5224\n",
      "batch: 25340/60157............. Loss: 5.5073\n",
      "batch: 25360/60157............. Loss: 5.5218\n",
      "batch: 25380/60157............. Loss: 5.4878\n",
      "batch: 25400/60157............. Loss: 5.5142\n",
      "batch: 25420/60157............. Loss: 5.5139\n",
      "batch: 25440/60157............. Loss: 5.5207\n",
      "batch: 25460/60157............. Loss: 5.5195\n",
      "batch: 25480/60157............. Loss: 5.5132\n",
      "batch: 25500/60157............. Loss: 5.5220\n",
      "batch: 25520/60157............. Loss: 5.5200\n",
      "batch: 25540/60157............. Loss: 5.5131\n",
      "batch: 25560/60157............. Loss: 5.4715\n",
      "batch: 25580/60157............. Loss: 5.5104\n",
      "batch: 25600/60157............. Loss: 5.5199\n",
      "batch: 25620/60157............. Loss: 5.5231\n",
      "batch: 25640/60157............. Loss: 5.5110\n",
      "batch: 25660/60157............. Loss: 5.5248\n",
      "batch: 25680/60157............. Loss: 5.5233\n",
      "batch: 25700/60157............. Loss: 5.5059\n",
      "batch: 25720/60157............. Loss: 5.4735\n",
      "batch: 25740/60157............. Loss: 5.5193\n",
      "batch: 25760/60157............. Loss: 5.5053\n",
      "batch: 25780/60157............. Loss: 5.5180\n",
      "batch: 25800/60157............. Loss: 5.5220\n",
      "batch: 25820/60157............. Loss: 5.5223\n",
      "batch: 25840/60157............. Loss: 5.4996\n",
      "batch: 25860/60157............. Loss: 5.5195\n",
      "batch: 25880/60157............. Loss: 5.5177\n",
      "batch: 25900/60157............. Loss: 5.5225\n",
      "batch: 25920/60157............. Loss: 5.4948\n",
      "batch: 25940/60157............. Loss: 5.4885\n",
      "batch: 25960/60157............. Loss: 5.5052\n",
      "batch: 25980/60157............. Loss: 5.4879\n",
      "batch: 26000/60157............. Loss: 5.5209\n",
      "batch: 26020/60157............. Loss: 5.5192\n",
      "batch: 26040/60157............. Loss: 5.5141\n",
      "batch: 26060/60157............. Loss: 5.5104\n",
      "batch: 26080/60157............. Loss: 5.5229\n",
      "batch: 26100/60157............. Loss: 5.5153\n",
      "batch: 26120/60157............. Loss: 5.5194\n",
      "batch: 26140/60157............. Loss: 5.5157\n",
      "batch: 26160/60157............. Loss: 5.5184\n",
      "batch: 26180/60157............. Loss: 5.5125\n",
      "batch: 26200/60157............. Loss: 5.4896\n",
      "batch: 26220/60157............. Loss: 5.4916\n",
      "batch: 26240/60157............. Loss: 5.4887\n",
      "batch: 26260/60157............. Loss: 5.5017\n",
      "batch: 26280/60157............. Loss: 5.5162\n",
      "batch: 26300/60157............. Loss: 5.5193\n",
      "batch: 26320/60157............. Loss: 5.5166\n",
      "batch: 26340/60157............. Loss: 5.5076\n",
      "batch: 26360/60157............. Loss: 5.5184\n",
      "batch: 26380/60157............. Loss: 5.5189\n",
      "batch: 26400/60157............. Loss: 5.5190\n",
      "batch: 26420/60157............. Loss: 5.5180\n",
      "batch: 26440/60157............. Loss: 5.5234\n",
      "batch: 26460/60157............. Loss: 5.5200\n",
      "batch: 26480/60157............. Loss: 5.5186\n",
      "batch: 26500/60157............. Loss: 5.4879\n",
      "batch: 26520/60157............. Loss: 5.5218\n",
      "batch: 26540/60157............. Loss: 5.5172\n",
      "batch: 26560/60157............. Loss: 5.5213\n",
      "batch: 26580/60157............. Loss: 5.5123\n",
      "batch: 26600/60157............. Loss: 5.5177\n",
      "batch: 26620/60157............. Loss: 5.4801\n",
      "batch: 26640/60157............. Loss: 5.5194\n",
      "batch: 26660/60157............. Loss: 5.5178\n",
      "batch: 26680/60157............. Loss: 5.5132\n",
      "batch: 26700/60157............. Loss: 5.5173\n",
      "batch: 26720/60157............. Loss: 5.5221\n",
      "batch: 26740/60157............. Loss: 5.4920\n",
      "batch: 26760/60157............. Loss: 5.5228\n",
      "batch: 26780/60157............. Loss: 5.5231\n",
      "batch: 26800/60157............. Loss: 5.5153\n",
      "batch: 26820/60157............. Loss: 5.5106\n",
      "batch: 26840/60157............. Loss: 5.5101\n",
      "batch: 26860/60157............. Loss: 5.5142\n",
      "batch: 26880/60157............. Loss: 5.4721\n",
      "batch: 26900/60157............. Loss: 5.5216\n",
      "batch: 26920/60157............. Loss: 5.5035\n",
      "batch: 26940/60157............. Loss: 5.4986\n",
      "batch: 26960/60157............. Loss: 5.5184\n",
      "batch: 26980/60157............. Loss: 5.4976\n",
      "batch: 27000/60157............. Loss: 5.5184\n",
      "batch: 27020/60157............. Loss: 5.5178\n",
      "batch: 27040/60157............. Loss: 5.5080\n",
      "batch: 27060/60157............. Loss: 5.5114\n",
      "batch: 27080/60157............. Loss: 5.5185\n",
      "batch: 27100/60157............. Loss: 5.5141\n",
      "batch: 27120/60157............. Loss: 5.4798\n",
      "batch: 27140/60157............. Loss: 5.5140\n",
      "batch: 27160/60157............. Loss: 5.4942\n",
      "batch: 27180/60157............. Loss: 5.5088\n",
      "batch: 27200/60157............. Loss: 5.5203\n",
      "batch: 27220/60157............. Loss: 5.5194\n",
      "batch: 27240/60157............. Loss: 5.5032\n",
      "batch: 27260/60157............. Loss: 5.5042\n",
      "batch: 27280/60157............. Loss: 5.5158\n",
      "batch: 27300/60157............. Loss: 5.4964\n",
      "batch: 27320/60157............. Loss: 5.5169\n",
      "batch: 27340/60157............. Loss: 5.5121\n",
      "batch: 27360/60157............. Loss: 5.5070\n",
      "batch: 27380/60157............. Loss: 5.4543\n",
      "batch: 27400/60157............. Loss: 5.5052\n",
      "batch: 27420/60157............. Loss: 5.5145\n",
      "batch: 27440/60157............. Loss: 5.5132\n",
      "batch: 27460/60157............. Loss: 5.5094\n",
      "batch: 27480/60157............. Loss: 5.5214\n",
      "batch: 27500/60157............. Loss: 5.5182\n",
      "batch: 27520/60157............. Loss: 5.5226\n",
      "batch: 27540/60157............. Loss: 5.5189\n",
      "batch: 27560/60157............. Loss: 5.5173\n",
      "batch: 27580/60157............. Loss: 5.5174\n",
      "batch: 27600/60157............. Loss: 5.5020\n",
      "batch: 27620/60157............. Loss: 5.5223\n",
      "batch: 27640/60157............. Loss: 5.4860\n",
      "batch: 27660/60157............. Loss: 5.5199\n",
      "batch: 27680/60157............. Loss: 5.5166\n",
      "batch: 27700/60157............. Loss: 5.5209\n",
      "batch: 27720/60157............. Loss: 5.5138\n",
      "batch: 27740/60157............. Loss: 5.5189\n",
      "batch: 27760/60157............. Loss: 5.4951\n",
      "batch: 27780/60157............. Loss: 5.5163\n",
      "batch: 27800/60157............. Loss: 5.5171\n",
      "batch: 27820/60157............. Loss: 5.5201\n",
      "batch: 27840/60157............. Loss: 5.5187\n",
      "batch: 27860/60157............. Loss: 5.5143\n",
      "batch: 27880/60157............. Loss: 5.5017\n",
      "batch: 27900/60157............. Loss: 5.5191\n",
      "batch: 27920/60157............. Loss: 5.5187\n",
      "batch: 27940/60157............. Loss: 5.5195\n",
      "batch: 27960/60157............. Loss: 5.5218\n",
      "batch: 27980/60157............. Loss: 5.4988\n",
      "batch: 28000/60157............. Loss: 5.5024\n",
      "batch: 28020/60157............. Loss: 5.4684\n",
      "batch: 28040/60157............. Loss: 5.5162\n",
      "batch: 28060/60157............. Loss: 5.5113\n",
      "batch: 28080/60157............. Loss: 5.5219\n",
      "batch: 28100/60157............. Loss: 5.5199\n",
      "batch: 28120/60157............. Loss: 5.5191\n",
      "batch: 28140/60157............. Loss: 5.5197\n",
      "batch: 28160/60157............. Loss: 5.4883\n",
      "batch: 28180/60157............. Loss: 5.5165\n",
      "batch: 28200/60157............. Loss: 5.5137\n",
      "batch: 28220/60157............. Loss: 5.4676\n",
      "batch: 28240/60157............. Loss: 5.5230\n",
      "batch: 28260/60157............. Loss: 5.5162\n",
      "batch: 28280/60157............. Loss: 5.5145\n",
      "batch: 28300/60157............. Loss: 5.5189\n",
      "batch: 28320/60157............. Loss: 5.5152\n",
      "batch: 28340/60157............. Loss: 5.5106\n",
      "batch: 28360/60157............. Loss: 5.5046\n",
      "batch: 28380/60157............. Loss: 5.5169\n",
      "batch: 28400/60157............. Loss: 5.5211\n",
      "batch: 28420/60157............. Loss: 5.5174\n",
      "batch: 28440/60157............. Loss: 5.5227\n",
      "batch: 28460/60157............. Loss: 5.5170\n",
      "batch: 28480/60157............. Loss: 5.4721\n",
      "batch: 28500/60157............. Loss: 5.5097\n",
      "batch: 28520/60157............. Loss: 5.5219\n",
      "batch: 28540/60157............. Loss: 5.5132\n",
      "batch: 28560/60157............. Loss: 5.5177\n",
      "batch: 28580/60157............. Loss: 5.5109\n",
      "batch: 28600/60157............. Loss: 5.5119\n",
      "batch: 28620/60157............. Loss: 5.5151\n",
      "batch: 28640/60157............. Loss: 5.4629\n",
      "batch: 28660/60157............. Loss: 5.4964\n",
      "batch: 28680/60157............. Loss: 5.5241\n",
      "batch: 28700/60157............. Loss: 5.5205\n",
      "batch: 28720/60157............. Loss: 5.5199\n",
      "batch: 28740/60157............. Loss: 5.5206\n",
      "batch: 28760/60157............. Loss: 5.5202\n",
      "batch: 28780/60157............. Loss: 5.5217\n",
      "batch: 28800/60157............. Loss: 5.5166\n",
      "batch: 28820/60157............. Loss: 5.5166\n",
      "batch: 28840/60157............. Loss: 5.5155\n",
      "batch: 28860/60157............. Loss: 5.5104\n",
      "batch: 28880/60157............. Loss: 5.5204\n",
      "batch: 28900/60157............. Loss: 5.5124\n",
      "batch: 28920/60157............. Loss: 5.5198\n",
      "batch: 28940/60157............. Loss: 5.5061\n",
      "batch: 28960/60157............. Loss: 5.5144\n",
      "batch: 28980/60157............. Loss: 5.5150\n",
      "batch: 29000/60157............. Loss: 5.5138\n",
      "batch: 29020/60157............. Loss: 5.5135\n",
      "batch: 29040/60157............. Loss: 5.5088\n",
      "batch: 29060/60157............. Loss: 5.5173\n",
      "batch: 29080/60157............. Loss: 5.5155\n",
      "batch: 29100/60157............. Loss: 5.5200\n",
      "batch: 29120/60157............. Loss: 5.5196\n",
      "batch: 29140/60157............. Loss: 5.5101\n",
      "batch: 29160/60157............. Loss: 5.4702\n",
      "batch: 29180/60157............. Loss: 5.5119\n",
      "batch: 29200/60157............. Loss: 5.5112\n",
      "batch: 29220/60157............. Loss: 5.5195\n",
      "batch: 29240/60157............. Loss: 5.5191\n",
      "batch: 29260/60157............. Loss: 5.5131\n",
      "batch: 29280/60157............. Loss: 5.5174\n",
      "batch: 29300/60157............. Loss: 5.4884\n",
      "batch: 29320/60157............. Loss: 5.5110\n",
      "batch: 29340/60157............. Loss: 5.5223\n",
      "batch: 29360/60157............. Loss: 5.4881\n",
      "batch: 29380/60157............. Loss: 5.5186\n",
      "batch: 29400/60157............. Loss: 5.5034\n",
      "batch: 29420/60157............. Loss: 5.5164\n",
      "batch: 29440/60157............. Loss: 5.5189\n",
      "batch: 29460/60157............. Loss: 5.5156\n",
      "batch: 29480/60157............. Loss: 5.5148\n",
      "batch: 29500/60157............. Loss: 5.5199\n",
      "batch: 29520/60157............. Loss: 5.5184\n",
      "batch: 29540/60157............. Loss: 5.5195\n",
      "batch: 29560/60157............. Loss: 5.5124\n",
      "batch: 29580/60157............. Loss: 5.5122\n",
      "batch: 29600/60157............. Loss: 5.5199\n",
      "batch: 29620/60157............. Loss: 5.5248\n",
      "batch: 29640/60157............. Loss: 5.5190\n",
      "batch: 29660/60157............. Loss: 5.4951\n",
      "batch: 29680/60157............. Loss: 5.5147\n",
      "batch: 29700/60157............. Loss: 5.5215\n",
      "batch: 29720/60157............. Loss: 5.5103\n",
      "batch: 29740/60157............. Loss: 5.5180\n",
      "batch: 29760/60157............. Loss: 5.5163\n",
      "batch: 29780/60157............. Loss: 5.4854\n",
      "batch: 29800/60157............. Loss: 5.5157\n",
      "batch: 29820/60157............. Loss: 5.4652\n",
      "batch: 29840/60157............. Loss: 5.5203\n",
      "batch: 29860/60157............. Loss: 5.5168\n",
      "batch: 29880/60157............. Loss: 5.5043\n",
      "batch: 29900/60157............. Loss: 5.4737\n",
      "batch: 29920/60157............. Loss: 5.5211\n",
      "batch: 29940/60157............. Loss: 5.5214\n",
      "batch: 29960/60157............. Loss: 5.4757\n",
      "batch: 29980/60157............. Loss: 5.5201\n",
      "batch: 30000/60157............. Loss: 5.5135\n",
      "batch: 30020/60157............. Loss: 5.5078\n",
      "batch: 30040/60157............. Loss: 5.5211\n",
      "batch: 30060/60157............. Loss: 5.5095\n",
      "batch: 30080/60157............. Loss: 5.4966\n",
      "batch: 30100/60157............. Loss: 5.5155\n",
      "batch: 30120/60157............. Loss: 5.5007\n",
      "batch: 30140/60157............. Loss: 5.5117\n",
      "batch: 30160/60157............. Loss: 5.5245\n",
      "batch: 30180/60157............. Loss: 5.4780\n",
      "batch: 30200/60157............. Loss: 5.5156\n",
      "batch: 30220/60157............. Loss: 5.5092\n",
      "batch: 30240/60157............. Loss: 5.4991\n",
      "batch: 30260/60157............. Loss: 5.5042\n",
      "batch: 30280/60157............. Loss: 5.5132\n",
      "batch: 30300/60157............. Loss: 5.5158\n",
      "batch: 30320/60157............. Loss: 5.5204\n",
      "batch: 30340/60157............. Loss: 5.5176\n",
      "batch: 30360/60157............. Loss: 5.5152\n",
      "batch: 30380/60157............. Loss: 5.5181\n",
      "batch: 30400/60157............. Loss: 5.5196\n",
      "batch: 30420/60157............. Loss: 5.5056\n",
      "batch: 30440/60157............. Loss: 5.5173\n",
      "batch: 30460/60157............. Loss: 5.5095\n",
      "batch: 30480/60157............. Loss: 5.5190\n",
      "batch: 30500/60157............. Loss: 5.5141\n",
      "batch: 30520/60157............. Loss: 5.5150\n",
      "batch: 30540/60157............. Loss: 5.5193\n",
      "batch: 30560/60157............. Loss: 5.5192\n",
      "batch: 30580/60157............. Loss: 5.5242\n",
      "batch: 30600/60157............. Loss: 5.5151\n",
      "batch: 30620/60157............. Loss: 5.5177\n",
      "batch: 30640/60157............. Loss: 5.5111\n",
      "batch: 30660/60157............. Loss: 5.4989\n",
      "batch: 30680/60157............. Loss: 5.5189\n",
      "batch: 30700/60157............. Loss: 5.4666\n",
      "batch: 30720/60157............. Loss: 5.5105\n",
      "batch: 30740/60157............. Loss: 5.4728\n",
      "batch: 30760/60157............. Loss: 5.5121\n",
      "batch: 30780/60157............. Loss: 5.4827\n",
      "batch: 30800/60157............. Loss: 5.5128\n",
      "batch: 30820/60157............. Loss: 5.5080\n",
      "batch: 30840/60157............. Loss: 5.5119\n",
      "batch: 30860/60157............. Loss: 5.5013\n",
      "batch: 30880/60157............. Loss: 5.4569\n",
      "batch: 30900/60157............. Loss: 5.5170\n",
      "batch: 30920/60157............. Loss: 5.4835\n",
      "batch: 30940/60157............. Loss: 5.5214\n",
      "batch: 30960/60157............. Loss: 5.5189\n",
      "batch: 30980/60157............. Loss: 5.5173\n",
      "batch: 31000/60157............. Loss: 5.5204\n",
      "batch: 31020/60157............. Loss: 5.5223\n",
      "batch: 31040/60157............. Loss: 5.5268\n",
      "batch: 31060/60157............. Loss: 5.5263\n",
      "batch: 31080/60157............. Loss: 5.5236\n",
      "batch: 31100/60157............. Loss: 5.5222\n",
      "batch: 31120/60157............. Loss: 5.5226\n",
      "batch: 31140/60157............. Loss: 5.5196\n",
      "batch: 31160/60157............. Loss: 5.5199\n",
      "batch: 31180/60157............. Loss: 5.5107\n",
      "batch: 31200/60157............. Loss: 5.5275\n",
      "batch: 31220/60157............. Loss: 5.5220\n",
      "batch: 31240/60157............. Loss: 5.5034\n",
      "batch: 31260/60157............. Loss: 5.4826\n",
      "batch: 31280/60157............. Loss: 5.5134\n",
      "batch: 31300/60157............. Loss: 5.4922\n",
      "batch: 31320/60157............. Loss: 5.5226\n",
      "batch: 31340/60157............. Loss: 5.5081\n",
      "batch: 31360/60157............. Loss: 5.5135\n",
      "batch: 31380/60157............. Loss: 5.5196\n",
      "batch: 31400/60157............. Loss: 5.4837\n",
      "batch: 31420/60157............. Loss: 5.5254\n",
      "batch: 31440/60157............. Loss: 5.5212\n",
      "batch: 31460/60157............. Loss: 5.5222\n",
      "batch: 31480/60157............. Loss: 5.5244\n",
      "batch: 31500/60157............. Loss: 5.5250\n",
      "batch: 31520/60157............. Loss: 5.5229\n",
      "batch: 31540/60157............. Loss: 5.5225\n",
      "batch: 31560/60157............. Loss: 5.5232\n",
      "batch: 31580/60157............. Loss: 5.5192\n",
      "batch: 31600/60157............. Loss: 5.5196\n",
      "batch: 31620/60157............. Loss: 5.5095\n",
      "batch: 31640/60157............. Loss: 5.5220\n",
      "batch: 31660/60157............. Loss: 5.5254\n",
      "batch: 31680/60157............. Loss: 5.5244\n",
      "batch: 31700/60157............. Loss: 5.5097\n",
      "batch: 31720/60157............. Loss: 5.5202\n",
      "batch: 31740/60157............. Loss: 5.5084\n",
      "batch: 31760/60157............. Loss: 5.5213\n",
      "batch: 31780/60157............. Loss: 5.5164\n",
      "batch: 31800/60157............. Loss: 5.5201\n",
      "batch: 31820/60157............. Loss: 5.5207\n",
      "batch: 31840/60157............. Loss: 5.5070\n",
      "batch: 31860/60157............. Loss: 5.4764\n",
      "batch: 31880/60157............. Loss: 5.5233\n",
      "batch: 31900/60157............. Loss: 5.5038\n",
      "batch: 31920/60157............. Loss: 5.5284\n",
      "batch: 31940/60157............. Loss: 5.5271\n",
      "batch: 31960/60157............. Loss: 5.5215\n",
      "batch: 31980/60157............. Loss: 5.5279\n",
      "batch: 32000/60157............. Loss: 5.5168\n",
      "batch: 32020/60157............. Loss: 5.5170\n",
      "batch: 32040/60157............. Loss: 5.5151\n",
      "batch: 32060/60157............. Loss: 5.5123\n",
      "batch: 32080/60157............. Loss: 5.5290\n",
      "batch: 32100/60157............. Loss: 5.5297\n",
      "batch: 32120/60157............. Loss: 5.4941\n",
      "batch: 32140/60157............. Loss: 5.5217\n",
      "batch: 32160/60157............. Loss: 5.5274\n",
      "batch: 32180/60157............. Loss: 5.5080\n",
      "batch: 32200/60157............. Loss: 5.5221\n",
      "batch: 32220/60157............. Loss: 5.5213\n",
      "batch: 32240/60157............. Loss: 5.5181\n",
      "batch: 32260/60157............. Loss: 5.5196\n",
      "batch: 32280/60157............. Loss: 5.5201\n",
      "batch: 32300/60157............. Loss: 5.5219\n",
      "batch: 32320/60157............. Loss: 5.5201\n",
      "batch: 32340/60157............. Loss: 5.5234\n",
      "batch: 32360/60157............. Loss: 5.5163\n",
      "batch: 32380/60157............. Loss: 5.5261\n",
      "batch: 32400/60157............. Loss: 5.5194\n",
      "batch: 32420/60157............. Loss: 5.5232\n",
      "batch: 32440/60157............. Loss: 5.5238\n",
      "batch: 32460/60157............. Loss: 5.5179\n",
      "batch: 32480/60157............. Loss: 5.5168\n",
      "batch: 32500/60157............. Loss: 5.5231\n",
      "batch: 32520/60157............. Loss: 5.5047\n",
      "batch: 32540/60157............. Loss: 5.5251\n",
      "batch: 32560/60157............. Loss: 5.5295\n",
      "batch: 32580/60157............. Loss: 5.5033\n",
      "batch: 32600/60157............. Loss: 5.5221\n",
      "batch: 32620/60157............. Loss: 5.5176\n",
      "batch: 32640/60157............. Loss: 5.5143\n",
      "batch: 32660/60157............. Loss: 5.4745\n",
      "batch: 32680/60157............. Loss: 5.4925\n",
      "batch: 32700/60157............. Loss: 5.5186\n",
      "batch: 32720/60157............. Loss: 5.5160\n",
      "batch: 32740/60157............. Loss: 5.4666\n",
      "batch: 32760/60157............. Loss: 5.5197\n",
      "batch: 32780/60157............. Loss: 5.5183\n",
      "batch: 32800/60157............. Loss: 5.5167\n",
      "batch: 32820/60157............. Loss: 5.5209\n",
      "batch: 32840/60157............. Loss: 5.5195\n",
      "batch: 32860/60157............. Loss: 5.5157\n",
      "batch: 32880/60157............. Loss: 5.5213\n",
      "batch: 32900/60157............. Loss: 5.5176\n",
      "batch: 32920/60157............. Loss: 5.5243\n",
      "batch: 32940/60157............. Loss: 5.5160\n",
      "batch: 32960/60157............. Loss: 5.5158\n",
      "batch: 32980/60157............. Loss: 5.5204\n",
      "batch: 33000/60157............. Loss: 5.5155\n",
      "batch: 33020/60157............. Loss: 5.5180\n",
      "batch: 33040/60157............. Loss: 5.5215\n",
      "batch: 33060/60157............. Loss: 5.4727\n",
      "batch: 33080/60157............. Loss: 5.5218\n",
      "batch: 33100/60157............. Loss: 5.5088\n",
      "batch: 33120/60157............. Loss: 5.5252\n",
      "batch: 33140/60157............. Loss: 5.5232\n",
      "batch: 33160/60157............. Loss: 5.5218\n",
      "batch: 33180/60157............. Loss: 5.4929\n",
      "batch: 33200/60157............. Loss: 5.5179\n",
      "batch: 33220/60157............. Loss: 5.5224\n",
      "batch: 33240/60157............. Loss: 5.5230\n",
      "batch: 33260/60157............. Loss: 5.5116\n",
      "batch: 33280/60157............. Loss: 5.5211\n",
      "batch: 33300/60157............. Loss: 5.5164\n",
      "batch: 33320/60157............. Loss: 5.5230\n",
      "batch: 33340/60157............. Loss: 5.5184\n",
      "batch: 33360/60157............. Loss: 5.5190\n",
      "batch: 33380/60157............. Loss: 5.5160\n",
      "batch: 33400/60157............. Loss: 5.5199\n",
      "batch: 33420/60157............. Loss: 5.5159\n",
      "batch: 33440/60157............. Loss: 5.5189\n",
      "batch: 33460/60157............. Loss: 5.5126\n",
      "batch: 33480/60157............. Loss: 5.5156\n",
      "batch: 33500/60157............. Loss: 5.5202\n",
      "batch: 33520/60157............. Loss: 5.5171\n",
      "batch: 33540/60157............. Loss: 5.5183\n",
      "batch: 33560/60157............. Loss: 5.5120\n",
      "batch: 33580/60157............. Loss: 5.5160\n",
      "batch: 33600/60157............. Loss: 5.5217\n",
      "batch: 33620/60157............. Loss: 5.4697\n",
      "batch: 33640/60157............. Loss: 5.5226\n",
      "batch: 33660/60157............. Loss: 5.5174\n",
      "batch: 33680/60157............. Loss: 5.5105\n",
      "batch: 33700/60157............. Loss: 5.5109\n",
      "batch: 33720/60157............. Loss: 5.4813\n",
      "batch: 33740/60157............. Loss: 5.5127\n",
      "batch: 33760/60157............. Loss: 5.5162\n",
      "batch: 33780/60157............. Loss: 5.5189\n",
      "batch: 33800/60157............. Loss: 5.5197\n",
      "batch: 33820/60157............. Loss: 5.4666\n",
      "batch: 33840/60157............. Loss: 5.4708\n",
      "batch: 33860/60157............. Loss: 5.5196\n",
      "batch: 33880/60157............. Loss: 5.5156\n",
      "batch: 33900/60157............. Loss: 5.5104\n",
      "batch: 33920/60157............. Loss: 5.5166\n",
      "batch: 33940/60157............. Loss: 5.5182\n",
      "batch: 33960/60157............. Loss: 5.5138\n",
      "batch: 33980/60157............. Loss: 5.5184\n",
      "batch: 34000/60157............. Loss: 5.5210\n",
      "batch: 34020/60157............. Loss: 5.5219\n",
      "batch: 34040/60157............. Loss: 5.5160\n",
      "batch: 34060/60157............. Loss: 5.5092\n",
      "batch: 34080/60157............. Loss: 5.5202\n",
      "batch: 34100/60157............. Loss: 5.4723\n",
      "batch: 34120/60157............. Loss: 5.5166\n",
      "batch: 34140/60157............. Loss: 5.5176\n",
      "batch: 34160/60157............. Loss: 5.5231\n",
      "batch: 34180/60157............. Loss: 5.5164\n",
      "batch: 34200/60157............. Loss: 5.5129\n",
      "batch: 34220/60157............. Loss: 5.4874\n",
      "batch: 34240/60157............. Loss: 5.5207\n",
      "batch: 34260/60157............. Loss: 5.5173\n",
      "batch: 34280/60157............. Loss: 5.5206\n",
      "batch: 34300/60157............. Loss: 5.5222\n",
      "batch: 34320/60157............. Loss: 5.4914\n",
      "batch: 34340/60157............. Loss: 5.5234\n",
      "batch: 34360/60157............. Loss: 5.5132\n",
      "batch: 34380/60157............. Loss: 5.5081\n",
      "batch: 34400/60157............. Loss: 5.5207\n",
      "batch: 34420/60157............. Loss: 5.5257\n",
      "batch: 34440/60157............. Loss: 5.5211\n",
      "batch: 34460/60157............. Loss: 5.5206\n",
      "batch: 34480/60157............. Loss: 5.5167\n",
      "batch: 34500/60157............. Loss: 5.5175\n",
      "batch: 34520/60157............. Loss: 5.5177\n",
      "batch: 34540/60157............. Loss: 5.5204\n",
      "batch: 34560/60157............. Loss: 5.4697\n",
      "batch: 34580/60157............. Loss: 5.5181\n",
      "batch: 34600/60157............. Loss: 5.5207\n",
      "batch: 34620/60157............. Loss: 5.5058\n",
      "batch: 34640/60157............. Loss: 5.5006\n",
      "batch: 34660/60157............. Loss: 5.5130\n",
      "batch: 34680/60157............. Loss: 5.5086\n",
      "batch: 34700/60157............. Loss: 5.4981\n",
      "batch: 34720/60157............. Loss: 5.5159\n",
      "batch: 34740/60157............. Loss: 5.5170\n",
      "batch: 34760/60157............. Loss: 5.5102\n",
      "batch: 34780/60157............. Loss: 5.5174\n",
      "batch: 34800/60157............. Loss: 5.5164\n",
      "batch: 34820/60157............. Loss: 5.5154\n",
      "batch: 34840/60157............. Loss: 5.5039\n",
      "batch: 34860/60157............. Loss: 5.5206\n",
      "batch: 34880/60157............. Loss: 5.4938\n",
      "batch: 34900/60157............. Loss: 5.5182\n",
      "batch: 34920/60157............. Loss: 5.5168\n",
      "batch: 34940/60157............. Loss: 5.5171\n",
      "batch: 34960/60157............. Loss: 5.5206\n",
      "batch: 34980/60157............. Loss: 5.5151\n",
      "batch: 35000/60157............. Loss: 5.5125\n",
      "batch: 35020/60157............. Loss: 5.5244\n",
      "batch: 35040/60157............. Loss: 5.5201\n",
      "batch: 35060/60157............. Loss: 5.5221\n",
      "batch: 35080/60157............. Loss: 5.4979\n",
      "batch: 35100/60157............. Loss: 5.5024\n",
      "batch: 35120/60157............. Loss: 5.5156\n",
      "batch: 35140/60157............. Loss: 5.5162\n",
      "batch: 35160/60157............. Loss: 5.5001\n",
      "batch: 35180/60157............. Loss: 5.5011\n",
      "batch: 35200/60157............. Loss: 5.5226\n",
      "batch: 35220/60157............. Loss: 5.4896\n",
      "batch: 35240/60157............. Loss: 5.4943\n",
      "batch: 35260/60157............. Loss: 5.5193\n",
      "batch: 35280/60157............. Loss: 5.5063\n",
      "batch: 35300/60157............. Loss: 5.4841\n",
      "batch: 35320/60157............. Loss: 5.4862\n",
      "batch: 35340/60157............. Loss: 5.5084\n",
      "batch: 35360/60157............. Loss: 5.5120\n",
      "batch: 35380/60157............. Loss: 5.5232\n",
      "batch: 35400/60157............. Loss: 5.5055\n",
      "batch: 35420/60157............. Loss: 5.5169\n",
      "batch: 35440/60157............. Loss: 5.5166\n",
      "batch: 35460/60157............. Loss: 5.4954\n",
      "batch: 35480/60157............. Loss: 5.5161\n",
      "batch: 35500/60157............. Loss: 5.5224\n",
      "batch: 35520/60157............. Loss: 5.5176\n",
      "batch: 35540/60157............. Loss: 5.5168\n",
      "batch: 35560/60157............. Loss: 5.5187\n",
      "batch: 35580/60157............. Loss: 5.5214\n",
      "batch: 35600/60157............. Loss: 5.5088\n",
      "batch: 35620/60157............. Loss: 5.4961\n",
      "batch: 35640/60157............. Loss: 5.4843\n",
      "batch: 35660/60157............. Loss: 5.5196\n",
      "batch: 35680/60157............. Loss: 5.5196\n",
      "batch: 35700/60157............. Loss: 5.5200\n",
      "batch: 35720/60157............. Loss: 5.5192\n",
      "batch: 35740/60157............. Loss: 5.5237\n",
      "batch: 35760/60157............. Loss: 5.5187\n",
      "batch: 35780/60157............. Loss: 5.5206\n",
      "batch: 35800/60157............. Loss: 5.5199\n",
      "batch: 35820/60157............. Loss: 5.5201\n",
      "batch: 35840/60157............. Loss: 5.5192\n",
      "batch: 35860/60157............. Loss: 5.5217\n",
      "batch: 35880/60157............. Loss: 5.5185\n",
      "batch: 35900/60157............. Loss: 5.5231\n",
      "batch: 35920/60157............. Loss: 5.5215\n",
      "batch: 35940/60157............. Loss: 5.4793\n",
      "batch: 35960/60157............. Loss: 5.5214\n",
      "batch: 35980/60157............. Loss: 5.5163\n",
      "batch: 36000/60157............. Loss: 5.5216\n",
      "batch: 36020/60157............. Loss: 5.5223\n",
      "batch: 36040/60157............. Loss: 5.5241\n",
      "batch: 36060/60157............. Loss: 5.5150\n",
      "batch: 36080/60157............. Loss: 5.5041\n",
      "batch: 36100/60157............. Loss: 5.5175\n",
      "batch: 36120/60157............. Loss: 5.5203\n",
      "batch: 36140/60157............. Loss: 5.4857\n",
      "batch: 36160/60157............. Loss: 5.5181\n",
      "batch: 36180/60157............. Loss: 5.5199\n",
      "batch: 36200/60157............. Loss: 5.5138\n",
      "batch: 36220/60157............. Loss: 5.5186\n",
      "batch: 36240/60157............. Loss: 5.5193\n",
      "batch: 36260/60157............. Loss: 5.4843\n",
      "batch: 36280/60157............. Loss: 5.5162\n",
      "batch: 36300/60157............. Loss: 5.5023\n",
      "batch: 36320/60157............. Loss: 5.5144\n",
      "batch: 36340/60157............. Loss: 5.5195\n",
      "batch: 36360/60157............. Loss: 5.5159\n",
      "batch: 36380/60157............. Loss: 5.5149\n",
      "batch: 36400/60157............. Loss: 5.5198\n",
      "batch: 36420/60157............. Loss: 5.5109\n",
      "batch: 36440/60157............. Loss: 5.5125\n",
      "batch: 36460/60157............. Loss: 5.5104\n",
      "batch: 36480/60157............. Loss: 5.4745\n",
      "batch: 36500/60157............. Loss: 5.5219\n",
      "batch: 36520/60157............. Loss: 5.5194\n",
      "batch: 36540/60157............. Loss: 5.5156\n",
      "batch: 36560/60157............. Loss: 5.5100\n",
      "batch: 36580/60157............. Loss: 5.5170\n",
      "batch: 36600/60157............. Loss: 5.5224\n",
      "batch: 36620/60157............. Loss: 5.5137\n",
      "batch: 36640/60157............. Loss: 5.5110\n",
      "batch: 36660/60157............. Loss: 5.5140\n",
      "batch: 36680/60157............. Loss: 5.5068\n",
      "batch: 36700/60157............. Loss: 5.5221\n",
      "batch: 36720/60157............. Loss: 5.5165\n",
      "batch: 36740/60157............. Loss: 5.5104\n",
      "batch: 36760/60157............. Loss: 5.5195\n",
      "batch: 36780/60157............. Loss: 5.5098\n",
      "batch: 36800/60157............. Loss: 5.5185\n",
      "batch: 36820/60157............. Loss: 5.5187\n",
      "batch: 36840/60157............. Loss: 5.5094\n",
      "batch: 36860/60157............. Loss: 5.5129\n",
      "batch: 36880/60157............. Loss: 5.5258\n",
      "batch: 36900/60157............. Loss: 5.5129\n",
      "batch: 36920/60157............. Loss: 5.5238\n",
      "batch: 36940/60157............. Loss: 5.5206\n",
      "batch: 36960/60157............. Loss: 5.5166\n",
      "batch: 36980/60157............. Loss: 5.5208\n",
      "batch: 37000/60157............. Loss: 5.5208\n",
      "batch: 37020/60157............. Loss: 5.5172\n",
      "batch: 37040/60157............. Loss: 5.5189\n",
      "batch: 37060/60157............. Loss: 5.5292\n",
      "batch: 37080/60157............. Loss: 5.5192\n",
      "batch: 37100/60157............. Loss: 5.5260\n",
      "batch: 37120/60157............. Loss: 5.5250\n",
      "batch: 37140/60157............. Loss: 5.5221\n",
      "batch: 37160/60157............. Loss: 5.4997\n",
      "batch: 37180/60157............. Loss: 5.5062\n",
      "batch: 37200/60157............. Loss: 5.5167\n",
      "batch: 37220/60157............. Loss: 5.5196\n",
      "batch: 37240/60157............. Loss: 5.5165\n",
      "batch: 37260/60157............. Loss: 5.5247\n",
      "batch: 37280/60157............. Loss: 5.5262\n",
      "batch: 37300/60157............. Loss: 5.5205\n",
      "batch: 37320/60157............. Loss: 5.5225\n",
      "batch: 37340/60157............. Loss: 5.5169\n",
      "batch: 37360/60157............. Loss: 5.5074\n",
      "batch: 37380/60157............. Loss: 5.5067\n",
      "batch: 37400/60157............. Loss: 5.5247\n",
      "batch: 37420/60157............. Loss: 5.4919\n",
      "batch: 37440/60157............. Loss: 5.5082\n",
      "batch: 37460/60157............. Loss: 5.5210\n",
      "batch: 37480/60157............. Loss: 5.5205\n",
      "batch: 37500/60157............. Loss: 5.5314\n",
      "batch: 37520/60157............. Loss: 5.5116\n",
      "batch: 37540/60157............. Loss: 5.5162\n",
      "batch: 37560/60157............. Loss: 5.5278\n",
      "batch: 37580/60157............. Loss: 5.4956\n",
      "batch: 37600/60157............. Loss: 5.5192\n",
      "batch: 37620/60157............. Loss: 5.5204\n",
      "batch: 37640/60157............. Loss: 5.5167\n",
      "batch: 37660/60157............. Loss: 5.5244\n",
      "batch: 37680/60157............. Loss: 5.5212\n",
      "batch: 37700/60157............. Loss: 5.5215\n",
      "batch: 37720/60157............. Loss: 5.5275\n",
      "batch: 37740/60157............. Loss: 5.5208\n",
      "batch: 37760/60157............. Loss: 5.4858\n",
      "batch: 37780/60157............. Loss: 5.5188\n",
      "batch: 37800/60157............. Loss: 5.5009\n",
      "batch: 37820/60157............. Loss: 5.5111\n",
      "batch: 37840/60157............. Loss: 5.5112\n",
      "batch: 37860/60157............. Loss: 5.5059\n",
      "batch: 37880/60157............. Loss: 5.5230\n",
      "batch: 37900/60157............. Loss: 5.5191\n",
      "batch: 37920/60157............. Loss: 5.5285\n",
      "batch: 37940/60157............. Loss: 5.5153\n",
      "batch: 37960/60157............. Loss: 5.5184\n",
      "batch: 37980/60157............. Loss: 5.5251\n",
      "batch: 38000/60157............. Loss: 5.5233\n",
      "batch: 38020/60157............. Loss: 5.5098\n",
      "batch: 38040/60157............. Loss: 5.5219\n",
      "batch: 38060/60157............. Loss: 5.5148\n",
      "batch: 38080/60157............. Loss: 5.5212\n",
      "batch: 38100/60157............. Loss: 5.5139\n",
      "batch: 38120/60157............. Loss: 5.5186\n",
      "batch: 38140/60157............. Loss: 5.5081\n",
      "batch: 38160/60157............. Loss: 5.5137\n",
      "batch: 38180/60157............. Loss: 5.5190\n",
      "batch: 38200/60157............. Loss: 5.5186\n",
      "batch: 38220/60157............. Loss: 5.4997\n",
      "batch: 38240/60157............. Loss: 5.5045\n",
      "batch: 38260/60157............. Loss: 5.5139\n",
      "batch: 38280/60157............. Loss: 5.5182\n",
      "batch: 38300/60157............. Loss: 5.5192\n",
      "batch: 38320/60157............. Loss: 5.5162\n",
      "batch: 38340/60157............. Loss: 5.5158\n",
      "batch: 38360/60157............. Loss: 5.5217\n",
      "batch: 38380/60157............. Loss: 5.5170\n",
      "batch: 38400/60157............. Loss: 5.5131\n",
      "batch: 38420/60157............. Loss: 5.5197\n",
      "batch: 38440/60157............. Loss: 5.5151\n",
      "batch: 38460/60157............. Loss: 5.5187\n",
      "batch: 38480/60157............. Loss: 5.5237\n",
      "batch: 38500/60157............. Loss: 5.5184\n",
      "batch: 38520/60157............. Loss: 5.4787\n",
      "batch: 38540/60157............. Loss: 5.5192\n",
      "batch: 38560/60157............. Loss: 5.5127\n",
      "batch: 38580/60157............. Loss: 5.5118\n",
      "batch: 38600/60157............. Loss: 5.5160\n",
      "batch: 38620/60157............. Loss: 5.5101\n",
      "batch: 38640/60157............. Loss: 5.5072\n",
      "batch: 38660/60157............. Loss: 5.5217\n",
      "batch: 38680/60157............. Loss: 5.5038\n",
      "batch: 38700/60157............. Loss: 5.5222\n",
      "batch: 38720/60157............. Loss: 5.5241\n",
      "batch: 38740/60157............. Loss: 5.5162\n",
      "batch: 38760/60157............. Loss: 5.5129\n",
      "batch: 38780/60157............. Loss: 5.5106\n",
      "batch: 38800/60157............. Loss: 5.5195\n",
      "batch: 38820/60157............. Loss: 5.5134\n",
      "batch: 38840/60157............. Loss: 5.5226\n",
      "batch: 38860/60157............. Loss: 5.5145\n",
      "batch: 38880/60157............. Loss: 5.5121\n",
      "batch: 38900/60157............. Loss: 5.5212\n",
      "batch: 38920/60157............. Loss: 5.5158\n",
      "batch: 38940/60157............. Loss: 5.5148\n",
      "batch: 38960/60157............. Loss: 5.4758\n",
      "batch: 38980/60157............. Loss: 5.5185\n",
      "batch: 39000/60157............. Loss: 5.5193\n",
      "batch: 39020/60157............. Loss: 5.5062\n",
      "batch: 39040/60157............. Loss: 5.5035\n",
      "batch: 39060/60157............. Loss: 5.5059\n",
      "batch: 39080/60157............. Loss: 5.5034\n",
      "batch: 39100/60157............. Loss: 5.5139\n",
      "batch: 39120/60157............. Loss: 5.5162\n",
      "batch: 39140/60157............. Loss: 5.5157\n",
      "batch: 39160/60157............. Loss: 5.5155\n",
      "batch: 39180/60157............. Loss: 5.5048\n",
      "batch: 39200/60157............. Loss: 5.5161\n",
      "batch: 39220/60157............. Loss: 5.5223\n",
      "batch: 39240/60157............. Loss: 5.5017\n",
      "batch: 39260/60157............. Loss: 5.5113\n",
      "batch: 39280/60157............. Loss: 5.5002\n",
      "batch: 39300/60157............. Loss: 5.5235\n",
      "batch: 39320/60157............. Loss: 5.5178\n",
      "batch: 39340/60157............. Loss: 5.5096\n",
      "batch: 39360/60157............. Loss: 5.5126\n",
      "batch: 39380/60157............. Loss: 5.4859\n",
      "batch: 39400/60157............. Loss: 5.5148\n",
      "batch: 39420/60157............. Loss: 5.4930\n",
      "batch: 39440/60157............. Loss: 5.5161\n",
      "batch: 39460/60157............. Loss: 5.5202\n",
      "batch: 39480/60157............. Loss: 5.5163\n",
      "batch: 39500/60157............. Loss: 5.4818\n",
      "batch: 39520/60157............. Loss: 5.5189\n",
      "batch: 39540/60157............. Loss: 5.5210\n",
      "batch: 39560/60157............. Loss: 5.5123\n",
      "batch: 39580/60157............. Loss: 5.5126\n",
      "batch: 39600/60157............. Loss: 5.5187\n",
      "batch: 39620/60157............. Loss: 5.5207\n",
      "batch: 39640/60157............. Loss: 5.5212\n",
      "batch: 39660/60157............. Loss: 5.4963\n",
      "batch: 39680/60157............. Loss: 5.4779\n",
      "batch: 39700/60157............. Loss: 5.5065\n",
      "batch: 39720/60157............. Loss: 5.4971\n",
      "batch: 39740/60157............. Loss: 5.5127\n",
      "batch: 39760/60157............. Loss: 5.5222\n",
      "batch: 39780/60157............. Loss: 5.5216\n",
      "batch: 39800/60157............. Loss: 5.5213\n",
      "batch: 39820/60157............. Loss: 5.5208\n",
      "batch: 39840/60157............. Loss: 5.5183\n",
      "batch: 39860/60157............. Loss: 5.5187\n",
      "batch: 39880/60157............. Loss: 5.5193\n",
      "batch: 39900/60157............. Loss: 5.4985\n",
      "batch: 39920/60157............. Loss: 5.5105\n",
      "batch: 39940/60157............. Loss: 5.5259\n",
      "batch: 39960/60157............. Loss: 5.5249\n",
      "batch: 39980/60157............. Loss: 5.5119\n",
      "batch: 40000/60157............. Loss: 5.5211\n",
      "batch: 40020/60157............. Loss: 5.4884\n",
      "batch: 40040/60157............. Loss: 5.5119\n",
      "batch: 40060/60157............. Loss: 5.5199\n",
      "batch: 40080/60157............. Loss: 5.5231\n",
      "batch: 40100/60157............. Loss: 5.5205\n",
      "batch: 40120/60157............. Loss: 5.5007\n",
      "batch: 40140/60157............. Loss: 5.5204\n",
      "batch: 40160/60157............. Loss: 5.5215\n",
      "batch: 40180/60157............. Loss: 5.5202\n",
      "batch: 40200/60157............. Loss: 5.4783\n",
      "batch: 40220/60157............. Loss: 5.5061\n",
      "batch: 40240/60157............. Loss: 5.5204\n",
      "batch: 40260/60157............. Loss: 5.4561\n",
      "batch: 40280/60157............. Loss: 5.4573\n",
      "batch: 40300/60157............. Loss: 5.5228\n",
      "batch: 40320/60157............. Loss: 5.5101\n",
      "batch: 40340/60157............. Loss: 5.5099\n",
      "batch: 40360/60157............. Loss: 5.5181\n",
      "batch: 40380/60157............. Loss: 5.5200\n",
      "batch: 40400/60157............. Loss: 5.5175\n",
      "batch: 40420/60157............. Loss: 5.5235\n",
      "batch: 40440/60157............. Loss: 5.5138\n",
      "batch: 40460/60157............. Loss: 5.5170\n",
      "batch: 40480/60157............. Loss: 5.5238\n",
      "batch: 40500/60157............. Loss: 5.4862\n",
      "batch: 40520/60157............. Loss: 5.4887\n",
      "batch: 40540/60157............. Loss: 5.5112\n",
      "batch: 40560/60157............. Loss: 5.5056\n",
      "batch: 40580/60157............. Loss: 5.5166\n",
      "batch: 40600/60157............. Loss: 5.5137\n",
      "batch: 40620/60157............. Loss: 5.5208\n",
      "batch: 40640/60157............. Loss: 5.5091\n",
      "batch: 40660/60157............. Loss: 5.5237\n",
      "batch: 40680/60157............. Loss: 5.4909\n",
      "batch: 40700/60157............. Loss: 5.5185\n",
      "batch: 40720/60157............. Loss: 5.5088\n",
      "batch: 40740/60157............. Loss: 5.5181\n",
      "batch: 40760/60157............. Loss: 5.5171\n",
      "batch: 40780/60157............. Loss: 5.4809\n",
      "batch: 40800/60157............. Loss: 5.5169\n",
      "batch: 40820/60157............. Loss: 5.5182\n",
      "batch: 40840/60157............. Loss: 5.5204\n",
      "batch: 40860/60157............. Loss: 5.4513\n",
      "batch: 40880/60157............. Loss: 5.5135\n",
      "batch: 40900/60157............. Loss: 5.5117\n",
      "batch: 40920/60157............. Loss: 5.5219\n",
      "batch: 40940/60157............. Loss: 5.5241\n",
      "batch: 40960/60157............. Loss: 5.4807\n",
      "batch: 40980/60157............. Loss: 5.5013\n",
      "batch: 41000/60157............. Loss: 5.5192\n",
      "batch: 41020/60157............. Loss: 5.5147\n",
      "batch: 41040/60157............. Loss: 5.5204\n",
      "batch: 41060/60157............. Loss: 5.5196\n",
      "batch: 41080/60157............. Loss: 5.5201\n",
      "batch: 41100/60157............. Loss: 5.4876\n",
      "batch: 41120/60157............. Loss: 5.4754\n",
      "batch: 41140/60157............. Loss: 5.5107\n",
      "batch: 41160/60157............. Loss: 5.5169\n",
      "batch: 41180/60157............. Loss: 5.5212\n",
      "batch: 41200/60157............. Loss: 5.5076\n",
      "batch: 41220/60157............. Loss: 5.5151\n",
      "batch: 41240/60157............. Loss: 5.5165\n",
      "batch: 41260/60157............. Loss: 5.5240\n",
      "batch: 41280/60157............. Loss: 5.5240\n",
      "batch: 41300/60157............. Loss: 5.5176\n",
      "batch: 41320/60157............. Loss: 5.4944\n",
      "batch: 41340/60157............. Loss: 5.5143\n",
      "batch: 41360/60157............. Loss: 5.5244\n",
      "batch: 41380/60157............. Loss: 5.4961\n",
      "batch: 41400/60157............. Loss: 5.5198\n",
      "batch: 41420/60157............. Loss: 5.5196\n",
      "batch: 41440/60157............. Loss: 5.4893\n",
      "batch: 41460/60157............. Loss: 5.5166\n",
      "batch: 41480/60157............. Loss: 5.5213\n",
      "batch: 41500/60157............. Loss: 5.5219\n",
      "batch: 41520/60157............. Loss: 5.5238\n",
      "batch: 41540/60157............. Loss: 5.5178\n",
      "batch: 41560/60157............. Loss: 5.5174\n",
      "batch: 41580/60157............. Loss: 5.5167\n",
      "batch: 41600/60157............. Loss: 5.5249\n",
      "batch: 41620/60157............. Loss: 5.5105\n",
      "batch: 41640/60157............. Loss: 5.5173\n",
      "batch: 41660/60157............. Loss: 5.5178\n",
      "batch: 41680/60157............. Loss: 5.5172\n",
      "batch: 41700/60157............. Loss: 5.5207\n",
      "batch: 41720/60157............. Loss: 5.5071\n",
      "batch: 41740/60157............. Loss: 5.5210\n",
      "batch: 41760/60157............. Loss: 5.5223\n",
      "batch: 41780/60157............. Loss: 5.5185\n",
      "batch: 41800/60157............. Loss: 5.5219\n",
      "batch: 41820/60157............. Loss: 5.5213\n",
      "batch: 41840/60157............. Loss: 5.5249\n",
      "batch: 41860/60157............. Loss: 5.5143\n",
      "batch: 41880/60157............. Loss: 5.5221\n",
      "batch: 41900/60157............. Loss: 5.4744\n",
      "batch: 41920/60157............. Loss: 5.5171\n",
      "batch: 41940/60157............. Loss: 5.5170\n",
      "batch: 41960/60157............. Loss: 5.4905\n",
      "batch: 41980/60157............. Loss: 5.5102\n",
      "batch: 42000/60157............. Loss: 5.5205\n",
      "batch: 42020/60157............. Loss: 5.5249\n",
      "batch: 42040/60157............. Loss: 5.4790\n",
      "batch: 42060/60157............. Loss: 5.5183\n",
      "batch: 42080/60157............. Loss: 5.5078\n",
      "batch: 42100/60157............. Loss: 5.4859\n",
      "batch: 42120/60157............. Loss: 5.5006\n",
      "batch: 42140/60157............. Loss: 5.5218\n",
      "batch: 42160/60157............. Loss: 5.5219\n",
      "batch: 42180/60157............. Loss: 5.5000\n",
      "batch: 42200/60157............. Loss: 5.5189\n",
      "batch: 42220/60157............. Loss: 5.5165\n",
      "batch: 42240/60157............. Loss: 5.4661\n",
      "batch: 42260/60157............. Loss: 5.5204\n",
      "batch: 42280/60157............. Loss: 5.5096\n",
      "batch: 42300/60157............. Loss: 5.4968\n",
      "batch: 42320/60157............. Loss: 5.5118\n",
      "batch: 42340/60157............. Loss: 5.5193\n",
      "batch: 42360/60157............. Loss: 5.5207\n",
      "batch: 42380/60157............. Loss: 5.5189\n",
      "batch: 42400/60157............. Loss: 5.5151\n",
      "batch: 42420/60157............. Loss: 5.5248\n",
      "batch: 42440/60157............. Loss: 5.5100\n",
      "batch: 42460/60157............. Loss: 5.5226\n",
      "batch: 42480/60157............. Loss: 5.5186\n",
      "batch: 42500/60157............. Loss: 5.5084\n",
      "batch: 42520/60157............. Loss: 5.4921\n",
      "batch: 42540/60157............. Loss: 5.5188\n",
      "batch: 42560/60157............. Loss: 5.5173\n",
      "batch: 42580/60157............. Loss: 5.5197\n",
      "batch: 42600/60157............. Loss: 5.5206\n",
      "batch: 42620/60157............. Loss: 5.5179\n",
      "batch: 42640/60157............. Loss: 5.4912\n",
      "batch: 42660/60157............. Loss: 5.5142\n",
      "batch: 42680/60157............. Loss: 5.5163\n",
      "batch: 42700/60157............. Loss: 5.5149\n",
      "batch: 42720/60157............. Loss: 5.5207\n",
      "batch: 42740/60157............. Loss: 5.4947\n",
      "batch: 42760/60157............. Loss: 5.4984\n",
      "batch: 42780/60157............. Loss: 5.5086\n",
      "batch: 42800/60157............. Loss: 5.5021\n",
      "batch: 42820/60157............. Loss: 5.5122\n",
      "batch: 42840/60157............. Loss: 5.5117\n",
      "batch: 42860/60157............. Loss: 5.5215\n",
      "batch: 42880/60157............. Loss: 5.5189\n",
      "batch: 42900/60157............. Loss: 5.5171\n",
      "batch: 42920/60157............. Loss: 5.5149\n",
      "batch: 42940/60157............. Loss: 5.5119\n",
      "batch: 42960/60157............. Loss: 5.5148\n",
      "batch: 42980/60157............. Loss: 5.4904\n",
      "batch: 43000/60157............. Loss: 5.5154\n",
      "batch: 43020/60157............. Loss: 5.5182\n",
      "batch: 43040/60157............. Loss: 5.5131\n",
      "batch: 43060/60157............. Loss: 5.5064\n",
      "batch: 43080/60157............. Loss: 5.5178\n",
      "batch: 43100/60157............. Loss: 5.5195\n",
      "batch: 43120/60157............. Loss: 5.5078\n",
      "batch: 43140/60157............. Loss: 5.5141\n",
      "batch: 43160/60157............. Loss: 5.5166\n",
      "batch: 43180/60157............. Loss: 5.5206\n",
      "batch: 43200/60157............. Loss: 5.5199\n",
      "batch: 43220/60157............. Loss: 5.5065\n",
      "batch: 43240/60157............. Loss: 5.5197\n",
      "batch: 43260/60157............. Loss: 5.5219\n",
      "batch: 43280/60157............. Loss: 5.5057\n",
      "batch: 43300/60157............. Loss: 5.5060\n",
      "batch: 43320/60157............. Loss: 5.5174\n",
      "batch: 43340/60157............. Loss: 5.5186\n",
      "batch: 43360/60157............. Loss: 5.5161\n",
      "batch: 43380/60157............. Loss: 5.5145\n",
      "batch: 43400/60157............. Loss: 5.5218\n",
      "batch: 43420/60157............. Loss: 5.5167\n",
      "batch: 43440/60157............. Loss: 5.5180\n",
      "batch: 43460/60157............. Loss: 5.5013\n",
      "batch: 43480/60157............. Loss: 5.5202\n",
      "batch: 43500/60157............. Loss: 5.5140\n",
      "batch: 43520/60157............. Loss: 5.5122\n",
      "batch: 43540/60157............. Loss: 5.5127\n",
      "batch: 43560/60157............. Loss: 5.5103\n",
      "batch: 43580/60157............. Loss: 5.5089\n",
      "batch: 43600/60157............. Loss: 5.5210\n",
      "batch: 43620/60157............. Loss: 5.5081\n",
      "batch: 43640/60157............. Loss: 5.5170\n",
      "batch: 43660/60157............. Loss: 5.5153\n",
      "batch: 43680/60157............. Loss: 5.5054\n",
      "batch: 43700/60157............. Loss: 5.5252\n",
      "batch: 43720/60157............. Loss: 5.5177\n",
      "batch: 43740/60157............. Loss: 5.4737\n",
      "batch: 43760/60157............. Loss: 5.5186\n",
      "batch: 43780/60157............. Loss: 5.4834\n",
      "batch: 43800/60157............. Loss: 5.5193\n",
      "batch: 43820/60157............. Loss: 5.5152\n",
      "batch: 43840/60157............. Loss: 5.5250\n",
      "batch: 43860/60157............. Loss: 5.4859\n",
      "batch: 43880/60157............. Loss: 5.5176\n",
      "batch: 43900/60157............. Loss: 5.5017\n",
      "batch: 43920/60157............. Loss: 5.5137\n",
      "batch: 43940/60157............. Loss: 5.5168\n",
      "batch: 43960/60157............. Loss: 5.5038\n",
      "batch: 43980/60157............. Loss: 5.4968\n",
      "batch: 44000/60157............. Loss: 5.5236\n",
      "batch: 44020/60157............. Loss: 5.5264\n",
      "batch: 44040/60157............. Loss: 5.5096\n",
      "batch: 44060/60157............. Loss: 5.5194\n",
      "batch: 44080/60157............. Loss: 5.4923\n",
      "batch: 44100/60157............. Loss: 5.5158\n",
      "batch: 44120/60157............. Loss: 5.4665\n",
      "batch: 44140/60157............. Loss: 5.5080\n",
      "batch: 44160/60157............. Loss: 5.5174\n",
      "batch: 44180/60157............. Loss: 5.5188\n",
      "batch: 44200/60157............. Loss: 5.5167\n",
      "batch: 44220/60157............. Loss: 5.4990\n",
      "batch: 44240/60157............. Loss: 5.5189\n",
      "batch: 44260/60157............. Loss: 5.5176\n",
      "batch: 44280/60157............. Loss: 5.4841\n",
      "batch: 44300/60157............. Loss: 5.5195\n",
      "batch: 44320/60157............. Loss: 5.5002\n",
      "batch: 44340/60157............. Loss: 5.4996\n",
      "batch: 44360/60157............. Loss: 5.5171\n",
      "batch: 44380/60157............. Loss: 5.5107\n",
      "batch: 44400/60157............. Loss: 5.5172\n",
      "batch: 44420/60157............. Loss: 5.5249\n",
      "batch: 44440/60157............. Loss: 5.5126\n",
      "batch: 44460/60157............. Loss: 5.4963\n",
      "batch: 44480/60157............. Loss: 5.5177\n",
      "batch: 44500/60157............. Loss: 5.5189\n",
      "batch: 44520/60157............. Loss: 5.5140\n",
      "batch: 44540/60157............. Loss: 5.4943\n",
      "batch: 44560/60157............. Loss: 5.5205\n",
      "batch: 44580/60157............. Loss: 5.5172\n",
      "batch: 44600/60157............. Loss: 5.5155\n",
      "batch: 44620/60157............. Loss: 5.5180\n",
      "batch: 44640/60157............. Loss: 5.5259\n",
      "batch: 44660/60157............. Loss: 5.5200\n",
      "batch: 44680/60157............. Loss: 5.5185\n",
      "batch: 44700/60157............. Loss: 5.5049\n",
      "batch: 44720/60157............. Loss: 5.5131\n",
      "batch: 44740/60157............. Loss: 5.5157\n",
      "batch: 44760/60157............. Loss: 5.5031\n",
      "batch: 44780/60157............. Loss: 5.4732\n",
      "batch: 44800/60157............. Loss: 5.5125\n",
      "batch: 44820/60157............. Loss: 5.4838\n",
      "batch: 44840/60157............. Loss: 5.5164\n",
      "batch: 44860/60157............. Loss: 5.5198\n",
      "batch: 44880/60157............. Loss: 5.5136\n",
      "batch: 44900/60157............. Loss: 5.5151\n",
      "batch: 44920/60157............. Loss: 5.5168\n",
      "batch: 44940/60157............. Loss: 5.5167\n",
      "batch: 44960/60157............. Loss: 5.4863\n",
      "batch: 44980/60157............. Loss: 5.5210\n",
      "batch: 45000/60157............. Loss: 5.5145\n",
      "batch: 45020/60157............. Loss: 5.5209\n",
      "batch: 45040/60157............. Loss: 5.5193\n",
      "batch: 45060/60157............. Loss: 5.5068\n",
      "batch: 45080/60157............. Loss: 5.5197\n",
      "batch: 45100/60157............. Loss: 5.5153\n",
      "batch: 45120/60157............. Loss: 5.5160\n",
      "batch: 45140/60157............. Loss: 5.5147\n",
      "batch: 45160/60157............. Loss: 5.4807\n",
      "batch: 45180/60157............. Loss: 5.5149\n",
      "batch: 45200/60157............. Loss: 5.5225\n",
      "batch: 45220/60157............. Loss: 5.5182\n",
      "batch: 45240/60157............. Loss: 5.5124\n",
      "batch: 45260/60157............. Loss: 5.5040\n",
      "batch: 45280/60157............. Loss: 5.5173\n",
      "batch: 45300/60157............. Loss: 5.4918\n",
      "batch: 45320/60157............. Loss: 5.5156\n",
      "batch: 45340/60157............. Loss: 5.4705\n",
      "batch: 45360/60157............. Loss: 5.5166\n",
      "batch: 45380/60157............. Loss: 5.5109\n",
      "batch: 45400/60157............. Loss: 5.5147\n",
      "batch: 45420/60157............. Loss: 5.5160\n",
      "batch: 45440/60157............. Loss: 5.5221\n",
      "batch: 45460/60157............. Loss: 5.5108\n",
      "batch: 45480/60157............. Loss: 5.4770\n",
      "batch: 45500/60157............. Loss: 5.5131\n",
      "batch: 45520/60157............. Loss: 5.5165\n",
      "batch: 45540/60157............. Loss: 5.5188\n",
      "batch: 45560/60157............. Loss: 5.5223\n",
      "batch: 45580/60157............. Loss: 5.4984\n",
      "batch: 45600/60157............. Loss: 5.4778\n",
      "batch: 45620/60157............. Loss: 5.5117\n",
      "batch: 45640/60157............. Loss: 5.5136\n",
      "batch: 45660/60157............. Loss: 5.5112\n",
      "batch: 45680/60157............. Loss: 5.5116\n",
      "batch: 45700/60157............. Loss: 5.5109\n",
      "batch: 45720/60157............. Loss: 5.5046\n",
      "batch: 45740/60157............. Loss: 5.5106\n",
      "batch: 45760/60157............. Loss: 5.5187\n",
      "batch: 45780/60157............. Loss: 5.5210\n",
      "batch: 45800/60157............. Loss: 5.5173\n",
      "batch: 45820/60157............. Loss: 5.5030\n",
      "batch: 45840/60157............. Loss: 5.5119\n",
      "batch: 45860/60157............. Loss: 5.5203\n",
      "batch: 45880/60157............. Loss: 5.5179\n",
      "batch: 45900/60157............. Loss: 5.4299\n",
      "batch: 45920/60157............. Loss: 5.5105\n",
      "batch: 45940/60157............. Loss: 5.5153\n",
      "batch: 45960/60157............. Loss: 5.5110\n",
      "batch: 45980/60157............. Loss: 5.5188\n",
      "batch: 46000/60157............. Loss: 5.5200\n",
      "batch: 46020/60157............. Loss: 5.5167\n",
      "batch: 46040/60157............. Loss: 5.5147\n",
      "batch: 46060/60157............. Loss: 5.5145\n",
      "batch: 46080/60157............. Loss: 5.5151\n",
      "batch: 46100/60157............. Loss: 5.5187\n",
      "batch: 46120/60157............. Loss: 5.4910\n",
      "batch: 46140/60157............. Loss: 5.5238\n",
      "batch: 46160/60157............. Loss: 5.5072\n",
      "batch: 46180/60157............. Loss: 5.5196\n",
      "batch: 46200/60157............. Loss: 5.5175\n",
      "batch: 46220/60157............. Loss: 5.5162\n",
      "batch: 46240/60157............. Loss: 5.5167\n",
      "batch: 46260/60157............. Loss: 5.5034\n",
      "batch: 46280/60157............. Loss: 5.5133\n",
      "batch: 46300/60157............. Loss: 5.5194\n",
      "batch: 46320/60157............. Loss: 5.5196\n",
      "batch: 46340/60157............. Loss: 5.5026\n",
      "batch: 46360/60157............. Loss: 5.5218\n",
      "batch: 46380/60157............. Loss: 5.5161\n",
      "batch: 46400/60157............. Loss: 5.5004\n",
      "batch: 46420/60157............. Loss: 5.5080\n",
      "batch: 46440/60157............. Loss: 5.5017\n",
      "batch: 46460/60157............. Loss: 5.5094\n",
      "batch: 46480/60157............. Loss: 5.5166\n",
      "batch: 46500/60157............. Loss: 5.5238\n",
      "batch: 46520/60157............. Loss: 5.5237\n",
      "batch: 46540/60157............. Loss: 5.5184\n",
      "batch: 46560/60157............. Loss: 5.5140\n",
      "batch: 46580/60157............. Loss: 5.5116\n",
      "batch: 46600/60157............. Loss: 5.5057\n",
      "batch: 46620/60157............. Loss: 5.5148\n",
      "batch: 46640/60157............. Loss: 5.5180\n",
      "batch: 46660/60157............. Loss: 5.5118\n",
      "batch: 46680/60157............. Loss: 5.5228\n",
      "batch: 46700/60157............. Loss: 5.5192\n",
      "batch: 46720/60157............. Loss: 5.5146\n",
      "batch: 46740/60157............. Loss: 5.5166\n",
      "batch: 46760/60157............. Loss: 5.5166\n",
      "batch: 46780/60157............. Loss: 5.5226\n",
      "batch: 46800/60157............. Loss: 5.4884\n",
      "batch: 46820/60157............. Loss: 5.5221\n",
      "batch: 46840/60157............. Loss: 5.5049\n",
      "batch: 46860/60157............. Loss: 5.5165\n",
      "batch: 46880/60157............. Loss: 5.5180\n",
      "batch: 46900/60157............. Loss: 5.5173\n",
      "batch: 46920/60157............. Loss: 5.5103\n",
      "batch: 46940/60157............. Loss: 5.5060\n",
      "batch: 46960/60157............. Loss: 5.5019\n",
      "batch: 46980/60157............. Loss: 5.5185\n",
      "batch: 47000/60157............. Loss: 5.5118\n",
      "batch: 47020/60157............. Loss: 5.5167\n",
      "batch: 47040/60157............. Loss: 5.5141\n",
      "batch: 47060/60157............. Loss: 5.4925\n",
      "batch: 47080/60157............. Loss: 5.5133\n",
      "batch: 47100/60157............. Loss: 5.4952\n",
      "batch: 47120/60157............. Loss: 5.5020\n",
      "batch: 47140/60157............. Loss: 5.5210\n",
      "batch: 47160/60157............. Loss: 5.4788\n",
      "batch: 47180/60157............. Loss: 5.5079\n",
      "batch: 47200/60157............. Loss: 5.5193\n",
      "batch: 47220/60157............. Loss: 5.5132\n",
      "batch: 47240/60157............. Loss: 5.4718\n",
      "batch: 47260/60157............. Loss: 5.5140\n",
      "batch: 47280/60157............. Loss: 5.5183\n",
      "batch: 47300/60157............. Loss: 5.5022\n",
      "batch: 47320/60157............. Loss: 5.5161\n",
      "batch: 47340/60157............. Loss: 5.5173\n",
      "batch: 47360/60157............. Loss: 5.5100\n",
      "batch: 47380/60157............. Loss: 5.5068\n",
      "batch: 47400/60157............. Loss: 5.5118\n",
      "batch: 47420/60157............. Loss: 5.5145\n",
      "batch: 47440/60157............. Loss: 5.5063\n",
      "batch: 47460/60157............. Loss: 5.5213\n",
      "batch: 47480/60157............. Loss: 5.5203\n",
      "batch: 47500/60157............. Loss: 5.5164\n",
      "batch: 47520/60157............. Loss: 5.5216\n",
      "batch: 47540/60157............. Loss: 5.5116\n",
      "batch: 47560/60157............. Loss: 5.5012\n",
      "batch: 47580/60157............. Loss: 5.4945\n",
      "batch: 47600/60157............. Loss: 5.5040\n",
      "batch: 47620/60157............. Loss: 5.5046\n",
      "batch: 47640/60157............. Loss: 5.4985\n",
      "batch: 47660/60157............. Loss: 5.5191\n",
      "batch: 47680/60157............. Loss: 5.5223\n",
      "batch: 47700/60157............. Loss: 5.5145\n",
      "batch: 47720/60157............. Loss: 5.5096\n",
      "batch: 47740/60157............. Loss: 5.5157\n",
      "batch: 47760/60157............. Loss: 5.4900\n",
      "batch: 47780/60157............. Loss: 5.5182\n",
      "batch: 47800/60157............. Loss: 5.4978\n",
      "batch: 47820/60157............. Loss: 5.5198\n",
      "batch: 47840/60157............. Loss: 5.5026\n",
      "batch: 47860/60157............. Loss: 5.5198\n",
      "batch: 47880/60157............. Loss: 5.5054\n",
      "batch: 47900/60157............. Loss: 5.5157\n",
      "batch: 47920/60157............. Loss: 5.5160\n",
      "batch: 47940/60157............. Loss: 5.5178\n",
      "batch: 47960/60157............. Loss: 5.4798\n",
      "batch: 47980/60157............. Loss: 5.5198\n",
      "batch: 48000/60157............. Loss: 5.5142\n",
      "batch: 48020/60157............. Loss: 5.5210\n",
      "batch: 48040/60157............. Loss: 5.5201\n",
      "batch: 48060/60157............. Loss: 5.4970\n",
      "batch: 48080/60157............. Loss: 5.5159\n",
      "batch: 48100/60157............. Loss: 5.5218\n",
      "batch: 48120/60157............. Loss: 5.5100\n",
      "batch: 48140/60157............. Loss: 5.5186\n",
      "batch: 48160/60157............. Loss: 5.4867\n",
      "batch: 48180/60157............. Loss: 5.5156\n",
      "batch: 48200/60157............. Loss: 5.4945\n",
      "batch: 48220/60157............. Loss: 5.5094\n",
      "batch: 48240/60157............. Loss: 5.5144\n",
      "batch: 48260/60157............. Loss: 5.5065\n",
      "batch: 48280/60157............. Loss: 5.5058\n",
      "batch: 48300/60157............. Loss: 5.5194\n",
      "batch: 48320/60157............. Loss: 5.4949\n",
      "batch: 48340/60157............. Loss: 5.4769\n",
      "batch: 48360/60157............. Loss: 5.4745\n",
      "batch: 48380/60157............. Loss: 5.4790\n",
      "batch: 48400/60157............. Loss: 5.5182\n",
      "batch: 48420/60157............. Loss: 5.4128\n",
      "batch: 48440/60157............. Loss: 5.5171\n",
      "batch: 48460/60157............. Loss: 5.5229\n",
      "batch: 48480/60157............. Loss: 5.5186\n",
      "batch: 48500/60157............. Loss: 5.5199\n",
      "batch: 48520/60157............. Loss: 5.4981\n",
      "batch: 48540/60157............. Loss: 5.5153\n",
      "batch: 48560/60157............. Loss: 5.4683\n",
      "batch: 48580/60157............. Loss: 5.5230\n",
      "batch: 48600/60157............. Loss: 5.5187\n",
      "batch: 48620/60157............. Loss: 5.4785\n",
      "batch: 48640/60157............. Loss: 5.5147\n",
      "batch: 48660/60157............. Loss: 5.5155\n",
      "batch: 48680/60157............. Loss: 5.5219\n",
      "batch: 48700/60157............. Loss: 5.5124\n",
      "batch: 48720/60157............. Loss: 5.5152\n",
      "batch: 48740/60157............. Loss: 5.5107\n",
      "batch: 48760/60157............. Loss: 5.4753\n",
      "batch: 48780/60157............. Loss: 5.5217\n",
      "batch: 48800/60157............. Loss: 5.4926\n",
      "batch: 48820/60157............. Loss: 5.5167\n",
      "batch: 48840/60157............. Loss: 5.5130\n",
      "batch: 48860/60157............. Loss: 5.5105\n",
      "batch: 48880/60157............. Loss: 5.5177\n",
      "batch: 48900/60157............. Loss: 5.5176\n",
      "batch: 48920/60157............. Loss: 5.5143\n",
      "batch: 48940/60157............. Loss: 5.4871\n",
      "batch: 48960/60157............. Loss: 5.5177\n",
      "batch: 48980/60157............. Loss: 5.5146\n",
      "batch: 49000/60157............. Loss: 5.5057\n",
      "batch: 49020/60157............. Loss: 5.4948\n",
      "batch: 49040/60157............. Loss: 5.5190\n",
      "batch: 49060/60157............. Loss: 5.5221\n",
      "batch: 49080/60157............. Loss: 5.5119\n",
      "batch: 49100/60157............. Loss: 5.4973\n",
      "batch: 49120/60157............. Loss: 5.5108\n",
      "batch: 49140/60157............. Loss: 5.5082\n",
      "batch: 49160/60157............. Loss: 5.5139\n",
      "batch: 49180/60157............. Loss: 5.5234\n",
      "batch: 49200/60157............. Loss: 5.4819\n",
      "batch: 49220/60157............. Loss: 5.5194\n",
      "batch: 49240/60157............. Loss: 5.5186\n",
      "batch: 49260/60157............. Loss: 5.4745\n",
      "batch: 49280/60157............. Loss: 5.5126\n",
      "batch: 49300/60157............. Loss: 5.5138\n",
      "batch: 49320/60157............. Loss: 5.5181\n",
      "batch: 49340/60157............. Loss: 5.5155\n",
      "batch: 49360/60157............. Loss: 5.5121\n",
      "batch: 49380/60157............. Loss: 5.5137\n",
      "batch: 49400/60157............. Loss: 5.4985\n",
      "batch: 49420/60157............. Loss: 5.4232\n",
      "batch: 49440/60157............. Loss: 5.5145\n",
      "batch: 49460/60157............. Loss: 5.5055\n",
      "batch: 49480/60157............. Loss: 5.5161\n",
      "batch: 49500/60157............. Loss: 5.5187\n",
      "batch: 49520/60157............. Loss: 5.5174\n",
      "batch: 49540/60157............. Loss: 5.5017\n",
      "batch: 49560/60157............. Loss: 5.4628\n",
      "batch: 49580/60157............. Loss: 5.5105\n",
      "batch: 49600/60157............. Loss: 5.5211\n",
      "batch: 49620/60157............. Loss: 5.4689\n",
      "batch: 49640/60157............. Loss: 5.5080\n",
      "batch: 49660/60157............. Loss: 5.5201\n",
      "batch: 49680/60157............. Loss: 5.5101\n",
      "batch: 49700/60157............. Loss: 5.5050\n",
      "batch: 49720/60157............. Loss: 5.5210\n",
      "batch: 49740/60157............. Loss: 5.4807\n",
      "batch: 49760/60157............. Loss: 5.5130\n",
      "batch: 49780/60157............. Loss: 5.5146\n",
      "batch: 49800/60157............. Loss: 5.5227\n",
      "batch: 49820/60157............. Loss: 5.5179\n",
      "batch: 49840/60157............. Loss: 5.5153\n",
      "batch: 49860/60157............. Loss: 5.5248\n",
      "batch: 49880/60157............. Loss: 5.5207\n",
      "batch: 49900/60157............. Loss: 5.5184\n",
      "batch: 49920/60157............. Loss: 5.4946\n",
      "batch: 49940/60157............. Loss: 5.5052\n",
      "batch: 49960/60157............. Loss: 5.5160\n",
      "batch: 49980/60157............. Loss: 5.4959\n",
      "batch: 50000/60157............. Loss: 5.5202\n",
      "batch: 50020/60157............. Loss: 5.5105\n",
      "batch: 50040/60157............. Loss: 5.5216\n",
      "batch: 50060/60157............. Loss: 5.5235\n",
      "batch: 50080/60157............. Loss: 5.4680\n",
      "batch: 50100/60157............. Loss: 5.5120\n",
      "batch: 50120/60157............. Loss: 5.5104\n",
      "batch: 50140/60157............. Loss: 5.5055\n",
      "batch: 50160/60157............. Loss: 5.5142\n",
      "batch: 50180/60157............. Loss: 5.4948\n",
      "batch: 50200/60157............. Loss: 5.5136\n",
      "batch: 50220/60157............. Loss: 5.5153\n",
      "batch: 50240/60157............. Loss: 5.5194\n",
      "batch: 50260/60157............. Loss: 5.5212\n",
      "batch: 50280/60157............. Loss: 5.5240\n",
      "batch: 50300/60157............. Loss: 5.5203\n",
      "batch: 50320/60157............. Loss: 5.5174\n",
      "batch: 50340/60157............. Loss: 5.5143\n",
      "batch: 50360/60157............. Loss: 5.5200\n",
      "batch: 50380/60157............. Loss: 5.5105\n",
      "batch: 50400/60157............. Loss: 5.5185\n",
      "batch: 50420/60157............. Loss: 5.4680\n",
      "batch: 50440/60157............. Loss: 5.5224\n",
      "batch: 50460/60157............. Loss: 5.5090\n",
      "batch: 50480/60157............. Loss: 5.5131\n",
      "batch: 50500/60157............. Loss: 5.4942\n",
      "batch: 50520/60157............. Loss: 5.5182\n",
      "batch: 50540/60157............. Loss: 5.5098\n",
      "batch: 50560/60157............. Loss: 5.5174\n",
      "batch: 50580/60157............. Loss: 5.5118\n",
      "batch: 50600/60157............. Loss: 5.5037\n",
      "batch: 50620/60157............. Loss: 5.4969\n",
      "batch: 50640/60157............. Loss: 5.5172\n",
      "batch: 50660/60157............. Loss: 5.5187\n",
      "batch: 50680/60157............. Loss: 5.5133\n",
      "batch: 50700/60157............. Loss: 5.5165\n",
      "batch: 50720/60157............. Loss: 5.5129\n",
      "batch: 50740/60157............. Loss: 5.5181\n",
      "batch: 50760/60157............. Loss: 5.5198\n",
      "batch: 50780/60157............. Loss: 5.5147\n",
      "batch: 50800/60157............. Loss: 5.5103\n",
      "batch: 50820/60157............. Loss: 5.5166\n",
      "batch: 50840/60157............. Loss: 5.5078\n",
      "batch: 50860/60157............. Loss: 5.5162\n",
      "batch: 50880/60157............. Loss: 5.5177\n",
      "batch: 50900/60157............. Loss: 5.5166\n",
      "batch: 50920/60157............. Loss: 5.5059\n",
      "batch: 50940/60157............. Loss: 5.5134\n",
      "batch: 50960/60157............. Loss: 5.5111\n",
      "batch: 50980/60157............. Loss: 5.5135\n",
      "batch: 51000/60157............. Loss: 5.5223\n",
      "batch: 51020/60157............. Loss: 5.5065\n",
      "batch: 51040/60157............. Loss: 5.5096\n",
      "batch: 51060/60157............. Loss: 5.5189\n",
      "batch: 51080/60157............. Loss: 5.5225\n",
      "batch: 51100/60157............. Loss: 5.5190\n",
      "batch: 51120/60157............. Loss: 5.5174\n",
      "batch: 51140/60157............. Loss: 5.5157\n",
      "batch: 51160/60157............. Loss: 5.5103\n",
      "batch: 51180/60157............. Loss: 5.4704\n",
      "batch: 51200/60157............. Loss: 5.5083\n",
      "batch: 51220/60157............. Loss: 5.4835\n",
      "batch: 51240/60157............. Loss: 5.5090\n",
      "batch: 51260/60157............. Loss: 5.5181\n",
      "batch: 51280/60157............. Loss: 5.5104\n",
      "batch: 51300/60157............. Loss: 5.5232\n",
      "batch: 51320/60157............. Loss: 5.5153\n",
      "batch: 51340/60157............. Loss: 5.4966\n",
      "batch: 51360/60157............. Loss: 5.5145\n",
      "batch: 51380/60157............. Loss: 5.5157\n",
      "batch: 51400/60157............. Loss: 5.5148\n",
      "batch: 51420/60157............. Loss: 5.5167\n",
      "batch: 51440/60157............. Loss: 5.4654\n",
      "batch: 51460/60157............. Loss: 5.5186\n",
      "batch: 51480/60157............. Loss: 5.5183\n",
      "batch: 51500/60157............. Loss: 5.4984\n",
      "batch: 51520/60157............. Loss: 5.5210\n",
      "batch: 51540/60157............. Loss: 5.5010\n",
      "batch: 51560/60157............. Loss: 5.5036\n",
      "batch: 51580/60157............. Loss: 5.5232\n",
      "batch: 51600/60157............. Loss: 5.5122\n",
      "batch: 51620/60157............. Loss: 5.5075\n",
      "batch: 51640/60157............. Loss: 5.5155\n",
      "batch: 51660/60157............. Loss: 5.5176\n",
      "batch: 51680/60157............. Loss: 5.5155\n",
      "batch: 51700/60157............. Loss: 5.4849\n",
      "batch: 51720/60157............. Loss: 5.5147\n",
      "batch: 51740/60157............. Loss: 5.4955\n",
      "batch: 51760/60157............. Loss: 5.5181\n",
      "batch: 51780/60157............. Loss: 5.5132\n",
      "batch: 51800/60157............. Loss: 5.4934\n",
      "batch: 51820/60157............. Loss: 5.5171\n",
      "batch: 51840/60157............. Loss: 5.5156\n",
      "batch: 51860/60157............. Loss: 5.5149\n",
      "batch: 51880/60157............. Loss: 5.4757\n",
      "batch: 51900/60157............. Loss: 5.5079\n",
      "batch: 51920/60157............. Loss: 5.5134\n",
      "batch: 51940/60157............. Loss: 5.4660\n",
      "batch: 51960/60157............. Loss: 5.5158\n",
      "batch: 51980/60157............. Loss: 5.5159\n",
      "batch: 52000/60157............. Loss: 5.5185\n",
      "batch: 52020/60157............. Loss: 5.5109\n",
      "batch: 52040/60157............. Loss: 5.4755\n",
      "batch: 52060/60157............. Loss: 5.5016\n",
      "batch: 52080/60157............. Loss: 5.5120\n",
      "batch: 52100/60157............. Loss: 5.5224\n",
      "batch: 52120/60157............. Loss: 5.5211\n",
      "batch: 52140/60157............. Loss: 5.5116\n",
      "batch: 52160/60157............. Loss: 5.5013\n",
      "batch: 52180/60157............. Loss: 5.4968\n",
      "batch: 52200/60157............. Loss: 5.5178\n",
      "batch: 52220/60157............. Loss: 5.4897\n",
      "batch: 52240/60157............. Loss: 5.5168\n",
      "batch: 52260/60157............. Loss: 5.5161\n",
      "batch: 52280/60157............. Loss: 5.5146\n",
      "batch: 52300/60157............. Loss: 5.4865\n",
      "batch: 52320/60157............. Loss: 5.5163\n",
      "batch: 52340/60157............. Loss: 5.5176\n",
      "batch: 52360/60157............. Loss: 5.4950\n",
      "batch: 52380/60157............. Loss: 5.5138\n",
      "batch: 52400/60157............. Loss: 5.5086\n",
      "batch: 52420/60157............. Loss: 5.5056\n",
      "batch: 52440/60157............. Loss: 5.5202\n",
      "batch: 52460/60157............. Loss: 5.5162\n",
      "batch: 52480/60157............. Loss: 5.5010\n",
      "batch: 52500/60157............. Loss: 5.5102\n",
      "batch: 52520/60157............. Loss: 5.5188\n",
      "batch: 52540/60157............. Loss: 5.5188\n",
      "batch: 52560/60157............. Loss: 5.5185\n",
      "batch: 52580/60157............. Loss: 5.4877\n",
      "batch: 52600/60157............. Loss: 5.4967\n",
      "batch: 52620/60157............. Loss: 5.5135\n",
      "batch: 52640/60157............. Loss: 5.5188\n",
      "batch: 52660/60157............. Loss: 5.5129\n",
      "batch: 52680/60157............. Loss: 5.5078\n",
      "batch: 52700/60157............. Loss: 5.5135\n",
      "batch: 52720/60157............. Loss: 5.5044\n",
      "batch: 52740/60157............. Loss: 5.5218\n",
      "batch: 52760/60157............. Loss: 5.4967\n",
      "batch: 52780/60157............. Loss: 5.5184\n",
      "batch: 52800/60157............. Loss: 5.5113\n",
      "batch: 52820/60157............. Loss: 5.5220\n",
      "batch: 52840/60157............. Loss: 5.4739\n",
      "batch: 52860/60157............. Loss: 5.5142\n",
      "batch: 52880/60157............. Loss: 5.5204\n",
      "batch: 52900/60157............. Loss: 5.5102\n",
      "batch: 52920/60157............. Loss: 5.5131\n",
      "batch: 52940/60157............. Loss: 5.5191\n",
      "batch: 52960/60157............. Loss: 5.5068\n",
      "batch: 52980/60157............. Loss: 5.5180\n",
      "batch: 53000/60157............. Loss: 5.5145\n",
      "batch: 53020/60157............. Loss: 5.5193\n",
      "batch: 53040/60157............. Loss: 5.5252\n",
      "batch: 53060/60157............. Loss: 5.5186\n",
      "batch: 53080/60157............. Loss: 5.5178\n",
      "batch: 53100/60157............. Loss: 5.4843\n",
      "batch: 53120/60157............. Loss: 5.4943\n",
      "batch: 53140/60157............. Loss: 5.5175\n",
      "batch: 53160/60157............. Loss: 5.5042\n",
      "batch: 53180/60157............. Loss: 5.5157\n",
      "batch: 53200/60157............. Loss: 5.5189\n",
      "batch: 53220/60157............. Loss: 5.5212\n",
      "batch: 53240/60157............. Loss: 5.5133\n",
      "batch: 53260/60157............. Loss: 5.5153\n",
      "batch: 53280/60157............. Loss: 5.5225\n",
      "batch: 53300/60157............. Loss: 5.5084\n",
      "batch: 53320/60157............. Loss: 5.5136\n",
      "batch: 53340/60157............. Loss: 5.5135\n",
      "batch: 53360/60157............. Loss: 5.5151\n",
      "batch: 53380/60157............. Loss: 5.4827\n",
      "batch: 53400/60157............. Loss: 5.5132\n",
      "batch: 53420/60157............. Loss: 5.4996\n",
      "batch: 53440/60157............. Loss: 5.5219\n",
      "batch: 53460/60157............. Loss: 5.5099\n",
      "batch: 53480/60157............. Loss: 5.4934\n",
      "batch: 53500/60157............. Loss: 5.5097\n",
      "batch: 53520/60157............. Loss: 5.5155\n",
      "batch: 53540/60157............. Loss: 5.5218\n",
      "batch: 53560/60157............. Loss: 5.4999\n",
      "batch: 53580/60157............. Loss: 5.5178\n",
      "batch: 53600/60157............. Loss: 5.4778\n",
      "batch: 53620/60157............. Loss: 5.5194\n",
      "batch: 53640/60157............. Loss: 5.5111\n",
      "batch: 53660/60157............. Loss: 5.5191\n",
      "batch: 53680/60157............. Loss: 5.4806\n",
      "batch: 53700/60157............. Loss: 5.5106\n",
      "batch: 53720/60157............. Loss: 5.4498\n",
      "batch: 53740/60157............. Loss: 5.4597\n",
      "batch: 53760/60157............. Loss: 5.5203\n",
      "batch: 53780/60157............. Loss: 5.5171\n",
      "batch: 53800/60157............. Loss: 5.5104\n",
      "batch: 53820/60157............. Loss: 5.5066\n",
      "batch: 53840/60157............. Loss: 5.5183\n",
      "batch: 53860/60157............. Loss: 5.5195\n",
      "batch: 53880/60157............. Loss: 5.5175\n",
      "batch: 53900/60157............. Loss: 5.5104\n",
      "batch: 53920/60157............. Loss: 5.5132\n",
      "batch: 53940/60157............. Loss: 5.5180\n",
      "batch: 53960/60157............. Loss: 5.5188\n",
      "batch: 53980/60157............. Loss: 5.5148\n",
      "batch: 54000/60157............. Loss: 5.4903\n",
      "batch: 54020/60157............. Loss: 5.5196\n",
      "batch: 54040/60157............. Loss: 5.5171\n",
      "batch: 54060/60157............. Loss: 5.5186\n",
      "batch: 54080/60157............. Loss: 5.5187\n",
      "batch: 54100/60157............. Loss: 5.5128\n",
      "batch: 54120/60157............. Loss: 5.5159\n",
      "batch: 54140/60157............. Loss: 5.5165\n",
      "batch: 54160/60157............. Loss: 5.5083\n",
      "batch: 54180/60157............. Loss: 5.5199\n",
      "batch: 54200/60157............. Loss: 5.5227\n",
      "batch: 54220/60157............. Loss: 5.5134\n",
      "batch: 54240/60157............. Loss: 5.5228\n",
      "batch: 54260/60157............. Loss: 5.5186\n",
      "batch: 54280/60157............. Loss: 5.4883\n",
      "batch: 54300/60157............. Loss: 5.5159\n",
      "batch: 54320/60157............. Loss: 5.5195\n",
      "batch: 54340/60157............. Loss: 5.5064\n",
      "batch: 54360/60157............. Loss: 5.5179\n",
      "batch: 54380/60157............. Loss: 5.5182\n",
      "batch: 54400/60157............. Loss: 5.5228\n",
      "batch: 54420/60157............. Loss: 5.5109\n",
      "batch: 54440/60157............. Loss: 5.5197\n",
      "batch: 54460/60157............. Loss: 5.5170\n",
      "batch: 54480/60157............. Loss: 5.5114\n",
      "batch: 54500/60157............. Loss: 5.5127\n",
      "batch: 54520/60157............. Loss: 5.5103\n",
      "batch: 54540/60157............. Loss: 5.4472\n",
      "batch: 54560/60157............. Loss: 5.5179\n",
      "batch: 54580/60157............. Loss: 5.5126\n",
      "batch: 54600/60157............. Loss: 5.5129\n",
      "batch: 54620/60157............. Loss: 5.4882\n",
      "batch: 54640/60157............. Loss: 5.5114\n",
      "batch: 54660/60157............. Loss: 5.5151\n",
      "batch: 54680/60157............. Loss: 5.4857\n",
      "batch: 54700/60157............. Loss: 5.5175\n",
      "batch: 54720/60157............. Loss: 5.5002\n",
      "batch: 54740/60157............. Loss: 5.5131\n",
      "batch: 54760/60157............. Loss: 5.5059\n",
      "batch: 54780/60157............. Loss: 5.5188\n",
      "batch: 54800/60157............. Loss: 5.5227\n",
      "batch: 54820/60157............. Loss: 5.4883\n",
      "batch: 54840/60157............. Loss: 5.5244\n",
      "batch: 54860/60157............. Loss: 5.5168\n",
      "batch: 54880/60157............. Loss: 5.5051\n",
      "batch: 54900/60157............. Loss: 5.5210\n",
      "batch: 54920/60157............. Loss: 5.5216\n",
      "batch: 54940/60157............. Loss: 5.5095\n",
      "batch: 54960/60157............. Loss: 5.5128\n",
      "batch: 54980/60157............. Loss: 5.5108\n",
      "batch: 55000/60157............. Loss: 5.5120\n",
      "batch: 55020/60157............. Loss: 5.5109\n",
      "batch: 55040/60157............. Loss: 5.5188\n",
      "batch: 55060/60157............. Loss: 5.5166\n",
      "batch: 55080/60157............. Loss: 5.5200\n",
      "batch: 55100/60157............. Loss: 5.5012\n",
      "batch: 55120/60157............. Loss: 5.5165\n",
      "batch: 55140/60157............. Loss: 5.5187\n",
      "batch: 55160/60157............. Loss: 5.4920\n",
      "batch: 55180/60157............. Loss: 5.5145\n",
      "batch: 55200/60157............. Loss: 5.5174\n",
      "batch: 55220/60157............. Loss: 5.5214\n",
      "batch: 55240/60157............. Loss: 5.5112\n",
      "batch: 55260/60157............. Loss: 5.5111\n",
      "batch: 55280/60157............. Loss: 5.5118\n",
      "batch: 55300/60157............. Loss: 5.5165\n",
      "batch: 55320/60157............. Loss: 5.5215\n",
      "batch: 55340/60157............. Loss: 5.5177\n",
      "batch: 55360/60157............. Loss: 5.5193\n",
      "batch: 55380/60157............. Loss: 5.5111\n",
      "batch: 55400/60157............. Loss: 5.5219\n",
      "batch: 55420/60157............. Loss: 5.4680\n",
      "batch: 55440/60157............. Loss: 5.5015\n",
      "batch: 55460/60157............. Loss: 5.4861\n",
      "batch: 55480/60157............. Loss: 5.5106\n",
      "batch: 55500/60157............. Loss: 5.5175\n",
      "batch: 55520/60157............. Loss: 5.5082\n",
      "batch: 55540/60157............. Loss: 5.5009\n",
      "batch: 55560/60157............. Loss: 5.5182\n",
      "batch: 55580/60157............. Loss: 5.4984\n",
      "batch: 55600/60157............. Loss: 5.5149\n",
      "batch: 55620/60157............. Loss: 5.4819\n",
      "batch: 55640/60157............. Loss: 5.5017\n",
      "batch: 55660/60157............. Loss: 5.5189\n",
      "batch: 55680/60157............. Loss: 5.5110\n",
      "batch: 55700/60157............. Loss: 5.5179\n",
      "batch: 55720/60157............. Loss: 5.5187\n",
      "batch: 55740/60157............. Loss: 5.5184\n",
      "batch: 55760/60157............. Loss: 5.4756\n",
      "batch: 55780/60157............. Loss: 5.5155\n",
      "batch: 55800/60157............. Loss: 5.5101\n",
      "batch: 55820/60157............. Loss: 5.5223\n",
      "batch: 55840/60157............. Loss: 5.5178\n",
      "batch: 55860/60157............. Loss: 5.4864\n",
      "batch: 55880/60157............. Loss: 5.5140\n",
      "batch: 55900/60157............. Loss: 5.5115\n",
      "batch: 55920/60157............. Loss: 5.5153\n",
      "batch: 55940/60157............. Loss: 5.5146\n",
      "batch: 55960/60157............. Loss: 5.5213\n",
      "batch: 55980/60157............. Loss: 5.5171\n",
      "batch: 56000/60157............. Loss: 5.5200\n",
      "batch: 56020/60157............. Loss: 5.5246\n",
      "batch: 56040/60157............. Loss: 5.5052\n",
      "batch: 56060/60157............. Loss: 5.5189\n",
      "batch: 56080/60157............. Loss: 5.5049\n",
      "batch: 56100/60157............. Loss: 5.5171\n",
      "batch: 56120/60157............. Loss: 5.5130\n",
      "batch: 56140/60157............. Loss: 5.5130\n",
      "batch: 56160/60157............. Loss: 5.5123\n",
      "batch: 56180/60157............. Loss: 5.5119\n",
      "batch: 56200/60157............. Loss: 5.5239\n",
      "batch: 56220/60157............. Loss: 5.4893\n",
      "batch: 56240/60157............. Loss: 5.5107\n",
      "batch: 56260/60157............. Loss: 5.5158\n",
      "batch: 56280/60157............. Loss: 5.4957\n",
      "batch: 56300/60157............. Loss: 5.5124\n",
      "batch: 56320/60157............. Loss: 5.5118\n",
      "batch: 56340/60157............. Loss: 5.5186\n",
      "batch: 56360/60157............. Loss: 5.5173\n",
      "batch: 56380/60157............. Loss: 5.5059\n",
      "batch: 56400/60157............. Loss: 5.5155\n",
      "batch: 56420/60157............. Loss: 5.5125\n",
      "batch: 56440/60157............. Loss: 5.5122\n",
      "batch: 56460/60157............. Loss: 5.5166\n",
      "batch: 56480/60157............. Loss: 5.5093\n",
      "batch: 56500/60157............. Loss: 5.5017\n",
      "batch: 56520/60157............. Loss: 5.5197\n",
      "batch: 56540/60157............. Loss: 5.5094\n",
      "batch: 56560/60157............. Loss: 5.4862\n",
      "batch: 56580/60157............. Loss: 5.5129\n",
      "batch: 56600/60157............. Loss: 5.5111\n",
      "batch: 56620/60157............. Loss: 5.5191\n",
      "batch: 56640/60157............. Loss: 5.5113\n",
      "batch: 56660/60157............. Loss: 5.5097\n",
      "batch: 56680/60157............. Loss: 5.4954\n",
      "batch: 56700/60157............. Loss: 5.5159\n",
      "batch: 56720/60157............. Loss: 5.5097\n",
      "batch: 56740/60157............. Loss: 5.5158\n",
      "batch: 56760/60157............. Loss: 5.5015\n",
      "batch: 56780/60157............. Loss: 5.5139\n",
      "batch: 56800/60157............. Loss: 5.4708\n",
      "batch: 56820/60157............. Loss: 5.5058\n",
      "batch: 56840/60157............. Loss: 5.5198\n",
      "batch: 56860/60157............. Loss: 5.5043\n",
      "batch: 56880/60157............. Loss: 5.5191\n",
      "batch: 56900/60157............. Loss: 5.5130\n",
      "batch: 56920/60157............. Loss: 5.5153\n",
      "batch: 56940/60157............. Loss: 5.4968\n",
      "batch: 56960/60157............. Loss: 5.5130\n",
      "batch: 56980/60157............. Loss: 5.5185\n",
      "batch: 57000/60157............. Loss: 5.5189\n",
      "batch: 57020/60157............. Loss: 5.5137\n",
      "batch: 57040/60157............. Loss: 5.5225\n",
      "batch: 57060/60157............. Loss: 5.5169\n",
      "batch: 57080/60157............. Loss: 5.4742\n",
      "batch: 57100/60157............. Loss: 5.4696\n",
      "batch: 57120/60157............. Loss: 5.4836\n",
      "batch: 57140/60157............. Loss: 5.4846\n",
      "batch: 57160/60157............. Loss: 5.5026\n",
      "batch: 57180/60157............. Loss: 5.5140\n",
      "batch: 57200/60157............. Loss: 5.5104\n",
      "batch: 57220/60157............. Loss: 5.5269\n",
      "batch: 57240/60157............. Loss: 5.4973\n",
      "batch: 57260/60157............. Loss: 5.5105\n",
      "batch: 57280/60157............. Loss: 5.5188\n",
      "batch: 57300/60157............. Loss: 5.5157\n",
      "batch: 57320/60157............. Loss: 5.5222\n",
      "batch: 57340/60157............. Loss: 5.5116\n",
      "batch: 57360/60157............. Loss: 5.5175\n",
      "batch: 57380/60157............. Loss: 5.5177\n",
      "batch: 57400/60157............. Loss: 5.5135\n",
      "batch: 57420/60157............. Loss: 5.5171\n",
      "batch: 57440/60157............. Loss: 5.5075\n",
      "batch: 57460/60157............. Loss: 5.5112\n",
      "batch: 57480/60157............. Loss: 5.5114\n",
      "batch: 57500/60157............. Loss: 5.5167\n",
      "batch: 57520/60157............. Loss: 5.4754\n",
      "batch: 57540/60157............. Loss: 5.4933\n",
      "batch: 57560/60157............. Loss: 5.5143\n",
      "batch: 57580/60157............. Loss: 5.5206\n",
      "batch: 57600/60157............. Loss: 5.4821\n",
      "batch: 57620/60157............. Loss: 5.5161\n",
      "batch: 57640/60157............. Loss: 5.5114\n",
      "batch: 57660/60157............. Loss: 5.5142\n",
      "batch: 57680/60157............. Loss: 5.5134\n",
      "batch: 57700/60157............. Loss: 5.5152\n",
      "batch: 57720/60157............. Loss: 5.5148\n",
      "batch: 57740/60157............. Loss: 5.5197\n",
      "batch: 57760/60157............. Loss: 5.5181\n",
      "batch: 57780/60157............. Loss: 5.5175\n",
      "batch: 57800/60157............. Loss: 5.5148\n",
      "batch: 57820/60157............. Loss: 5.5147\n",
      "batch: 57840/60157............. Loss: 5.5163\n",
      "batch: 57860/60157............. Loss: 5.5074\n",
      "batch: 57880/60157............. Loss: 5.5253\n",
      "batch: 57900/60157............. Loss: 5.5167\n",
      "batch: 57920/60157............. Loss: 5.5162\n",
      "batch: 57940/60157............. Loss: 5.4829\n",
      "batch: 57960/60157............. Loss: 5.5080\n",
      "batch: 57980/60157............. Loss: 5.5134\n",
      "batch: 58000/60157............. Loss: 5.4857\n",
      "batch: 58020/60157............. Loss: 5.5135\n",
      "batch: 58040/60157............. Loss: 5.4766\n",
      "batch: 58060/60157............. Loss: 5.5221\n",
      "batch: 58080/60157............. Loss: 5.4496\n",
      "batch: 58100/60157............. Loss: 5.5223\n",
      "batch: 58120/60157............. Loss: 5.5250\n",
      "batch: 58140/60157............. Loss: 5.5140\n",
      "batch: 58160/60157............. Loss: 5.4897\n",
      "batch: 58180/60157............. Loss: 5.5268\n",
      "batch: 58200/60157............. Loss: 5.5247\n",
      "batch: 58220/60157............. Loss: 5.5054\n",
      "batch: 58240/60157............. Loss: 5.5223\n",
      "batch: 58260/60157............. Loss: 5.5189\n",
      "batch: 58280/60157............. Loss: 5.5217\n",
      "batch: 58300/60157............. Loss: 5.5173\n",
      "batch: 58320/60157............. Loss: 5.4915\n",
      "batch: 58340/60157............. Loss: 5.4889\n",
      "batch: 58360/60157............. Loss: 5.5000\n",
      "batch: 58380/60157............. Loss: 5.5201\n",
      "batch: 58400/60157............. Loss: 5.5086\n",
      "batch: 58420/60157............. Loss: 5.5165\n",
      "batch: 58440/60157............. Loss: 5.5182\n",
      "batch: 58460/60157............. Loss: 5.5191\n",
      "batch: 58480/60157............. Loss: 5.5130\n",
      "batch: 58500/60157............. Loss: 5.5166\n",
      "batch: 58520/60157............. Loss: 5.5138\n",
      "batch: 58540/60157............. Loss: 5.5220\n",
      "batch: 58560/60157............. Loss: 5.5094\n",
      "batch: 58580/60157............. Loss: 5.5146\n",
      "batch: 58600/60157............. Loss: 5.5229\n",
      "batch: 58620/60157............. Loss: 5.5120\n",
      "batch: 58640/60157............. Loss: 5.5054\n",
      "batch: 58660/60157............. Loss: 5.5198\n",
      "batch: 58680/60157............. Loss: 5.5237\n",
      "batch: 58700/60157............. Loss: 5.5197\n",
      "batch: 58720/60157............. Loss: 5.5134\n",
      "batch: 58740/60157............. Loss: 5.5219\n",
      "batch: 58760/60157............. Loss: 5.5209\n",
      "batch: 58780/60157............. Loss: 5.5220\n",
      "batch: 58800/60157............. Loss: 5.4867\n",
      "batch: 58820/60157............. Loss: 5.5148\n",
      "batch: 58840/60157............. Loss: 5.5112\n",
      "batch: 58860/60157............. Loss: 5.5133\n",
      "batch: 58880/60157............. Loss: 5.4918\n",
      "batch: 58900/60157............. Loss: 5.5026\n",
      "batch: 58920/60157............. Loss: 5.5094\n",
      "batch: 58940/60157............. Loss: 5.5191\n",
      "batch: 58960/60157............. Loss: 5.5099\n",
      "batch: 58980/60157............. Loss: 5.5169\n",
      "batch: 59000/60157............. Loss: 5.5080\n",
      "batch: 59020/60157............. Loss: 5.5174\n",
      "batch: 59040/60157............. Loss: 5.5116\n",
      "batch: 59060/60157............. Loss: 5.5230\n",
      "batch: 59080/60157............. Loss: 5.5214\n",
      "batch: 59100/60157............. Loss: 5.5192\n",
      "batch: 59120/60157............. Loss: 5.4994\n",
      "batch: 59140/60157............. Loss: 5.4953\n",
      "batch: 59160/60157............. Loss: 5.5003\n",
      "batch: 59180/60157............. Loss: 5.5127\n",
      "batch: 59200/60157............. Loss: 5.5002\n",
      "batch: 59220/60157............. Loss: 5.5166\n",
      "batch: 59240/60157............. Loss: 5.5187\n",
      "batch: 59260/60157............. Loss: 5.5201\n",
      "batch: 59280/60157............. Loss: 5.5223\n",
      "batch: 59300/60157............. Loss: 5.5186\n",
      "batch: 59320/60157............. Loss: 5.5158\n",
      "batch: 59340/60157............. Loss: 5.5077\n",
      "batch: 59360/60157............. Loss: 5.5093\n",
      "batch: 59380/60157............. Loss: 5.5020\n",
      "batch: 59400/60157............. Loss: 5.5039\n",
      "batch: 59420/60157............. Loss: 5.5098\n",
      "batch: 59440/60157............. Loss: 5.5147\n",
      "batch: 59460/60157............. Loss: 5.5116\n",
      "batch: 59480/60157............. Loss: 5.5166\n",
      "batch: 59500/60157............. Loss: 5.5121\n",
      "batch: 59520/60157............. Loss: 5.5152\n",
      "batch: 59540/60157............. Loss: 5.4846\n",
      "batch: 59560/60157............. Loss: 5.5206\n",
      "batch: 59580/60157............. Loss: 5.5094\n",
      "batch: 59600/60157............. Loss: 5.5145\n",
      "batch: 59620/60157............. Loss: 5.5193\n",
      "batch: 59640/60157............. Loss: 5.5174\n",
      "batch: 59660/60157............. Loss: 5.5003\n",
      "batch: 59680/60157............. Loss: 5.5136\n",
      "batch: 59700/60157............. Loss: 5.4790\n",
      "batch: 59720/60157............. Loss: 5.5065\n",
      "batch: 59740/60157............. Loss: 5.5129\n",
      "batch: 59760/60157............. Loss: 5.4746\n",
      "batch: 59780/60157............. Loss: 5.5039\n",
      "batch: 59800/60157............. Loss: 5.5163\n",
      "batch: 59820/60157............. Loss: 5.5011\n",
      "batch: 59840/60157............. Loss: 5.5196\n",
      "batch: 59860/60157............. Loss: 5.5170\n",
      "batch: 59880/60157............. Loss: 5.5159\n",
      "batch: 59900/60157............. Loss: 5.5032\n",
      "batch: 59920/60157............. Loss: 5.5185\n",
      "batch: 59940/60157............. Loss: 5.4919\n",
      "batch: 59960/60157............. Loss: 5.5145\n",
      "batch: 59980/60157............. Loss: 5.5102\n",
      "batch: 60000/60157............. Loss: 5.5149\n",
      "batch: 60020/60157............. Loss: 5.5131\n",
      "batch: 60040/60157............. Loss: 5.5129\n",
      "batch: 60060/60157............. Loss: 5.5149\n",
      "batch: 60080/60157............. Loss: 5.5157\n",
      "batch: 60100/60157............. Loss: 5.5063\n",
      "batch: 60120/60157............. Loss: 5.5140\n",
      "batch: 60140/60157............. Loss: 5.5206\n",
      "batch: 60160/60157............. Loss: 5.5210\n",
      "Epoch: 1/1............. Loss: 5.5210\n",
      "CPU times: user 4h 6min 2s, sys: 28min 46s, total: 4h 34min 49s\n",
      "Wall time: 3h 41min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs=1\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad()\n",
    "        input_seq = input_seq.cuda()\n",
    "        target_seq = target_seq.cuda()\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_batch += BATCH_SIZE\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a303e-1997-4ee1-8fe9-17ee1ed9c673",
   "metadata": {},
   "source": [
    "torch.save(model, \"model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80b513-9b23-4e7c-b796-04784d74a728",
   "metadata": {},
   "source": [
    "Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b947369-5947-4785-ba3b-b6057e780256",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(input_seq, target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43964a5-a4ca-4460-9f7c-e90a0552aa6e",
   "metadata": {},
   "source": [
    "## **3. GRU con audio como input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a360e2-1e88-4315-81f8-eaf3f6f6aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalVideoDatasetAprox1(set_selected=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316323d5-bac6-4bc0-9eb7-9f24b5d73114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con 60157 instancias con las que poder trabajar\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar\"%(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb7139-cb0f-418a-ba77-9705abb9139e",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3305caf3-5d65-4413-b285-2b51d477a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a57431-35cb-4df7-8414-c62c457fa930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox3(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(0)\n",
    "model.cuda()\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbd487-7413-4ce9-a94e-3be9c20ab3c2",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8532d5-d722-4d36-8ad0-6e8c7e9fef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceccf3df-96d3-4f0e-870d-4304094f69ca",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0236f953-6155-4d3d-80a6-b5971ebe30ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos_mds/train/../src/Dataset.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sound_frames = torch.tensor(sound_frames, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 16/60157............. Loss: 5.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid new backstep -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 32/60157............. Loss: 5.5452\n",
      "batch: 48/60157............. Loss: 5.5439\n",
      "batch: 64/60157............. Loss: 5.5430\n",
      "batch: 80/60157............. Loss: 5.5421\n",
      "batch: 96/60157............. Loss: 5.5407\n",
      "batch: 112/60157............. Loss: 5.5398\n",
      "batch: 128/60157............. Loss: 5.5396\n",
      "batch: 144/60157............. Loss: 5.5393\n",
      "batch: 160/60157............. Loss: 5.5383\n",
      "batch: 176/60157............. Loss: 5.5345\n",
      "batch: 192/60157............. Loss: 5.5374\n",
      "batch: 208/60157............. Loss: 5.5366\n",
      "batch: 224/60157............. Loss: 5.5364\n",
      "batch: 240/60157............. Loss: 5.5351\n",
      "batch: 256/60157............. Loss: 5.5329\n",
      "batch: 272/60157............. Loss: 5.5380\n",
      "batch: 288/60157............. Loss: 5.5338\n",
      "batch: 304/60157............. Loss: 5.5337\n",
      "batch: 320/60157............. Loss: 5.5334\n",
      "batch: 336/60157............. Loss: 5.5337\n",
      "batch: 352/60157............. Loss: 5.5333\n",
      "batch: 368/60157............. Loss: 5.5307\n",
      "batch: 384/60157............. Loss: 5.5339\n",
      "batch: 400/60157............. Loss: 5.5319\n",
      "batch: 416/60157............. Loss: 5.5280\n",
      "batch: 432/60157............. Loss: 5.5367\n",
      "batch: 448/60157............. Loss: 5.5336\n",
      "batch: 464/60157............. Loss: 5.5302\n",
      "batch: 480/60157............. Loss: 5.5353\n",
      "batch: 496/60157............. Loss: 5.5336\n",
      "batch: 512/60157............. Loss: 5.5316\n",
      "batch: 528/60157............. Loss: 5.5296\n",
      "batch: 544/60157............. Loss: 5.5289\n",
      "batch: 560/60157............. Loss: 5.5298\n",
      "batch: 576/60157............. Loss: 5.5316\n",
      "batch: 592/60157............. Loss: 5.5301\n",
      "batch: 608/60157............. Loss: 5.5273\n",
      "batch: 624/60157............. Loss: 5.5297\n",
      "batch: 640/60157............. Loss: 5.5329\n",
      "batch: 656/60157............. Loss: 5.5283\n",
      "batch: 672/60157............. Loss: 5.5293\n",
      "batch: 688/60157............. Loss: 5.5313\n",
      "batch: 704/60157............. Loss: 5.5323\n",
      "batch: 720/60157............. Loss: 5.5288\n",
      "batch: 736/60157............. Loss: 5.5290\n",
      "batch: 752/60157............. Loss: 5.5310\n",
      "batch: 768/60157............. Loss: 5.5227\n",
      "batch: 784/60157............. Loss: 5.5166\n",
      "batch: 800/60157............. Loss: 5.5237\n",
      "batch: 816/60157............. Loss: 5.5329\n",
      "batch: 832/60157............. Loss: 5.5305\n",
      "batch: 848/60157............. Loss: 5.5338\n",
      "batch: 864/60157............. Loss: 5.5281\n",
      "batch: 880/60157............. Loss: 5.5262\n",
      "batch: 896/60157............. Loss: 5.5281\n",
      "batch: 912/60157............. Loss: 5.5237\n",
      "batch: 928/60157............. Loss: 5.5266\n",
      "batch: 944/60157............. Loss: 5.5297\n",
      "batch: 960/60157............. Loss: 5.5296\n",
      "batch: 976/60157............. Loss: 5.5292\n",
      "batch: 992/60157............. Loss: 5.5259\n",
      "batch: 1008/60157............. Loss: 5.5271\n",
      "batch: 1024/60157............. Loss: 5.5298\n",
      "batch: 1040/60157............. Loss: 5.5260\n",
      "batch: 1056/60157............. Loss: 5.5335\n",
      "batch: 1072/60157............. Loss: 5.5252\n",
      "batch: 1088/60157............. Loss: 5.5327\n",
      "batch: 1104/60157............. Loss: 5.5272\n",
      "batch: 1120/60157............. Loss: 5.5343\n",
      "batch: 1136/60157............. Loss: 5.5263\n",
      "batch: 1152/60157............. Loss: 5.5281\n",
      "batch: 1168/60157............. Loss: 5.5301\n",
      "batch: 1184/60157............. Loss: 5.5307\n",
      "batch: 1200/60157............. Loss: 5.5299\n",
      "batch: 1216/60157............. Loss: 5.5253\n",
      "batch: 1232/60157............. Loss: 5.5249\n",
      "batch: 1248/60157............. Loss: 5.5253\n",
      "batch: 1264/60157............. Loss: 5.5281\n",
      "batch: 1280/60157............. Loss: 5.5278\n",
      "batch: 1296/60157............. Loss: 5.5272\n",
      "batch: 1312/60157............. Loss: 5.5290\n",
      "batch: 1328/60157............. Loss: 5.5268\n",
      "batch: 1344/60157............. Loss: 5.5274\n",
      "batch: 1360/60157............. Loss: 5.5241\n",
      "batch: 1376/60157............. Loss: 5.5302\n",
      "batch: 1392/60157............. Loss: 5.5267\n",
      "batch: 1408/60157............. Loss: 5.5263\n",
      "batch: 1424/60157............. Loss: 5.5286\n",
      "batch: 1440/60157............. Loss: 5.5287\n",
      "batch: 1456/60157............. Loss: 5.5254\n",
      "batch: 1472/60157............. Loss: 5.5134\n",
      "batch: 1488/60157............. Loss: 5.5238\n",
      "batch: 1504/60157............. Loss: 5.5285\n",
      "batch: 1520/60157............. Loss: 5.5269\n",
      "batch: 1536/60157............. Loss: 5.5271\n",
      "batch: 1552/60157............. Loss: 5.5315\n",
      "batch: 1568/60157............. Loss: 5.5294\n",
      "batch: 1584/60157............. Loss: 5.5269\n",
      "batch: 1600/60157............. Loss: 5.5270\n",
      "batch: 1616/60157............. Loss: 5.5262\n",
      "batch: 1632/60157............. Loss: 5.5243\n",
      "batch: 1648/60157............. Loss: 5.5264\n",
      "batch: 1664/60157............. Loss: 5.5261\n",
      "batch: 1680/60157............. Loss: 5.5339\n",
      "batch: 1696/60157............. Loss: 5.5272\n",
      "batch: 1712/60157............. Loss: 5.5248\n",
      "batch: 1728/60157............. Loss: 5.5260\n",
      "batch: 1744/60157............. Loss: 5.5288\n",
      "batch: 1760/60157............. Loss: 5.5304\n",
      "batch: 1776/60157............. Loss: 5.5286\n",
      "batch: 1792/60157............. Loss: 5.5266\n",
      "batch: 1808/60157............. Loss: 5.5257\n",
      "batch: 1824/60157............. Loss: 5.5278\n",
      "batch: 1840/60157............. Loss: 5.5237\n",
      "batch: 1856/60157............. Loss: 5.5265\n",
      "batch: 1872/60157............. Loss: 5.5268\n",
      "batch: 1888/60157............. Loss: 5.5259\n",
      "batch: 1904/60157............. Loss: 5.5264\n",
      "batch: 1920/60157............. Loss: 5.5268\n",
      "batch: 1936/60157............. Loss: 5.5233\n",
      "batch: 1952/60157............. Loss: 5.5231\n",
      "batch: 1968/60157............. Loss: 5.5300\n",
      "batch: 1984/60157............. Loss: 5.5304\n",
      "batch: 2000/60157............. Loss: 5.5235\n",
      "batch: 2016/60157............. Loss: 5.5223\n",
      "batch: 2032/60157............. Loss: 5.5310\n",
      "batch: 2048/60157............. Loss: 5.5272\n",
      "batch: 2064/60157............. Loss: 5.5276\n",
      "batch: 2080/60157............. Loss: 5.5313\n",
      "batch: 2096/60157............. Loss: 5.5236\n",
      "batch: 2112/60157............. Loss: 5.5282\n",
      "batch: 2128/60157............. Loss: 5.5265\n",
      "batch: 2144/60157............. Loss: 5.5288\n",
      "batch: 2160/60157............. Loss: 5.5282\n",
      "batch: 2176/60157............. Loss: 5.5253\n",
      "batch: 2192/60157............. Loss: 5.5270\n",
      "batch: 2208/60157............. Loss: 5.5258\n",
      "batch: 2224/60157............. Loss: 5.5254\n",
      "batch: 2240/60157............. Loss: 5.5264\n",
      "batch: 2256/60157............. Loss: 5.5246\n",
      "batch: 2272/60157............. Loss: 5.5254\n",
      "batch: 2288/60157............. Loss: 5.5280\n",
      "batch: 2304/60157............. Loss: 5.5281\n",
      "batch: 2320/60157............. Loss: 5.5279\n",
      "batch: 2336/60157............. Loss: 5.5195\n",
      "batch: 2352/60157............. Loss: 5.5238\n",
      "batch: 2368/60157............. Loss: 5.5215\n",
      "batch: 2384/60157............. Loss: 5.5256\n",
      "batch: 2400/60157............. Loss: 5.5255\n",
      "batch: 2416/60157............. Loss: 5.5277\n",
      "batch: 2432/60157............. Loss: 5.5219\n",
      "batch: 2448/60157............. Loss: 5.5247\n",
      "batch: 2464/60157............. Loss: 5.5263\n",
      "batch: 2480/60157............. Loss: 5.5261\n",
      "batch: 2496/60157............. Loss: 5.5268\n",
      "batch: 2512/60157............. Loss: 5.5212\n",
      "batch: 2528/60157............. Loss: 5.5294\n",
      "batch: 2544/60157............. Loss: 5.5258\n",
      "batch: 2560/60157............. Loss: 5.5223\n",
      "batch: 2576/60157............. Loss: 5.5268\n",
      "batch: 2592/60157............. Loss: 5.5272\n",
      "batch: 2608/60157............. Loss: 5.5279\n",
      "batch: 2624/60157............. Loss: 5.5275\n",
      "batch: 2640/60157............. Loss: 5.5282\n",
      "batch: 2656/60157............. Loss: 5.5253\n",
      "batch: 2672/60157............. Loss: 5.5272\n",
      "batch: 2688/60157............. Loss: 5.5238\n",
      "batch: 2704/60157............. Loss: 5.5225\n",
      "batch: 2720/60157............. Loss: 5.5217\n",
      "batch: 2736/60157............. Loss: 5.5219\n",
      "batch: 2752/60157............. Loss: 5.5222\n",
      "batch: 2768/60157............. Loss: 5.5273\n",
      "batch: 2784/60157............. Loss: 5.5221\n",
      "batch: 2800/60157............. Loss: 5.5269\n",
      "batch: 2816/60157............. Loss: 5.5328\n",
      "batch: 2832/60157............. Loss: 5.5232\n",
      "batch: 2848/60157............. Loss: 5.5245\n",
      "batch: 2864/60157............. Loss: 5.5256\n",
      "batch: 2880/60157............. Loss: 5.5301\n",
      "batch: 2896/60157............. Loss: 5.5279\n",
      "batch: 2912/60157............. Loss: 5.5274\n",
      "batch: 2928/60157............. Loss: 5.5256\n",
      "batch: 2944/60157............. Loss: 5.5281\n",
      "batch: 2960/60157............. Loss: 5.5222\n",
      "batch: 2976/60157............. Loss: 5.5259\n",
      "batch: 2992/60157............. Loss: 5.5285\n",
      "batch: 3008/60157............. Loss: 5.5307\n",
      "batch: 3024/60157............. Loss: 5.5192\n",
      "batch: 3040/60157............. Loss: 5.5258\n",
      "batch: 3056/60157............. Loss: 5.5248\n",
      "batch: 3072/60157............. Loss: 5.5284\n",
      "batch: 3088/60157............. Loss: 5.5170\n",
      "batch: 3104/60157............. Loss: 5.5261\n",
      "batch: 3120/60157............. Loss: 5.5271\n",
      "batch: 3136/60157............. Loss: 5.5246\n",
      "batch: 3152/60157............. Loss: 5.5307\n",
      "batch: 3168/60157............. Loss: 5.5221\n",
      "batch: 3184/60157............. Loss: 5.5335\n",
      "batch: 3200/60157............. Loss: 5.5251\n",
      "batch: 3216/60157............. Loss: 5.5230\n",
      "batch: 3232/60157............. Loss: 5.5286\n",
      "batch: 3248/60157............. Loss: 5.5225\n",
      "batch: 3264/60157............. Loss: 5.5311\n",
      "batch: 3280/60157............. Loss: 5.5321\n",
      "batch: 3296/60157............. Loss: 5.5231\n",
      "batch: 3312/60157............. Loss: 5.5279\n",
      "batch: 3328/60157............. Loss: 5.5261\n",
      "batch: 3344/60157............. Loss: 5.5230\n",
      "batch: 3360/60157............. Loss: 5.5274\n",
      "batch: 3376/60157............. Loss: 5.5269\n",
      "batch: 3392/60157............. Loss: 5.5230\n",
      "batch: 3408/60157............. Loss: 5.5244\n",
      "batch: 3424/60157............. Loss: 5.5362\n",
      "batch: 3440/60157............. Loss: 5.5256\n",
      "batch: 3456/60157............. Loss: 5.5251\n",
      "batch: 3472/60157............. Loss: 5.5253\n",
      "batch: 3488/60157............. Loss: 5.5221\n",
      "batch: 3504/60157............. Loss: 5.5260\n",
      "batch: 3520/60157............. Loss: 5.5249\n",
      "batch: 3536/60157............. Loss: 5.5239\n",
      "batch: 3552/60157............. Loss: 5.5262\n",
      "batch: 3568/60157............. Loss: 5.5255\n",
      "batch: 3584/60157............. Loss: 5.5269\n",
      "batch: 3600/60157............. Loss: 5.5264\n",
      "batch: 3616/60157............. Loss: 5.5226\n",
      "batch: 3632/60157............. Loss: 5.5261\n",
      "batch: 3648/60157............. Loss: 5.5253\n",
      "batch: 3664/60157............. Loss: 5.5295\n",
      "batch: 3680/60157............. Loss: 5.5248\n",
      "batch: 3696/60157............. Loss: 5.5264\n",
      "batch: 3712/60157............. Loss: 5.5258\n",
      "batch: 3728/60157............. Loss: 5.5264\n",
      "batch: 3744/60157............. Loss: 5.5278\n",
      "batch: 3760/60157............. Loss: 5.5216\n",
      "batch: 3776/60157............. Loss: 5.5256\n",
      "batch: 3792/60157............. Loss: 5.5248\n",
      "batch: 3808/60157............. Loss: 5.5270\n",
      "batch: 3824/60157............. Loss: 5.5258\n",
      "batch: 3840/60157............. Loss: 5.5270\n",
      "batch: 3856/60157............. Loss: 5.5273\n",
      "batch: 3872/60157............. Loss: 5.5284\n",
      "batch: 3888/60157............. Loss: 5.5297\n",
      "batch: 3904/60157............. Loss: 5.5272\n",
      "batch: 3920/60157............. Loss: 5.5241\n",
      "batch: 3936/60157............. Loss: 5.5261\n",
      "batch: 3952/60157............. Loss: 5.5240\n",
      "batch: 3968/60157............. Loss: 5.5275\n",
      "batch: 3984/60157............. Loss: 5.5300\n",
      "batch: 4000/60157............. Loss: 5.5223\n",
      "batch: 4016/60157............. Loss: 5.5264\n",
      "batch: 4032/60157............. Loss: 5.5270\n",
      "batch: 4048/60157............. Loss: 5.5264\n",
      "batch: 4064/60157............. Loss: 5.5241\n",
      "batch: 4080/60157............. Loss: 5.5181\n",
      "batch: 4096/60157............. Loss: 5.5251\n",
      "batch: 4112/60157............. Loss: 5.5298\n",
      "batch: 4128/60157............. Loss: 5.5251\n",
      "batch: 4144/60157............. Loss: 5.5240\n",
      "batch: 4160/60157............. Loss: 5.5294\n",
      "batch: 4176/60157............. Loss: 5.5256\n",
      "batch: 4192/60157............. Loss: 5.5192\n",
      "batch: 4208/60157............. Loss: 5.5271\n",
      "batch: 4224/60157............. Loss: 5.5237\n",
      "batch: 4240/60157............. Loss: 5.5215\n",
      "batch: 4256/60157............. Loss: 5.5188\n",
      "batch: 4272/60157............. Loss: 5.5191\n",
      "batch: 4288/60157............. Loss: 5.5210\n",
      "batch: 4304/60157............. Loss: 5.5232\n",
      "batch: 4320/60157............. Loss: 5.5260\n",
      "batch: 4336/60157............. Loss: 5.5236\n",
      "batch: 4352/60157............. Loss: 5.5292\n",
      "batch: 4368/60157............. Loss: 5.5246\n",
      "batch: 4384/60157............. Loss: 5.5229\n",
      "batch: 4400/60157............. Loss: 5.5253\n",
      "batch: 4416/60157............. Loss: 5.5255\n",
      "batch: 4432/60157............. Loss: 5.5256\n",
      "batch: 4448/60157............. Loss: 5.5268\n",
      "batch: 4464/60157............. Loss: 5.5223\n",
      "batch: 4480/60157............. Loss: 5.5203\n",
      "batch: 4496/60157............. Loss: 5.5257\n",
      "batch: 4512/60157............. Loss: 5.5274\n",
      "batch: 4528/60157............. Loss: 5.5247\n",
      "batch: 4544/60157............. Loss: 5.5271\n",
      "batch: 4560/60157............. Loss: 5.5242\n",
      "batch: 4576/60157............. Loss: 5.5228\n",
      "batch: 4592/60157............. Loss: 5.5261\n",
      "batch: 4608/60157............. Loss: 5.5216\n",
      "batch: 4624/60157............. Loss: 5.5307\n",
      "batch: 4640/60157............. Loss: 5.5289\n",
      "batch: 4656/60157............. Loss: 5.5264\n",
      "batch: 4672/60157............. Loss: 5.5197\n",
      "batch: 4688/60157............. Loss: 5.5213\n",
      "batch: 4704/60157............. Loss: 5.5222\n",
      "batch: 4720/60157............. Loss: 5.5270\n",
      "batch: 4736/60157............. Loss: 5.5268\n",
      "batch: 4752/60157............. Loss: 5.5277\n",
      "batch: 4768/60157............. Loss: 5.5205\n",
      "batch: 4784/60157............. Loss: 5.5244\n",
      "batch: 4800/60157............. Loss: 5.5240\n",
      "batch: 4816/60157............. Loss: 5.5263\n",
      "batch: 4832/60157............. Loss: 5.5235\n",
      "batch: 4848/60157............. Loss: 5.5251\n",
      "batch: 4864/60157............. Loss: 5.5276\n",
      "batch: 4880/60157............. Loss: 5.5240\n",
      "batch: 4896/60157............. Loss: 5.5206\n",
      "batch: 4912/60157............. Loss: 5.5205\n",
      "batch: 4928/60157............. Loss: 5.5229\n",
      "batch: 4944/60157............. Loss: 5.5245\n",
      "batch: 4960/60157............. Loss: 5.5190\n",
      "batch: 4976/60157............. Loss: 5.5274\n",
      "batch: 4992/60157............. Loss: 5.5255\n",
      "batch: 5008/60157............. Loss: 5.5214\n",
      "batch: 5024/60157............. Loss: 5.5255\n",
      "batch: 5040/60157............. Loss: 5.5090\n",
      "batch: 5056/60157............. Loss: 5.5262\n",
      "batch: 5072/60157............. Loss: 5.5247\n",
      "batch: 5088/60157............. Loss: 5.5243\n",
      "batch: 5104/60157............. Loss: 5.5257\n",
      "batch: 5120/60157............. Loss: 5.5212\n",
      "batch: 5136/60157............. Loss: 5.5234\n",
      "batch: 5152/60157............. Loss: 5.5273\n",
      "batch: 5168/60157............. Loss: 5.5296\n",
      "batch: 5184/60157............. Loss: 5.5222\n",
      "batch: 5200/60157............. Loss: 5.5317\n",
      "batch: 5216/60157............. Loss: 5.5229\n",
      "batch: 5232/60157............. Loss: 5.5273\n",
      "batch: 5248/60157............. Loss: 5.5280\n",
      "batch: 5264/60157............. Loss: 5.5254\n",
      "batch: 5280/60157............. Loss: 5.5226\n",
      "batch: 5296/60157............. Loss: 5.5204\n",
      "batch: 5312/60157............. Loss: 5.5223\n",
      "batch: 5328/60157............. Loss: 5.5199\n",
      "batch: 5344/60157............. Loss: 5.5196\n",
      "batch: 5360/60157............. Loss: 5.5204\n",
      "batch: 5376/60157............. Loss: 5.5213\n",
      "batch: 5392/60157............. Loss: 5.5251\n",
      "batch: 5408/60157............. Loss: 5.5262\n",
      "batch: 5424/60157............. Loss: 5.5279\n",
      "batch: 5440/60157............. Loss: 5.5223\n",
      "batch: 5456/60157............. Loss: 5.5284\n",
      "batch: 5472/60157............. Loss: 5.5207\n",
      "batch: 5488/60157............. Loss: 5.5224\n",
      "batch: 5504/60157............. Loss: 5.5246\n",
      "batch: 5520/60157............. Loss: 5.5240\n",
      "batch: 5536/60157............. Loss: 5.5236\n",
      "batch: 5552/60157............. Loss: 5.5258\n",
      "batch: 5568/60157............. Loss: 5.5228\n",
      "batch: 5584/60157............. Loss: 5.5266\n",
      "batch: 5600/60157............. Loss: 5.5263\n",
      "batch: 5616/60157............. Loss: 5.5255\n",
      "batch: 5632/60157............. Loss: 5.5171\n",
      "batch: 5648/60157............. Loss: 5.5226\n",
      "batch: 5664/60157............. Loss: 5.5259\n",
      "batch: 5680/60157............. Loss: 5.5284\n",
      "batch: 5696/60157............. Loss: 5.5248\n",
      "batch: 5712/60157............. Loss: 5.5201\n",
      "batch: 5728/60157............. Loss: 5.5255\n",
      "batch: 5744/60157............. Loss: 5.5239\n",
      "batch: 5760/60157............. Loss: 5.5207\n",
      "batch: 5776/60157............. Loss: 5.5270\n",
      "batch: 5792/60157............. Loss: 5.5313\n",
      "batch: 5808/60157............. Loss: 5.5256\n",
      "batch: 5824/60157............. Loss: 5.5232\n",
      "batch: 5840/60157............. Loss: 5.5244\n",
      "batch: 5856/60157............. Loss: 5.5185\n",
      "batch: 5872/60157............. Loss: 5.5246\n",
      "batch: 5888/60157............. Loss: 5.5263\n",
      "batch: 5904/60157............. Loss: 5.5257\n",
      "batch: 5920/60157............. Loss: 5.5268\n",
      "batch: 5936/60157............. Loss: 5.5241\n",
      "batch: 5952/60157............. Loss: 5.5210\n",
      "batch: 5968/60157............. Loss: 5.5272\n",
      "batch: 5984/60157............. Loss: 5.5256\n",
      "batch: 6000/60157............. Loss: 5.5273\n",
      "batch: 6016/60157............. Loss: 5.5282\n",
      "batch: 6032/60157............. Loss: 5.5237\n",
      "batch: 6048/60157............. Loss: 5.5215\n",
      "batch: 6064/60157............. Loss: 5.5250\n",
      "batch: 6080/60157............. Loss: 5.5278\n",
      "batch: 6096/60157............. Loss: 5.5262\n",
      "batch: 6112/60157............. Loss: 5.5241\n",
      "batch: 6128/60157............. Loss: 5.5155\n",
      "batch: 6144/60157............. Loss: 5.5279\n",
      "batch: 6160/60157............. Loss: 5.5230\n",
      "batch: 6176/60157............. Loss: 5.5228\n",
      "batch: 6192/60157............. Loss: 5.5209\n",
      "batch: 6208/60157............. Loss: 5.5253\n",
      "batch: 6224/60157............. Loss: 5.5272\n",
      "batch: 6240/60157............. Loss: 5.5241\n",
      "batch: 6256/60157............. Loss: 5.5268\n",
      "batch: 6272/60157............. Loss: 5.5197\n",
      "batch: 6288/60157............. Loss: 5.5222\n",
      "batch: 6304/60157............. Loss: 5.5234\n",
      "batch: 6320/60157............. Loss: 5.5258\n",
      "batch: 6336/60157............. Loss: 5.5217\n",
      "batch: 6352/60157............. Loss: 5.5244\n",
      "batch: 6368/60157............. Loss: 5.5214\n",
      "batch: 6384/60157............. Loss: 5.5272\n",
      "batch: 6400/60157............. Loss: 5.5226\n",
      "batch: 6416/60157............. Loss: 5.5244\n",
      "batch: 6432/60157............. Loss: 5.5189\n",
      "batch: 6448/60157............. Loss: 5.5276\n",
      "batch: 6464/60157............. Loss: 5.5217\n",
      "batch: 6480/60157............. Loss: 5.5250\n",
      "batch: 6496/60157............. Loss: 5.5196\n",
      "batch: 6512/60157............. Loss: 5.5238\n",
      "batch: 6528/60157............. Loss: 5.5187\n",
      "batch: 6544/60157............. Loss: 5.5283\n",
      "batch: 6560/60157............. Loss: 5.5266\n",
      "batch: 6576/60157............. Loss: 5.5238\n",
      "batch: 6592/60157............. Loss: 5.5237\n",
      "batch: 6608/60157............. Loss: 5.5251\n",
      "batch: 6624/60157............. Loss: 5.5263\n",
      "batch: 6640/60157............. Loss: 5.5279\n",
      "batch: 6656/60157............. Loss: 5.5239\n",
      "batch: 6672/60157............. Loss: 5.5215\n",
      "batch: 6688/60157............. Loss: 5.5238\n",
      "batch: 6704/60157............. Loss: 5.5145\n",
      "batch: 6720/60157............. Loss: 5.5260\n",
      "batch: 6736/60157............. Loss: 5.5196\n",
      "batch: 6752/60157............. Loss: 5.5238\n",
      "batch: 6768/60157............. Loss: 5.5261\n",
      "batch: 6784/60157............. Loss: 5.5253\n",
      "batch: 6800/60157............. Loss: 5.5253\n",
      "batch: 6816/60157............. Loss: 5.5226\n",
      "batch: 6832/60157............. Loss: 5.5196\n",
      "batch: 6848/60157............. Loss: 5.5232\n",
      "batch: 6864/60157............. Loss: 5.5230\n",
      "batch: 6880/60157............. Loss: 5.5227\n",
      "batch: 6896/60157............. Loss: 5.5262\n",
      "batch: 6912/60157............. Loss: 5.5301\n",
      "batch: 6928/60157............. Loss: 5.5269\n",
      "batch: 6944/60157............. Loss: 5.5216\n",
      "batch: 6960/60157............. Loss: 5.5285\n",
      "batch: 6976/60157............. Loss: 5.5184\n",
      "batch: 6992/60157............. Loss: 5.5205\n",
      "batch: 7008/60157............. Loss: 5.5273\n",
      "batch: 7024/60157............. Loss: 5.5242\n",
      "batch: 7040/60157............. Loss: 5.5223\n",
      "batch: 7056/60157............. Loss: 5.5246\n",
      "batch: 7072/60157............. Loss: 5.5224\n",
      "batch: 7088/60157............. Loss: 5.5239\n",
      "batch: 7104/60157............. Loss: 5.5220\n",
      "batch: 7120/60157............. Loss: 5.5247\n",
      "batch: 7136/60157............. Loss: 5.5316\n",
      "batch: 7152/60157............. Loss: 5.5248\n",
      "batch: 7168/60157............. Loss: 5.5258\n",
      "batch: 7184/60157............. Loss: 5.5215\n",
      "batch: 7200/60157............. Loss: 5.5159\n",
      "batch: 7216/60157............. Loss: 5.5218\n",
      "batch: 7232/60157............. Loss: 5.5220\n",
      "batch: 7248/60157............. Loss: 5.5273\n",
      "batch: 7264/60157............. Loss: 5.5238\n",
      "batch: 7280/60157............. Loss: 5.5221\n",
      "batch: 7296/60157............. Loss: 5.5257\n",
      "batch: 7312/60157............. Loss: 5.5267\n",
      "batch: 7328/60157............. Loss: 5.5251\n",
      "batch: 7344/60157............. Loss: 5.5231\n",
      "batch: 7360/60157............. Loss: 5.5248\n",
      "batch: 7376/60157............. Loss: 5.5240\n",
      "batch: 7392/60157............. Loss: 5.5235\n",
      "batch: 7408/60157............. Loss: 5.5216\n",
      "batch: 7424/60157............. Loss: 5.5206\n",
      "batch: 7440/60157............. Loss: 5.5248\n",
      "batch: 7456/60157............. Loss: 5.5214\n",
      "batch: 7472/60157............. Loss: 5.5220\n",
      "batch: 7488/60157............. Loss: 5.5294\n",
      "batch: 7504/60157............. Loss: 5.5287\n",
      "batch: 7520/60157............. Loss: 5.5216\n",
      "batch: 7536/60157............. Loss: 5.5295\n",
      "batch: 7552/60157............. Loss: 5.5252\n",
      "batch: 7568/60157............. Loss: 5.5277\n",
      "batch: 7584/60157............. Loss: 5.5242\n",
      "batch: 7600/60157............. Loss: 5.5179\n",
      "batch: 7616/60157............. Loss: 5.5246\n",
      "batch: 7632/60157............. Loss: 5.5224\n",
      "batch: 7648/60157............. Loss: 5.5245\n",
      "batch: 7664/60157............. Loss: 5.5271\n",
      "batch: 7680/60157............. Loss: 5.5215\n",
      "batch: 7696/60157............. Loss: 5.5276\n",
      "batch: 7712/60157............. Loss: 5.5184\n",
      "batch: 7728/60157............. Loss: 5.5207\n",
      "batch: 7744/60157............. Loss: 5.5205\n",
      "batch: 7760/60157............. Loss: 5.5276\n",
      "batch: 7776/60157............. Loss: 5.5282\n",
      "batch: 7792/60157............. Loss: 5.5236\n",
      "batch: 7808/60157............. Loss: 5.5247\n",
      "batch: 7824/60157............. Loss: 5.5180\n",
      "batch: 7840/60157............. Loss: 5.5177\n",
      "batch: 7856/60157............. Loss: 5.5264\n",
      "batch: 7872/60157............. Loss: 5.5253\n",
      "batch: 7888/60157............. Loss: 5.5231\n",
      "batch: 7904/60157............. Loss: 5.5236\n",
      "batch: 7920/60157............. Loss: 5.5198\n",
      "batch: 7936/60157............. Loss: 5.5257\n",
      "batch: 7952/60157............. Loss: 5.5219\n",
      "batch: 7968/60157............. Loss: 5.5301\n",
      "batch: 7984/60157............. Loss: 5.5201\n",
      "batch: 8000/60157............. Loss: 5.5272\n",
      "batch: 8016/60157............. Loss: 5.5108\n",
      "batch: 8032/60157............. Loss: 5.5198\n",
      "batch: 8048/60157............. Loss: 5.5247\n",
      "batch: 8064/60157............. Loss: 5.5278\n",
      "batch: 8080/60157............. Loss: 5.5231\n",
      "batch: 8096/60157............. Loss: 5.5246\n",
      "batch: 8112/60157............. Loss: 5.5229\n",
      "batch: 8128/60157............. Loss: 5.5196\n",
      "batch: 8144/60157............. Loss: 5.5203\n",
      "batch: 8160/60157............. Loss: 5.5257\n",
      "batch: 8176/60157............. Loss: 5.5283\n",
      "batch: 8192/60157............. Loss: 5.5249\n",
      "batch: 8208/60157............. Loss: 5.5225\n",
      "batch: 8224/60157............. Loss: 5.5226\n",
      "batch: 8240/60157............. Loss: 5.5265\n",
      "batch: 8256/60157............. Loss: 5.5242\n",
      "batch: 8272/60157............. Loss: 5.5229\n",
      "batch: 8288/60157............. Loss: 5.5187\n",
      "batch: 8304/60157............. Loss: 5.5191\n",
      "batch: 8320/60157............. Loss: 5.5239\n",
      "batch: 8336/60157............. Loss: 5.5304\n",
      "batch: 8352/60157............. Loss: 5.5171\n",
      "batch: 8368/60157............. Loss: 5.5288\n",
      "batch: 8384/60157............. Loss: 5.5181\n",
      "batch: 8400/60157............. Loss: 5.5205\n",
      "batch: 8416/60157............. Loss: 5.5227\n",
      "batch: 8432/60157............. Loss: 5.5239\n",
      "batch: 8448/60157............. Loss: 5.5243\n",
      "batch: 8464/60157............. Loss: 5.5249\n",
      "batch: 8480/60157............. Loss: 5.5221\n",
      "batch: 8496/60157............. Loss: 5.5226\n",
      "batch: 8512/60157............. Loss: 5.5236\n",
      "batch: 8528/60157............. Loss: 5.5182\n",
      "batch: 8544/60157............. Loss: 5.5227\n",
      "batch: 8560/60157............. Loss: 5.5204\n",
      "batch: 8576/60157............. Loss: 5.5228\n",
      "batch: 8592/60157............. Loss: 5.5263\n",
      "batch: 8608/60157............. Loss: 5.5179\n",
      "batch: 8624/60157............. Loss: 5.5238\n",
      "batch: 8640/60157............. Loss: 5.5207\n",
      "batch: 8656/60157............. Loss: 5.5256\n",
      "batch: 8672/60157............. Loss: 5.5250\n",
      "batch: 8688/60157............. Loss: 5.5233\n",
      "batch: 8704/60157............. Loss: 5.5224\n",
      "batch: 8720/60157............. Loss: 5.5194\n",
      "batch: 8736/60157............. Loss: 5.5293\n",
      "batch: 8752/60157............. Loss: 5.5240\n",
      "batch: 8768/60157............. Loss: 5.5152\n",
      "batch: 8784/60157............. Loss: 5.5245\n",
      "batch: 8800/60157............. Loss: 5.5259\n",
      "batch: 8816/60157............. Loss: 5.5254\n",
      "batch: 8832/60157............. Loss: 5.5227\n",
      "batch: 8848/60157............. Loss: 5.5182\n",
      "batch: 8864/60157............. Loss: 5.5295\n",
      "batch: 8880/60157............. Loss: 5.5263\n",
      "batch: 8896/60157............. Loss: 5.5135\n",
      "batch: 8912/60157............. Loss: 5.5255\n",
      "batch: 8928/60157............. Loss: 5.5290\n",
      "batch: 8944/60157............. Loss: 5.5254\n",
      "batch: 8960/60157............. Loss: 5.5263\n",
      "batch: 8976/60157............. Loss: 5.5326\n",
      "batch: 8992/60157............. Loss: 5.5294\n",
      "batch: 9008/60157............. Loss: 5.5268\n",
      "batch: 9024/60157............. Loss: 5.5210\n",
      "batch: 9040/60157............. Loss: 5.5240\n",
      "batch: 9056/60157............. Loss: 5.5212\n",
      "batch: 9072/60157............. Loss: 5.5259\n",
      "batch: 9088/60157............. Loss: 5.5284\n",
      "batch: 9104/60157............. Loss: 5.5257\n",
      "batch: 9120/60157............. Loss: 5.5235\n",
      "batch: 9136/60157............. Loss: 5.5229\n",
      "batch: 9152/60157............. Loss: 5.5213\n",
      "batch: 9168/60157............. Loss: 5.5219\n",
      "batch: 9184/60157............. Loss: 5.5244\n",
      "batch: 9200/60157............. Loss: 5.5237\n",
      "batch: 9216/60157............. Loss: 5.5223\n",
      "batch: 9232/60157............. Loss: 5.5249\n",
      "batch: 9248/60157............. Loss: 5.5201\n",
      "batch: 9264/60157............. Loss: 5.5223\n",
      "batch: 9280/60157............. Loss: 5.5226\n",
      "batch: 9296/60157............. Loss: 5.5261\n",
      "batch: 9312/60157............. Loss: 5.5229\n",
      "batch: 9328/60157............. Loss: 5.5281\n",
      "batch: 9344/60157............. Loss: 5.5245\n",
      "batch: 9360/60157............. Loss: 5.5229\n",
      "batch: 9376/60157............. Loss: 5.5213\n",
      "batch: 9392/60157............. Loss: 5.5189\n",
      "batch: 9408/60157............. Loss: 5.5274\n",
      "batch: 9424/60157............. Loss: 5.5230\n",
      "batch: 9440/60157............. Loss: 5.5166\n",
      "batch: 9456/60157............. Loss: 5.5245\n",
      "batch: 9472/60157............. Loss: 5.5202\n",
      "batch: 9488/60157............. Loss: 5.5227\n",
      "batch: 9504/60157............. Loss: 5.5250\n",
      "batch: 9520/60157............. Loss: 5.5223\n",
      "batch: 9536/60157............. Loss: 5.5251\n",
      "batch: 9552/60157............. Loss: 5.5228\n",
      "batch: 9568/60157............. Loss: 5.5185\n",
      "batch: 9584/60157............. Loss: 5.5259\n",
      "batch: 9600/60157............. Loss: 5.5243\n",
      "batch: 9616/60157............. Loss: 5.5282\n",
      "batch: 9632/60157............. Loss: 5.5240\n",
      "batch: 9648/60157............. Loss: 5.5250\n",
      "batch: 9664/60157............. Loss: 5.5259\n",
      "batch: 9680/60157............. Loss: 5.5176\n",
      "batch: 9696/60157............. Loss: 5.5188\n",
      "batch: 9712/60157............. Loss: 5.5268\n",
      "batch: 9728/60157............. Loss: 5.5263\n",
      "batch: 9744/60157............. Loss: 5.5196\n",
      "batch: 9760/60157............. Loss: 5.5215\n",
      "batch: 9776/60157............. Loss: 5.5166\n",
      "batch: 9792/60157............. Loss: 5.5238\n",
      "batch: 9808/60157............. Loss: 5.5277\n",
      "batch: 9824/60157............. Loss: 5.5265\n",
      "batch: 9840/60157............. Loss: 5.5274\n",
      "batch: 9856/60157............. Loss: 5.5264\n",
      "batch: 9872/60157............. Loss: 5.5275\n",
      "batch: 9888/60157............. Loss: 5.5244\n",
      "batch: 9904/60157............. Loss: 5.5238\n",
      "batch: 9920/60157............. Loss: 5.5268\n",
      "batch: 9936/60157............. Loss: 5.5227\n",
      "batch: 9952/60157............. Loss: 5.5218\n",
      "batch: 9968/60157............. Loss: 5.5211\n",
      "batch: 9984/60157............. Loss: 5.5225\n",
      "batch: 10000/60157............. Loss: 5.5251\n",
      "batch: 10016/60157............. Loss: 5.5249\n",
      "batch: 10032/60157............. Loss: 5.5252\n",
      "batch: 10048/60157............. Loss: 5.5248\n",
      "batch: 10064/60157............. Loss: 5.5181\n",
      "batch: 10080/60157............. Loss: 5.5212\n",
      "batch: 10096/60157............. Loss: 5.5236\n",
      "batch: 10112/60157............. Loss: 5.5243\n",
      "batch: 10128/60157............. Loss: 5.5200\n",
      "batch: 10144/60157............. Loss: 5.5221\n",
      "batch: 10160/60157............. Loss: 5.5200\n",
      "batch: 10176/60157............. Loss: 5.5141\n",
      "batch: 10192/60157............. Loss: 5.5223\n",
      "batch: 10208/60157............. Loss: 5.5234\n",
      "batch: 10224/60157............. Loss: 5.5209\n",
      "batch: 10240/60157............. Loss: 5.5225\n",
      "batch: 10256/60157............. Loss: 5.5299\n",
      "batch: 10272/60157............. Loss: 5.5228\n",
      "batch: 10288/60157............. Loss: 5.5264\n",
      "batch: 10304/60157............. Loss: 5.5151\n",
      "batch: 10320/60157............. Loss: 5.5230\n",
      "batch: 10336/60157............. Loss: 5.5193\n",
      "batch: 10352/60157............. Loss: 5.5246\n",
      "batch: 10368/60157............. Loss: 5.5185\n",
      "batch: 10384/60157............. Loss: 5.5269\n",
      "batch: 10400/60157............. Loss: 5.5269\n",
      "batch: 10416/60157............. Loss: 5.5188\n",
      "batch: 10432/60157............. Loss: 5.5289\n",
      "batch: 10448/60157............. Loss: 5.5276\n",
      "batch: 10464/60157............. Loss: 5.5230\n",
      "batch: 10480/60157............. Loss: 5.5258\n",
      "batch: 10496/60157............. Loss: 5.5244\n",
      "batch: 10512/60157............. Loss: 5.5203\n",
      "batch: 10528/60157............. Loss: 5.5222\n",
      "batch: 10544/60157............. Loss: 5.5186\n",
      "batch: 10560/60157............. Loss: 5.5266\n",
      "batch: 10576/60157............. Loss: 5.5230\n",
      "batch: 10592/60157............. Loss: 5.5211\n",
      "batch: 10608/60157............. Loss: 5.5201\n",
      "batch: 10624/60157............. Loss: 5.5268\n",
      "batch: 10640/60157............. Loss: 5.5254\n",
      "batch: 10656/60157............. Loss: 5.5090\n",
      "batch: 10672/60157............. Loss: 5.5241\n",
      "batch: 10688/60157............. Loss: 5.5233\n",
      "batch: 10704/60157............. Loss: 5.5269\n",
      "batch: 10720/60157............. Loss: 5.5188\n",
      "batch: 10736/60157............. Loss: 5.5217\n",
      "batch: 10752/60157............. Loss: 5.5187\n",
      "batch: 10768/60157............. Loss: 5.5170\n",
      "batch: 10784/60157............. Loss: 5.5288\n",
      "batch: 10800/60157............. Loss: 5.5273\n",
      "batch: 10816/60157............. Loss: 5.5229\n",
      "batch: 10832/60157............. Loss: 5.5235\n",
      "batch: 10848/60157............. Loss: 5.5309\n",
      "batch: 10864/60157............. Loss: 5.5251\n",
      "batch: 10880/60157............. Loss: 5.5245\n",
      "batch: 10896/60157............. Loss: 5.5169\n",
      "batch: 10912/60157............. Loss: 5.5237\n",
      "batch: 10928/60157............. Loss: 5.5236\n",
      "batch: 10944/60157............. Loss: 5.5250\n",
      "batch: 10960/60157............. Loss: 5.5188\n",
      "batch: 10976/60157............. Loss: 5.5213\n",
      "batch: 10992/60157............. Loss: 5.5264\n",
      "batch: 11008/60157............. Loss: 5.5265\n",
      "batch: 11024/60157............. Loss: 5.5257\n",
      "batch: 11040/60157............. Loss: 5.5230\n",
      "batch: 11056/60157............. Loss: 5.5232\n",
      "batch: 11072/60157............. Loss: 5.5227\n",
      "batch: 11088/60157............. Loss: 5.5238\n",
      "batch: 11104/60157............. Loss: 5.5279\n",
      "batch: 11120/60157............. Loss: 5.5252\n",
      "batch: 11136/60157............. Loss: 5.5231\n",
      "batch: 11152/60157............. Loss: 5.5247\n",
      "batch: 11168/60157............. Loss: 5.5266\n",
      "batch: 11184/60157............. Loss: 5.5277\n",
      "batch: 11200/60157............. Loss: 5.5228\n",
      "batch: 11216/60157............. Loss: 5.5217\n",
      "batch: 11232/60157............. Loss: 5.5193\n",
      "batch: 11248/60157............. Loss: 5.5328\n",
      "batch: 11264/60157............. Loss: 5.5208\n",
      "batch: 11280/60157............. Loss: 5.5266\n",
      "batch: 11296/60157............. Loss: 5.5251\n",
      "batch: 11312/60157............. Loss: 5.5227\n",
      "batch: 11328/60157............. Loss: 5.5237\n",
      "batch: 11344/60157............. Loss: 5.5181\n",
      "batch: 11360/60157............. Loss: 5.5244\n",
      "batch: 11376/60157............. Loss: 5.5229\n",
      "batch: 11392/60157............. Loss: 5.5206\n",
      "batch: 11408/60157............. Loss: 5.5287\n",
      "batch: 11424/60157............. Loss: 5.5257\n",
      "batch: 11440/60157............. Loss: 5.5242\n",
      "batch: 11456/60157............. Loss: 5.5224\n",
      "batch: 11472/60157............. Loss: 5.5274\n",
      "batch: 11488/60157............. Loss: 5.5070\n",
      "batch: 11504/60157............. Loss: 5.5281\n",
      "batch: 11520/60157............. Loss: 5.5223\n",
      "batch: 11536/60157............. Loss: 5.5267\n",
      "batch: 11552/60157............. Loss: 5.5247\n",
      "batch: 11568/60157............. Loss: 5.5200\n",
      "batch: 11584/60157............. Loss: 5.5275\n",
      "batch: 11600/60157............. Loss: 5.5283\n",
      "batch: 11616/60157............. Loss: 5.5284\n",
      "batch: 11632/60157............. Loss: 5.5278\n",
      "batch: 11648/60157............. Loss: 5.5287\n",
      "batch: 11664/60157............. Loss: 5.5259\n",
      "batch: 11680/60157............. Loss: 5.5290\n",
      "batch: 11696/60157............. Loss: 5.5296\n",
      "batch: 11712/60157............. Loss: 5.5243\n",
      "batch: 11728/60157............. Loss: 5.5184\n",
      "batch: 11744/60157............. Loss: 5.5232\n",
      "batch: 11760/60157............. Loss: 5.5297\n",
      "batch: 11776/60157............. Loss: 5.5287\n",
      "batch: 11792/60157............. Loss: 5.5275\n",
      "batch: 11808/60157............. Loss: 5.5287\n",
      "batch: 11824/60157............. Loss: 5.5259\n",
      "batch: 11840/60157............. Loss: 5.5268\n",
      "batch: 11856/60157............. Loss: 5.5269\n",
      "batch: 11872/60157............. Loss: 5.5282\n",
      "batch: 11888/60157............. Loss: 5.5270\n",
      "batch: 11904/60157............. Loss: 5.5230\n",
      "batch: 11920/60157............. Loss: 5.5267\n",
      "batch: 11936/60157............. Loss: 5.5268\n",
      "batch: 11952/60157............. Loss: 5.5269\n",
      "batch: 11968/60157............. Loss: 5.5271\n",
      "batch: 11984/60157............. Loss: 5.5268\n",
      "batch: 12000/60157............. Loss: 5.5181\n",
      "batch: 12016/60157............. Loss: 5.5217\n",
      "batch: 12032/60157............. Loss: 5.5290\n",
      "batch: 12048/60157............. Loss: 5.5214\n",
      "batch: 12064/60157............. Loss: 5.5268\n",
      "batch: 12080/60157............. Loss: 5.5271\n",
      "batch: 12096/60157............. Loss: 5.5243\n",
      "batch: 12112/60157............. Loss: 5.5247\n",
      "batch: 12128/60157............. Loss: 5.5299\n",
      "batch: 12144/60157............. Loss: 5.5282\n",
      "batch: 12160/60157............. Loss: 5.5309\n",
      "batch: 12176/60157............. Loss: 5.5198\n",
      "batch: 12192/60157............. Loss: 5.5250\n",
      "batch: 12208/60157............. Loss: 5.5181\n",
      "batch: 12224/60157............. Loss: 5.5248\n",
      "batch: 12240/60157............. Loss: 5.5176\n",
      "batch: 12256/60157............. Loss: 5.5239\n",
      "batch: 12272/60157............. Loss: 5.5267\n",
      "batch: 12288/60157............. Loss: 5.5234\n",
      "batch: 12304/60157............. Loss: 5.5216\n",
      "batch: 12320/60157............. Loss: 5.5252\n",
      "batch: 12336/60157............. Loss: 5.5255\n",
      "batch: 12352/60157............. Loss: 5.5241\n",
      "batch: 12368/60157............. Loss: 5.5252\n",
      "batch: 12384/60157............. Loss: 5.5236\n",
      "batch: 12400/60157............. Loss: 5.5237\n",
      "batch: 12416/60157............. Loss: 5.5195\n",
      "batch: 12432/60157............. Loss: 5.5251\n",
      "batch: 12448/60157............. Loss: 5.5292\n",
      "batch: 12464/60157............. Loss: 5.5171\n",
      "batch: 12480/60157............. Loss: 5.5284\n",
      "batch: 12496/60157............. Loss: 5.5297\n",
      "batch: 12512/60157............. Loss: 5.5256\n",
      "batch: 12528/60157............. Loss: 5.5253\n",
      "batch: 12544/60157............. Loss: 5.5239\n",
      "batch: 12560/60157............. Loss: 5.5258\n",
      "batch: 12576/60157............. Loss: 5.5243\n",
      "batch: 12592/60157............. Loss: 5.5224\n",
      "batch: 12608/60157............. Loss: 5.5205\n",
      "batch: 12624/60157............. Loss: 5.5241\n",
      "batch: 12640/60157............. Loss: 5.5214\n",
      "batch: 12656/60157............. Loss: 5.5274\n",
      "batch: 12672/60157............. Loss: 5.5149\n",
      "batch: 12688/60157............. Loss: 5.5206\n",
      "batch: 12704/60157............. Loss: 5.5251\n",
      "batch: 12720/60157............. Loss: 5.5223\n",
      "batch: 12736/60157............. Loss: 5.5257\n",
      "batch: 12752/60157............. Loss: 5.5225\n",
      "batch: 12768/60157............. Loss: 5.5198\n",
      "batch: 12784/60157............. Loss: 5.5236\n",
      "batch: 12800/60157............. Loss: 5.5194\n",
      "batch: 12816/60157............. Loss: 5.5249\n",
      "batch: 12832/60157............. Loss: 5.5279\n",
      "batch: 12848/60157............. Loss: 5.5250\n",
      "batch: 12864/60157............. Loss: 5.5266\n",
      "batch: 12880/60157............. Loss: 5.5195\n",
      "batch: 12896/60157............. Loss: 5.5223\n",
      "batch: 12912/60157............. Loss: 5.5235\n",
      "batch: 12928/60157............. Loss: 5.5267\n",
      "batch: 12944/60157............. Loss: 5.5216\n",
      "batch: 12960/60157............. Loss: 5.5261\n",
      "batch: 12976/60157............. Loss: 5.5198\n",
      "batch: 12992/60157............. Loss: 5.5226\n",
      "batch: 13008/60157............. Loss: 5.5223\n",
      "batch: 13024/60157............. Loss: 5.5259\n",
      "batch: 13040/60157............. Loss: 5.5194\n",
      "batch: 13056/60157............. Loss: 5.5170\n",
      "batch: 13072/60157............. Loss: 5.5214\n",
      "batch: 13088/60157............. Loss: 5.5252\n",
      "batch: 13104/60157............. Loss: 5.5202\n",
      "batch: 13120/60157............. Loss: 5.5231\n",
      "batch: 13136/60157............. Loss: 5.5226\n",
      "batch: 13152/60157............. Loss: 5.5267\n",
      "batch: 13168/60157............. Loss: 5.5227\n",
      "batch: 13184/60157............. Loss: 5.5229\n",
      "batch: 13200/60157............. Loss: 5.5224\n",
      "batch: 13216/60157............. Loss: 5.5251\n",
      "batch: 13232/60157............. Loss: 5.5213\n",
      "batch: 13248/60157............. Loss: 5.5266\n",
      "batch: 13264/60157............. Loss: 5.5244\n",
      "batch: 13280/60157............. Loss: 5.5240\n",
      "batch: 13296/60157............. Loss: 5.5222\n",
      "batch: 13312/60157............. Loss: 5.5229\n",
      "batch: 13328/60157............. Loss: 5.5221\n",
      "batch: 13344/60157............. Loss: 5.5262\n",
      "batch: 13360/60157............. Loss: 5.5255\n",
      "batch: 13376/60157............. Loss: 5.4911\n",
      "batch: 13392/60157............. Loss: 5.5256\n",
      "batch: 13408/60157............. Loss: 5.5283\n",
      "batch: 13424/60157............. Loss: 5.5222\n",
      "batch: 13440/60157............. Loss: 5.5230\n",
      "batch: 13456/60157............. Loss: 5.5246\n",
      "batch: 13472/60157............. Loss: 5.5276\n",
      "batch: 13488/60157............. Loss: 5.5268\n",
      "batch: 13504/60157............. Loss: 5.5193\n",
      "batch: 13520/60157............. Loss: 5.5246\n",
      "batch: 13536/60157............. Loss: 5.5248\n",
      "batch: 13552/60157............. Loss: 5.5260\n",
      "batch: 13568/60157............. Loss: 5.5231\n",
      "batch: 13584/60157............. Loss: 5.5191\n",
      "batch: 13600/60157............. Loss: 5.5257\n",
      "batch: 13616/60157............. Loss: 5.5257\n",
      "batch: 13632/60157............. Loss: 5.5253\n",
      "batch: 13648/60157............. Loss: 5.5178\n",
      "batch: 13664/60157............. Loss: 5.5211\n",
      "batch: 13680/60157............. Loss: 5.5263\n",
      "batch: 13696/60157............. Loss: 5.5293\n",
      "batch: 13712/60157............. Loss: 5.5175\n",
      "batch: 13728/60157............. Loss: 5.5259\n",
      "batch: 13744/60157............. Loss: 5.5173\n",
      "batch: 13760/60157............. Loss: 5.5204\n",
      "batch: 13776/60157............. Loss: 5.5262\n",
      "batch: 13792/60157............. Loss: 5.5237\n",
      "batch: 13808/60157............. Loss: 5.5253\n",
      "batch: 13824/60157............. Loss: 5.5216\n",
      "batch: 13840/60157............. Loss: 5.5248\n",
      "batch: 13856/60157............. Loss: 5.5228\n",
      "batch: 13872/60157............. Loss: 5.5220\n",
      "batch: 13888/60157............. Loss: 5.5256\n",
      "batch: 13904/60157............. Loss: 5.5271\n",
      "batch: 13920/60157............. Loss: 5.5192\n",
      "batch: 13936/60157............. Loss: 5.5252\n",
      "batch: 13952/60157............. Loss: 5.5196\n",
      "batch: 13968/60157............. Loss: 5.5250\n",
      "batch: 13984/60157............. Loss: 5.5209\n",
      "batch: 14000/60157............. Loss: 5.5181\n",
      "batch: 14016/60157............. Loss: 5.5176\n",
      "batch: 14032/60157............. Loss: 5.5207\n",
      "batch: 14048/60157............. Loss: 5.5252\n",
      "batch: 14064/60157............. Loss: 5.5308\n",
      "batch: 14080/60157............. Loss: 5.5261\n",
      "batch: 14096/60157............. Loss: 5.5207\n",
      "batch: 14112/60157............. Loss: 5.5233\n",
      "batch: 14128/60157............. Loss: 5.5257\n",
      "batch: 14144/60157............. Loss: 5.5277\n",
      "batch: 14160/60157............. Loss: 5.5219\n",
      "batch: 14176/60157............. Loss: 5.5174\n",
      "batch: 14192/60157............. Loss: 5.5220\n",
      "batch: 14208/60157............. Loss: 5.5199\n",
      "batch: 14224/60157............. Loss: 5.5215\n",
      "batch: 14240/60157............. Loss: 5.5227\n",
      "batch: 14256/60157............. Loss: 5.5275\n",
      "batch: 14272/60157............. Loss: 5.5190\n",
      "batch: 14288/60157............. Loss: 5.5235\n",
      "batch: 14304/60157............. Loss: 5.5242\n",
      "batch: 14320/60157............. Loss: 5.5211\n",
      "batch: 14336/60157............. Loss: 5.5196\n",
      "batch: 14352/60157............. Loss: 5.5278\n",
      "batch: 14368/60157............. Loss: 5.5241\n",
      "batch: 14384/60157............. Loss: 5.5251\n",
      "batch: 14400/60157............. Loss: 5.5282\n",
      "batch: 14416/60157............. Loss: 5.5215\n",
      "batch: 14432/60157............. Loss: 5.5225\n",
      "batch: 14448/60157............. Loss: 5.5247\n",
      "batch: 14464/60157............. Loss: 5.5223\n",
      "batch: 14480/60157............. Loss: 5.5307\n",
      "batch: 14496/60157............. Loss: 5.5240\n",
      "batch: 14512/60157............. Loss: 5.5214\n",
      "batch: 14528/60157............. Loss: 5.5216\n",
      "batch: 14544/60157............. Loss: 5.5186\n",
      "batch: 14560/60157............. Loss: 5.5284\n",
      "batch: 14576/60157............. Loss: 5.5218\n",
      "batch: 14592/60157............. Loss: 5.5261\n",
      "batch: 14608/60157............. Loss: 5.5257\n",
      "batch: 14624/60157............. Loss: 5.5204\n",
      "batch: 14640/60157............. Loss: 5.5234\n",
      "batch: 14656/60157............. Loss: 5.5218\n",
      "batch: 14672/60157............. Loss: 5.5224\n",
      "batch: 14688/60157............. Loss: 5.5253\n",
      "batch: 14704/60157............. Loss: 5.5221\n",
      "batch: 14720/60157............. Loss: 5.5300\n",
      "batch: 14736/60157............. Loss: 5.5278\n",
      "batch: 14752/60157............. Loss: 5.5194\n",
      "batch: 14768/60157............. Loss: 5.5251\n",
      "batch: 14784/60157............. Loss: 5.5204\n",
      "batch: 14800/60157............. Loss: 5.5230\n",
      "batch: 14816/60157............. Loss: 5.5257\n",
      "batch: 14832/60157............. Loss: 5.5200\n",
      "batch: 14848/60157............. Loss: 5.5248\n",
      "batch: 14864/60157............. Loss: 5.5297\n",
      "batch: 14880/60157............. Loss: 5.5244\n",
      "batch: 14896/60157............. Loss: 5.5246\n",
      "batch: 14912/60157............. Loss: 5.5277\n",
      "batch: 14928/60157............. Loss: 5.5186\n",
      "batch: 14944/60157............. Loss: 5.5280\n",
      "batch: 14960/60157............. Loss: 5.5211\n",
      "batch: 14976/60157............. Loss: 5.5239\n",
      "batch: 14992/60157............. Loss: 5.5182\n",
      "batch: 15008/60157............. Loss: 5.5213\n",
      "batch: 15024/60157............. Loss: 5.5241\n",
      "batch: 15040/60157............. Loss: 5.5155\n",
      "batch: 15056/60157............. Loss: 5.5190\n",
      "batch: 15072/60157............. Loss: 5.5199\n",
      "batch: 15088/60157............. Loss: 5.5262\n",
      "batch: 15104/60157............. Loss: 5.5189\n",
      "batch: 15120/60157............. Loss: 5.5221\n",
      "batch: 15136/60157............. Loss: 5.5194\n",
      "batch: 15152/60157............. Loss: 5.5072\n",
      "batch: 15168/60157............. Loss: 5.5226\n",
      "batch: 15184/60157............. Loss: 5.5241\n",
      "batch: 15200/60157............. Loss: 5.5226\n",
      "batch: 15216/60157............. Loss: 5.5269\n",
      "batch: 15232/60157............. Loss: 5.5267\n",
      "batch: 15248/60157............. Loss: 5.5266\n",
      "batch: 15264/60157............. Loss: 5.5253\n",
      "batch: 15280/60157............. Loss: 5.5228\n",
      "batch: 15296/60157............. Loss: 5.5223\n",
      "batch: 15312/60157............. Loss: 5.5255\n",
      "batch: 15328/60157............. Loss: 5.5232\n",
      "batch: 15344/60157............. Loss: 5.5235\n",
      "batch: 15360/60157............. Loss: 5.5222\n",
      "batch: 15376/60157............. Loss: 5.5216\n",
      "batch: 15392/60157............. Loss: 5.5203\n",
      "batch: 15408/60157............. Loss: 5.5231\n",
      "batch: 15424/60157............. Loss: 5.5263\n",
      "batch: 15440/60157............. Loss: 5.5214\n",
      "batch: 15456/60157............. Loss: 5.5235\n",
      "batch: 15472/60157............. Loss: 5.5227\n",
      "batch: 15488/60157............. Loss: 5.5249\n",
      "batch: 15504/60157............. Loss: 5.5249\n",
      "batch: 15520/60157............. Loss: 5.5206\n",
      "batch: 15536/60157............. Loss: 5.5212\n",
      "batch: 15552/60157............. Loss: 5.5174\n",
      "batch: 15568/60157............. Loss: 5.5291\n",
      "batch: 15584/60157............. Loss: 5.5232\n",
      "batch: 15600/60157............. Loss: 5.5178\n",
      "batch: 15616/60157............. Loss: 5.5244\n",
      "batch: 15632/60157............. Loss: 5.5238\n",
      "batch: 15648/60157............. Loss: 5.5241\n",
      "batch: 15664/60157............. Loss: 5.5223\n",
      "batch: 15680/60157............. Loss: 5.5265\n",
      "batch: 15696/60157............. Loss: 5.5303\n",
      "batch: 15712/60157............. Loss: 5.5206\n",
      "batch: 15728/60157............. Loss: 5.5209\n",
      "batch: 15744/60157............. Loss: 5.5142\n",
      "batch: 15760/60157............. Loss: 5.5196\n",
      "batch: 15776/60157............. Loss: 5.5292\n",
      "batch: 15792/60157............. Loss: 5.5245\n",
      "batch: 15808/60157............. Loss: 5.5256\n",
      "batch: 15824/60157............. Loss: 5.5251\n",
      "batch: 15840/60157............. Loss: 5.5221\n",
      "batch: 15856/60157............. Loss: 5.5178\n",
      "batch: 15872/60157............. Loss: 5.5190\n",
      "batch: 15888/60157............. Loss: 5.5175\n",
      "batch: 15904/60157............. Loss: 5.5242\n",
      "batch: 15920/60157............. Loss: 5.5151\n",
      "batch: 15936/60157............. Loss: 5.5224\n",
      "batch: 15952/60157............. Loss: 5.5224\n",
      "batch: 15968/60157............. Loss: 5.5248\n",
      "batch: 15984/60157............. Loss: 5.5213\n",
      "batch: 16000/60157............. Loss: 5.5172\n",
      "batch: 16016/60157............. Loss: 5.5248\n",
      "batch: 16032/60157............. Loss: 5.5228\n",
      "batch: 16048/60157............. Loss: 5.5239\n",
      "batch: 16064/60157............. Loss: 5.5284\n",
      "batch: 16080/60157............. Loss: 5.5245\n",
      "batch: 16096/60157............. Loss: 5.5210\n",
      "batch: 16112/60157............. Loss: 5.5272\n",
      "batch: 16128/60157............. Loss: 5.5260\n",
      "batch: 16144/60157............. Loss: 5.5241\n",
      "batch: 16160/60157............. Loss: 5.5246\n",
      "batch: 16176/60157............. Loss: 5.5203\n",
      "batch: 16192/60157............. Loss: 5.5217\n",
      "batch: 16208/60157............. Loss: 5.5238\n",
      "batch: 16224/60157............. Loss: 5.5237\n",
      "batch: 16240/60157............. Loss: 5.5219\n",
      "batch: 16256/60157............. Loss: 5.5289\n",
      "batch: 16272/60157............. Loss: 5.5167\n",
      "batch: 16288/60157............. Loss: 5.5185\n",
      "batch: 16304/60157............. Loss: 5.5225\n",
      "batch: 16320/60157............. Loss: 5.5121\n",
      "batch: 16336/60157............. Loss: 5.5210\n",
      "batch: 16352/60157............. Loss: 5.5231\n",
      "batch: 16368/60157............. Loss: 5.5200\n",
      "batch: 16384/60157............. Loss: 5.5252\n",
      "batch: 16400/60157............. Loss: 5.5266\n",
      "batch: 16416/60157............. Loss: 5.5203\n",
      "batch: 16432/60157............. Loss: 5.5170\n",
      "batch: 16448/60157............. Loss: 5.5252\n",
      "batch: 16464/60157............. Loss: 5.5229\n",
      "batch: 16480/60157............. Loss: 5.5181\n",
      "batch: 16496/60157............. Loss: 5.5236\n",
      "batch: 16512/60157............. Loss: 5.5252\n",
      "batch: 16528/60157............. Loss: 5.5234\n",
      "batch: 16544/60157............. Loss: 5.5264\n",
      "batch: 16560/60157............. Loss: 5.5221\n",
      "batch: 16576/60157............. Loss: 5.5247\n",
      "batch: 16592/60157............. Loss: 5.5194\n",
      "batch: 16608/60157............. Loss: 5.5240\n",
      "batch: 16624/60157............. Loss: 5.5263\n",
      "batch: 16640/60157............. Loss: 5.5139\n",
      "batch: 16656/60157............. Loss: 5.5229\n",
      "batch: 16672/60157............. Loss: 5.5187\n",
      "batch: 16688/60157............. Loss: 5.5161\n",
      "batch: 16704/60157............. Loss: 5.5229\n",
      "batch: 16720/60157............. Loss: 5.5205\n",
      "batch: 16736/60157............. Loss: 5.5202\n",
      "batch: 16752/60157............. Loss: 5.5182\n",
      "batch: 16768/60157............. Loss: 5.5259\n",
      "batch: 16784/60157............. Loss: 5.5158\n",
      "batch: 16800/60157............. Loss: 5.5265\n",
      "batch: 16816/60157............. Loss: 5.5251\n",
      "batch: 16832/60157............. Loss: 5.5270\n",
      "batch: 16848/60157............. Loss: 5.5226\n",
      "batch: 16864/60157............. Loss: 5.5212\n",
      "batch: 16880/60157............. Loss: 5.5249\n",
      "batch: 16896/60157............. Loss: 5.5110\n",
      "batch: 16912/60157............. Loss: 5.5231\n",
      "batch: 16928/60157............. Loss: 5.5184\n",
      "batch: 16944/60157............. Loss: 5.5215\n",
      "batch: 16960/60157............. Loss: 5.5229\n",
      "batch: 16976/60157............. Loss: 5.5207\n",
      "batch: 16992/60157............. Loss: 5.5296\n",
      "batch: 17008/60157............. Loss: 5.5238\n",
      "batch: 17024/60157............. Loss: 5.5213\n",
      "batch: 17040/60157............. Loss: 5.5214\n",
      "batch: 17056/60157............. Loss: 5.5220\n",
      "batch: 17072/60157............. Loss: 5.5221\n",
      "batch: 17088/60157............. Loss: 5.5267\n",
      "batch: 17104/60157............. Loss: 5.5217\n",
      "batch: 17120/60157............. Loss: 5.5247\n",
      "batch: 17136/60157............. Loss: 5.5231\n",
      "batch: 17152/60157............. Loss: 5.5296\n",
      "batch: 17168/60157............. Loss: 5.5229\n",
      "batch: 17184/60157............. Loss: 5.5231\n",
      "batch: 17200/60157............. Loss: 5.5201\n",
      "batch: 17216/60157............. Loss: 5.5231\n",
      "batch: 17232/60157............. Loss: 5.5274\n",
      "batch: 17248/60157............. Loss: 5.5258\n",
      "batch: 17264/60157............. Loss: 5.5221\n",
      "batch: 17280/60157............. Loss: 5.5249\n",
      "batch: 17296/60157............. Loss: 5.5190\n",
      "batch: 17312/60157............. Loss: 5.5261\n",
      "batch: 17328/60157............. Loss: 5.5237\n",
      "batch: 17344/60157............. Loss: 5.5216\n",
      "batch: 17360/60157............. Loss: 5.5180\n",
      "batch: 17376/60157............. Loss: 5.5237\n",
      "batch: 17392/60157............. Loss: 5.5237\n",
      "batch: 17408/60157............. Loss: 5.5240\n",
      "batch: 17424/60157............. Loss: 5.5216\n",
      "batch: 17440/60157............. Loss: 5.5180\n",
      "batch: 17456/60157............. Loss: 5.5191\n",
      "batch: 17472/60157............. Loss: 5.5199\n",
      "batch: 17488/60157............. Loss: 5.5149\n",
      "batch: 17504/60157............. Loss: 5.5247\n",
      "batch: 17520/60157............. Loss: 5.5280\n",
      "batch: 17536/60157............. Loss: 5.5280\n",
      "batch: 17552/60157............. Loss: 5.5229\n",
      "batch: 17568/60157............. Loss: 5.5210\n",
      "batch: 17584/60157............. Loss: 5.5227\n",
      "batch: 17600/60157............. Loss: 5.5296\n",
      "batch: 17616/60157............. Loss: 5.5236\n",
      "batch: 17632/60157............. Loss: 5.5304\n",
      "batch: 17648/60157............. Loss: 5.5270\n",
      "batch: 17664/60157............. Loss: 5.5221\n",
      "batch: 17680/60157............. Loss: 5.5153\n",
      "batch: 17696/60157............. Loss: 5.5239\n",
      "batch: 17712/60157............. Loss: 5.5277\n",
      "batch: 17728/60157............. Loss: 5.5284\n",
      "batch: 17744/60157............. Loss: 5.5235\n",
      "batch: 17760/60157............. Loss: 5.5232\n",
      "batch: 17776/60157............. Loss: 5.5184\n",
      "batch: 17792/60157............. Loss: 5.5233\n",
      "batch: 17808/60157............. Loss: 5.5225\n",
      "batch: 17824/60157............. Loss: 5.5162\n",
      "batch: 17840/60157............. Loss: 5.5284\n",
      "batch: 17856/60157............. Loss: 5.5226\n",
      "batch: 17872/60157............. Loss: 5.5219\n",
      "batch: 17888/60157............. Loss: 5.5243\n",
      "batch: 17904/60157............. Loss: 5.5211\n",
      "batch: 17920/60157............. Loss: 5.5216\n",
      "batch: 17936/60157............. Loss: 5.5207\n",
      "batch: 17952/60157............. Loss: 5.5267\n",
      "batch: 17968/60157............. Loss: 5.5279\n",
      "batch: 17984/60157............. Loss: 5.5268\n",
      "batch: 18000/60157............. Loss: 5.5216\n",
      "batch: 18016/60157............. Loss: 5.5225\n",
      "batch: 18032/60157............. Loss: 5.5205\n",
      "batch: 18048/60157............. Loss: 5.5244\n",
      "batch: 18064/60157............. Loss: 5.5221\n",
      "batch: 18080/60157............. Loss: 5.5190\n",
      "batch: 18096/60157............. Loss: 5.5233\n",
      "batch: 18112/60157............. Loss: 5.5294\n",
      "batch: 18128/60157............. Loss: 5.5268\n",
      "batch: 18144/60157............. Loss: 5.5265\n",
      "batch: 18160/60157............. Loss: 5.5251\n",
      "batch: 18176/60157............. Loss: 5.5227\n",
      "batch: 18192/60157............. Loss: 5.5252\n",
      "batch: 18208/60157............. Loss: 5.5260\n",
      "batch: 18224/60157............. Loss: 5.5293\n",
      "batch: 18240/60157............. Loss: 5.5212\n",
      "batch: 18256/60157............. Loss: 5.5228\n",
      "batch: 18272/60157............. Loss: 5.5245\n",
      "batch: 18288/60157............. Loss: 5.5289\n",
      "batch: 18304/60157............. Loss: 5.5257\n",
      "batch: 18320/60157............. Loss: 5.5248\n",
      "batch: 18336/60157............. Loss: 5.5215\n",
      "batch: 18352/60157............. Loss: 5.5216\n",
      "batch: 18368/60157............. Loss: 5.5214\n",
      "batch: 18384/60157............. Loss: 5.5234\n",
      "batch: 18400/60157............. Loss: 5.5218\n",
      "batch: 18416/60157............. Loss: 5.5221\n",
      "batch: 18432/60157............. Loss: 5.5238\n",
      "batch: 18448/60157............. Loss: 5.5262\n",
      "batch: 18464/60157............. Loss: 5.5242\n",
      "batch: 18480/60157............. Loss: 5.5196\n",
      "batch: 18496/60157............. Loss: 5.5242\n",
      "batch: 18512/60157............. Loss: 5.5223\n",
      "batch: 18528/60157............. Loss: 5.5187\n",
      "batch: 18544/60157............. Loss: 5.5200\n",
      "batch: 18560/60157............. Loss: 5.5234\n",
      "batch: 18576/60157............. Loss: 5.5234\n",
      "batch: 18592/60157............. Loss: 5.5234\n",
      "batch: 18608/60157............. Loss: 5.5177\n",
      "batch: 18624/60157............. Loss: 5.5276\n",
      "batch: 18640/60157............. Loss: 5.5200\n",
      "batch: 18656/60157............. Loss: 5.5223\n",
      "batch: 18672/60157............. Loss: 5.5159\n",
      "batch: 18688/60157............. Loss: 5.5257\n",
      "batch: 18704/60157............. Loss: 5.5271\n",
      "batch: 18720/60157............. Loss: 5.5273\n",
      "batch: 18736/60157............. Loss: 5.5202\n",
      "batch: 18752/60157............. Loss: 5.5193\n",
      "batch: 18768/60157............. Loss: 5.5284\n",
      "batch: 18784/60157............. Loss: 5.5205\n",
      "batch: 18800/60157............. Loss: 5.5285\n",
      "batch: 18816/60157............. Loss: 5.5273\n",
      "batch: 18832/60157............. Loss: 5.5236\n",
      "batch: 18848/60157............. Loss: 5.5222\n",
      "batch: 18864/60157............. Loss: 5.5278\n",
      "batch: 18880/60157............. Loss: 5.5226\n",
      "batch: 18896/60157............. Loss: 5.5240\n",
      "batch: 18912/60157............. Loss: 5.5218\n",
      "batch: 18928/60157............. Loss: 5.5230\n",
      "batch: 18944/60157............. Loss: 5.5209\n",
      "batch: 18960/60157............. Loss: 5.5210\n",
      "batch: 18976/60157............. Loss: 5.5236\n",
      "batch: 18992/60157............. Loss: 5.5240\n",
      "batch: 19008/60157............. Loss: 5.5228\n",
      "batch: 19024/60157............. Loss: 5.5191\n",
      "batch: 19040/60157............. Loss: 5.5217\n",
      "batch: 19056/60157............. Loss: 5.5239\n",
      "batch: 19072/60157............. Loss: 5.5187\n",
      "batch: 19088/60157............. Loss: 5.5218\n",
      "batch: 19104/60157............. Loss: 5.5240\n",
      "batch: 19120/60157............. Loss: 5.5257\n",
      "batch: 19136/60157............. Loss: 5.5227\n",
      "batch: 19152/60157............. Loss: 5.5223\n",
      "batch: 19168/60157............. Loss: 5.5258\n",
      "batch: 19184/60157............. Loss: 5.5219\n",
      "batch: 19200/60157............. Loss: 5.5201\n",
      "batch: 19216/60157............. Loss: 5.5249\n",
      "batch: 19232/60157............. Loss: 5.5239\n",
      "batch: 19248/60157............. Loss: 5.5235\n",
      "batch: 19264/60157............. Loss: 5.5207\n",
      "batch: 19280/60157............. Loss: 5.5254\n",
      "batch: 19296/60157............. Loss: 5.5270\n",
      "batch: 19312/60157............. Loss: 5.5243\n",
      "batch: 19328/60157............. Loss: 5.5240\n",
      "batch: 19344/60157............. Loss: 5.5245\n",
      "batch: 19360/60157............. Loss: 5.5198\n",
      "batch: 19376/60157............. Loss: 5.5199\n",
      "batch: 19392/60157............. Loss: 5.5241\n",
      "batch: 19408/60157............. Loss: 5.5226\n",
      "batch: 19424/60157............. Loss: 5.5217\n",
      "batch: 19440/60157............. Loss: 5.5290\n",
      "batch: 19456/60157............. Loss: 5.5246\n",
      "batch: 19472/60157............. Loss: 5.5235\n",
      "batch: 19488/60157............. Loss: 5.5253\n",
      "batch: 19504/60157............. Loss: 5.5213\n",
      "batch: 19520/60157............. Loss: 5.5209\n",
      "batch: 19536/60157............. Loss: 5.5207\n",
      "batch: 19552/60157............. Loss: 5.5239\n",
      "batch: 19568/60157............. Loss: 5.5278\n",
      "batch: 19584/60157............. Loss: 5.5265\n",
      "batch: 19600/60157............. Loss: 5.5211\n",
      "batch: 19616/60157............. Loss: 5.5259\n",
      "batch: 19632/60157............. Loss: 5.5253\n",
      "batch: 19648/60157............. Loss: 5.5215\n",
      "batch: 19664/60157............. Loss: 5.5213\n",
      "batch: 19680/60157............. Loss: 5.5236\n",
      "batch: 19696/60157............. Loss: 5.5262\n",
      "batch: 19712/60157............. Loss: 5.5210\n",
      "batch: 19728/60157............. Loss: 5.5200\n",
      "batch: 19744/60157............. Loss: 5.5189\n",
      "batch: 19760/60157............. Loss: 5.5254\n",
      "batch: 19776/60157............. Loss: 5.5158\n",
      "batch: 19792/60157............. Loss: 5.5229\n",
      "batch: 19808/60157............. Loss: 5.5193\n",
      "batch: 19824/60157............. Loss: 5.5226\n",
      "batch: 19840/60157............. Loss: 5.5171\n",
      "batch: 19856/60157............. Loss: 5.5266\n",
      "batch: 19872/60157............. Loss: 5.5275\n",
      "batch: 19888/60157............. Loss: 5.5202\n",
      "batch: 19904/60157............. Loss: 5.5215\n",
      "batch: 19920/60157............. Loss: 5.5274\n",
      "batch: 19936/60157............. Loss: 5.5195\n",
      "batch: 19952/60157............. Loss: 5.5211\n",
      "batch: 19968/60157............. Loss: 5.5270\n",
      "batch: 19984/60157............. Loss: 5.5229\n",
      "batch: 20000/60157............. Loss: 5.5223\n",
      "batch: 20016/60157............. Loss: 5.5244\n",
      "batch: 20032/60157............. Loss: 5.5202\n",
      "batch: 20048/60157............. Loss: 5.5209\n",
      "batch: 20064/60157............. Loss: 5.5196\n",
      "batch: 20080/60157............. Loss: 5.5214\n",
      "batch: 20096/60157............. Loss: 5.5154\n",
      "batch: 20112/60157............. Loss: 5.5240\n",
      "batch: 20128/60157............. Loss: 5.5320\n",
      "batch: 20144/60157............. Loss: 5.5252\n",
      "batch: 20160/60157............. Loss: 5.5277\n",
      "batch: 20176/60157............. Loss: 5.5263\n",
      "batch: 20192/60157............. Loss: 5.5252\n",
      "batch: 20208/60157............. Loss: 5.5258\n",
      "batch: 20224/60157............. Loss: 5.5274\n",
      "batch: 20240/60157............. Loss: 5.5233\n",
      "batch: 20256/60157............. Loss: 5.5281\n",
      "batch: 20272/60157............. Loss: 5.5233\n",
      "batch: 20288/60157............. Loss: 5.5225\n",
      "batch: 20304/60157............. Loss: 5.5289\n",
      "batch: 20320/60157............. Loss: 5.5279\n",
      "batch: 20336/60157............. Loss: 5.5246\n",
      "batch: 20352/60157............. Loss: 5.5313\n",
      "batch: 20368/60157............. Loss: 5.5237\n",
      "batch: 20384/60157............. Loss: 5.5268\n",
      "batch: 20400/60157............. Loss: 5.5216\n",
      "batch: 20416/60157............. Loss: 5.5198\n",
      "batch: 20432/60157............. Loss: 5.5265\n",
      "batch: 20448/60157............. Loss: 5.5265\n",
      "batch: 20464/60157............. Loss: 5.5258\n",
      "batch: 20480/60157............. Loss: 5.5277\n",
      "batch: 20496/60157............. Loss: 5.5282\n",
      "batch: 20512/60157............. Loss: 5.5269\n",
      "batch: 20528/60157............. Loss: 5.5265\n",
      "batch: 20544/60157............. Loss: 5.5222\n",
      "batch: 20560/60157............. Loss: 5.5234\n",
      "batch: 20576/60157............. Loss: 5.5244\n",
      "batch: 20592/60157............. Loss: 5.5243\n",
      "batch: 20608/60157............. Loss: 5.5266\n",
      "batch: 20624/60157............. Loss: 5.5238\n",
      "batch: 20640/60157............. Loss: 5.5278\n",
      "batch: 20656/60157............. Loss: 5.5277\n",
      "batch: 20672/60157............. Loss: 5.5257\n",
      "batch: 20688/60157............. Loss: 5.5226\n",
      "batch: 20704/60157............. Loss: 5.5290\n",
      "batch: 20720/60157............. Loss: 5.5296\n",
      "batch: 20736/60157............. Loss: 5.5293\n",
      "batch: 20752/60157............. Loss: 5.5305\n",
      "batch: 20768/60157............. Loss: 5.5255\n",
      "batch: 20784/60157............. Loss: 5.5267\n",
      "batch: 20800/60157............. Loss: 5.5228\n",
      "batch: 20816/60157............. Loss: 5.5221\n",
      "batch: 20832/60157............. Loss: 5.5252\n",
      "batch: 20848/60157............. Loss: 5.5297\n",
      "batch: 20864/60157............. Loss: 5.5245\n",
      "batch: 20880/60157............. Loss: 5.5291\n",
      "batch: 20896/60157............. Loss: 5.5247\n",
      "batch: 20912/60157............. Loss: 5.5155\n",
      "batch: 20928/60157............. Loss: 5.5264\n",
      "batch: 20944/60157............. Loss: 5.5313\n",
      "batch: 20960/60157............. Loss: 5.5232\n",
      "batch: 20976/60157............. Loss: 5.5237\n",
      "batch: 20992/60157............. Loss: 5.5280\n",
      "batch: 21008/60157............. Loss: 5.5244\n",
      "batch: 21024/60157............. Loss: 5.5238\n",
      "batch: 21040/60157............. Loss: 5.5238\n",
      "batch: 21056/60157............. Loss: 5.5279\n",
      "batch: 21072/60157............. Loss: 5.5275\n",
      "batch: 21088/60157............. Loss: 5.5207\n",
      "batch: 21104/60157............. Loss: 5.5144\n",
      "batch: 21120/60157............. Loss: 5.5242\n",
      "batch: 21136/60157............. Loss: 5.5240\n",
      "batch: 21152/60157............. Loss: 5.5295\n",
      "batch: 21168/60157............. Loss: 5.5253\n",
      "batch: 21184/60157............. Loss: 5.5261\n",
      "batch: 21200/60157............. Loss: 5.5271\n",
      "batch: 21216/60157............. Loss: 5.5238\n",
      "batch: 21232/60157............. Loss: 5.5246\n",
      "batch: 21248/60157............. Loss: 5.5280\n",
      "batch: 21264/60157............. Loss: 5.5278\n",
      "batch: 21280/60157............. Loss: 5.5221\n",
      "batch: 21296/60157............. Loss: 5.5242\n",
      "batch: 21312/60157............. Loss: 5.5224\n",
      "batch: 21328/60157............. Loss: 5.5293\n",
      "batch: 21344/60157............. Loss: 5.5260\n",
      "batch: 21360/60157............. Loss: 5.5262\n",
      "batch: 21376/60157............. Loss: 5.5262\n",
      "batch: 21392/60157............. Loss: 5.5228\n",
      "batch: 21408/60157............. Loss: 5.5284\n",
      "batch: 21424/60157............. Loss: 5.5229\n",
      "batch: 21440/60157............. Loss: 5.5286\n",
      "batch: 21456/60157............. Loss: 5.5230\n",
      "batch: 21472/60157............. Loss: 5.5290\n",
      "batch: 21488/60157............. Loss: 5.5175\n",
      "batch: 21504/60157............. Loss: 5.5263\n",
      "batch: 21520/60157............. Loss: 5.5243\n",
      "batch: 21536/60157............. Loss: 5.5290\n",
      "batch: 21552/60157............. Loss: 5.5233\n",
      "batch: 21568/60157............. Loss: 5.5196\n",
      "batch: 21584/60157............. Loss: 5.5227\n",
      "batch: 21600/60157............. Loss: 5.5286\n",
      "batch: 21616/60157............. Loss: 5.5228\n",
      "batch: 21632/60157............. Loss: 5.5236\n",
      "batch: 21648/60157............. Loss: 5.5268\n",
      "batch: 21664/60157............. Loss: 5.5258\n",
      "batch: 21680/60157............. Loss: 5.5301\n",
      "batch: 21696/60157............. Loss: 5.5248\n",
      "batch: 21712/60157............. Loss: 5.5272\n",
      "batch: 21728/60157............. Loss: 5.5289\n",
      "batch: 21744/60157............. Loss: 5.5183\n",
      "batch: 21760/60157............. Loss: 5.5257\n",
      "batch: 21776/60157............. Loss: 5.5264\n",
      "batch: 21792/60157............. Loss: 5.5237\n",
      "batch: 21808/60157............. Loss: 5.5278\n",
      "batch: 21824/60157............. Loss: 5.5239\n",
      "batch: 21840/60157............. Loss: 5.5233\n",
      "batch: 21856/60157............. Loss: 5.5252\n",
      "batch: 21872/60157............. Loss: 5.5165\n",
      "batch: 21888/60157............. Loss: 5.5176\n",
      "batch: 21904/60157............. Loss: 5.5247\n",
      "batch: 21920/60157............. Loss: 5.5244\n",
      "batch: 21936/60157............. Loss: 5.5247\n",
      "batch: 21952/60157............. Loss: 5.5268\n",
      "batch: 21968/60157............. Loss: 5.5275\n",
      "batch: 21984/60157............. Loss: 5.5267\n",
      "batch: 22000/60157............. Loss: 5.5278\n",
      "batch: 22016/60157............. Loss: 5.5241\n",
      "batch: 22032/60157............. Loss: 5.5249\n",
      "batch: 22048/60157............. Loss: 5.5207\n",
      "batch: 22064/60157............. Loss: 5.5198\n",
      "batch: 22080/60157............. Loss: 5.5223\n",
      "batch: 22096/60157............. Loss: 5.5289\n",
      "batch: 22112/60157............. Loss: 5.5233\n",
      "batch: 22128/60157............. Loss: 5.5232\n",
      "batch: 22144/60157............. Loss: 5.5240\n",
      "batch: 22160/60157............. Loss: 5.5237\n",
      "batch: 22176/60157............. Loss: 5.5244\n",
      "batch: 22192/60157............. Loss: 5.5279\n",
      "batch: 22208/60157............. Loss: 5.5190\n",
      "batch: 22224/60157............. Loss: 5.5256\n",
      "batch: 22240/60157............. Loss: 5.5217\n",
      "batch: 22256/60157............. Loss: 5.5243\n",
      "batch: 22272/60157............. Loss: 5.5254\n",
      "batch: 22288/60157............. Loss: 5.5280\n",
      "batch: 22304/60157............. Loss: 5.5226\n",
      "batch: 22320/60157............. Loss: 5.5229\n",
      "batch: 22336/60157............. Loss: 5.5253\n",
      "batch: 22352/60157............. Loss: 5.5235\n",
      "batch: 22368/60157............. Loss: 5.5250\n",
      "batch: 22384/60157............. Loss: 5.5242\n",
      "batch: 22400/60157............. Loss: 5.5296\n",
      "batch: 22416/60157............. Loss: 5.5238\n",
      "batch: 22432/60157............. Loss: 5.5287\n",
      "batch: 22448/60157............. Loss: 5.5270\n",
      "batch: 22464/60157............. Loss: 5.5179\n",
      "batch: 22480/60157............. Loss: 5.5265\n",
      "batch: 22496/60157............. Loss: 5.5250\n",
      "batch: 22512/60157............. Loss: 5.5251\n",
      "batch: 22528/60157............. Loss: 5.5291\n",
      "batch: 22544/60157............. Loss: 5.5268\n",
      "batch: 22560/60157............. Loss: 5.5233\n",
      "batch: 22576/60157............. Loss: 5.5268\n",
      "batch: 22592/60157............. Loss: 5.5274\n",
      "batch: 22608/60157............. Loss: 5.5241\n",
      "batch: 22624/60157............. Loss: 5.5309\n",
      "batch: 22640/60157............. Loss: 5.5242\n",
      "batch: 22656/60157............. Loss: 5.5247\n",
      "batch: 22672/60157............. Loss: 5.5212\n",
      "batch: 22688/60157............. Loss: 5.5282\n",
      "batch: 22704/60157............. Loss: 5.5291\n",
      "batch: 22720/60157............. Loss: 5.5238\n",
      "batch: 22736/60157............. Loss: 5.5222\n",
      "batch: 22752/60157............. Loss: 5.5262\n",
      "batch: 22768/60157............. Loss: 5.5276\n",
      "batch: 22784/60157............. Loss: 5.5226\n",
      "batch: 22800/60157............. Loss: 5.5247\n",
      "batch: 22816/60157............. Loss: 5.5288\n",
      "batch: 22832/60157............. Loss: 5.5259\n",
      "batch: 22848/60157............. Loss: 5.5274\n",
      "batch: 22864/60157............. Loss: 5.5233\n",
      "batch: 22880/60157............. Loss: 5.5221\n",
      "batch: 22896/60157............. Loss: 5.5305\n",
      "batch: 22912/60157............. Loss: 5.5130\n",
      "batch: 22928/60157............. Loss: 5.5248\n",
      "batch: 22944/60157............. Loss: 5.5277\n",
      "batch: 22960/60157............. Loss: 5.5282\n",
      "batch: 22976/60157............. Loss: 5.5222\n",
      "batch: 22992/60157............. Loss: 5.5240\n",
      "batch: 23008/60157............. Loss: 5.5219\n",
      "batch: 23024/60157............. Loss: 5.5209\n",
      "batch: 23040/60157............. Loss: 5.5246\n",
      "batch: 23056/60157............. Loss: 5.5219\n",
      "batch: 23072/60157............. Loss: 5.5221\n",
      "batch: 23088/60157............. Loss: 5.5199\n",
      "batch: 23104/60157............. Loss: 5.5238\n",
      "batch: 23120/60157............. Loss: 5.5222\n",
      "batch: 23136/60157............. Loss: 5.5226\n",
      "batch: 23152/60157............. Loss: 5.5193\n",
      "batch: 23168/60157............. Loss: 5.5185\n",
      "batch: 23184/60157............. Loss: 5.5217\n",
      "batch: 23200/60157............. Loss: 5.5193\n",
      "batch: 23216/60157............. Loss: 5.5202\n",
      "batch: 23232/60157............. Loss: 5.5185\n",
      "batch: 23248/60157............. Loss: 5.5206\n",
      "batch: 23264/60157............. Loss: 5.5206\n",
      "batch: 23280/60157............. Loss: 5.5188\n",
      "batch: 23296/60157............. Loss: 5.5238\n",
      "batch: 23312/60157............. Loss: 5.5253\n",
      "batch: 23328/60157............. Loss: 5.5292\n",
      "batch: 23344/60157............. Loss: 5.5185\n",
      "batch: 23360/60157............. Loss: 5.5214\n",
      "batch: 23376/60157............. Loss: 5.5135\n",
      "batch: 23392/60157............. Loss: 5.5269\n",
      "batch: 23408/60157............. Loss: 5.5241\n",
      "batch: 23424/60157............. Loss: 5.5213\n",
      "batch: 23440/60157............. Loss: 5.5227\n",
      "batch: 23456/60157............. Loss: 5.5200\n",
      "batch: 23472/60157............. Loss: 5.5222\n",
      "batch: 23488/60157............. Loss: 5.5164\n",
      "batch: 23504/60157............. Loss: 5.5263\n",
      "batch: 23520/60157............. Loss: 5.5194\n",
      "batch: 23536/60157............. Loss: 5.5242\n",
      "batch: 23552/60157............. Loss: 5.5261\n",
      "batch: 23568/60157............. Loss: 5.5270\n",
      "batch: 23584/60157............. Loss: 5.5206\n",
      "batch: 23600/60157............. Loss: 5.5268\n",
      "batch: 23616/60157............. Loss: 5.5230\n",
      "batch: 23632/60157............. Loss: 5.5187\n",
      "batch: 23648/60157............. Loss: 5.5236\n",
      "batch: 23664/60157............. Loss: 5.5201\n",
      "batch: 23680/60157............. Loss: 5.5212\n",
      "batch: 23696/60157............. Loss: 5.5186\n",
      "batch: 23712/60157............. Loss: 5.5250\n",
      "batch: 23728/60157............. Loss: 5.5246\n",
      "batch: 23744/60157............. Loss: 5.5239\n",
      "batch: 23760/60157............. Loss: 5.5256\n",
      "batch: 23776/60157............. Loss: 5.5242\n",
      "batch: 23792/60157............. Loss: 5.5269\n",
      "batch: 23808/60157............. Loss: 5.5240\n",
      "batch: 23824/60157............. Loss: 5.5241\n",
      "batch: 23840/60157............. Loss: 5.5247\n",
      "batch: 23856/60157............. Loss: 5.5198\n",
      "batch: 23872/60157............. Loss: 5.5222\n",
      "batch: 23888/60157............. Loss: 5.5258\n",
      "batch: 23904/60157............. Loss: 5.5227\n",
      "batch: 23920/60157............. Loss: 5.5225\n",
      "batch: 23936/60157............. Loss: 5.5252\n",
      "batch: 23952/60157............. Loss: 5.5261\n",
      "batch: 23968/60157............. Loss: 5.5228\n",
      "batch: 23984/60157............. Loss: 5.5218\n",
      "batch: 24000/60157............. Loss: 5.5207\n",
      "batch: 24016/60157............. Loss: 5.5219\n",
      "batch: 24032/60157............. Loss: 5.5246\n",
      "batch: 24048/60157............. Loss: 5.5224\n",
      "batch: 24064/60157............. Loss: 5.5173\n",
      "batch: 24080/60157............. Loss: 5.5261\n",
      "batch: 24096/60157............. Loss: 5.5204\n",
      "batch: 24112/60157............. Loss: 5.5261\n",
      "batch: 24128/60157............. Loss: 5.5223\n",
      "batch: 24144/60157............. Loss: 5.5223\n",
      "batch: 24160/60157............. Loss: 5.5204\n",
      "batch: 24176/60157............. Loss: 5.5238\n",
      "batch: 24192/60157............. Loss: 5.5175\n",
      "batch: 24208/60157............. Loss: 5.5138\n",
      "batch: 24224/60157............. Loss: 5.5217\n",
      "batch: 24240/60157............. Loss: 5.5176\n",
      "batch: 24256/60157............. Loss: 5.5291\n",
      "batch: 24272/60157............. Loss: 5.5230\n",
      "batch: 24288/60157............. Loss: 5.5181\n",
      "batch: 24304/60157............. Loss: 5.5238\n",
      "batch: 24320/60157............. Loss: 5.5221\n",
      "batch: 24336/60157............. Loss: 5.5254\n",
      "batch: 24352/60157............. Loss: 5.5219\n",
      "batch: 24368/60157............. Loss: 5.5276\n",
      "batch: 24384/60157............. Loss: 5.5243\n",
      "batch: 24400/60157............. Loss: 5.5221\n",
      "batch: 24416/60157............. Loss: 5.5227\n",
      "batch: 24432/60157............. Loss: 5.5251\n",
      "batch: 24448/60157............. Loss: 5.5235\n",
      "batch: 24464/60157............. Loss: 5.5261\n",
      "batch: 24480/60157............. Loss: 5.5104\n",
      "batch: 24496/60157............. Loss: 5.5213\n",
      "batch: 24512/60157............. Loss: 5.5212\n",
      "batch: 24528/60157............. Loss: 5.5279\n",
      "batch: 24544/60157............. Loss: 5.5225\n",
      "batch: 24560/60157............. Loss: 5.5237\n",
      "batch: 24576/60157............. Loss: 5.5261\n",
      "batch: 24592/60157............. Loss: 5.5217\n",
      "batch: 24608/60157............. Loss: 5.5221\n",
      "batch: 24624/60157............. Loss: 5.5250\n",
      "batch: 24640/60157............. Loss: 5.5229\n",
      "batch: 24656/60157............. Loss: 5.5237\n",
      "batch: 24672/60157............. Loss: 5.5174\n",
      "batch: 24688/60157............. Loss: 5.5195\n",
      "batch: 24704/60157............. Loss: 5.5249\n",
      "batch: 24720/60157............. Loss: 5.5257\n",
      "batch: 24736/60157............. Loss: 5.5230\n",
      "batch: 24752/60157............. Loss: 5.5229\n",
      "batch: 24768/60157............. Loss: 5.5260\n",
      "batch: 24784/60157............. Loss: 5.5241\n",
      "batch: 24800/60157............. Loss: 5.5205\n",
      "batch: 24816/60157............. Loss: 5.5251\n",
      "batch: 24832/60157............. Loss: 5.5159\n",
      "batch: 24848/60157............. Loss: 5.5177\n",
      "batch: 24864/60157............. Loss: 5.5268\n",
      "batch: 24880/60157............. Loss: 5.5218\n",
      "batch: 24896/60157............. Loss: 5.5190\n",
      "batch: 24912/60157............. Loss: 5.5167\n",
      "batch: 24928/60157............. Loss: 5.5199\n",
      "batch: 24944/60157............. Loss: 5.5274\n",
      "batch: 24960/60157............. Loss: 5.5149\n",
      "batch: 24976/60157............. Loss: 5.5242\n",
      "batch: 24992/60157............. Loss: 5.5208\n",
      "batch: 25008/60157............. Loss: 5.5231\n",
      "batch: 25024/60157............. Loss: 5.5188\n",
      "batch: 25040/60157............. Loss: 5.5265\n",
      "batch: 25056/60157............. Loss: 5.5272\n",
      "batch: 25072/60157............. Loss: 5.5213\n",
      "batch: 25088/60157............. Loss: 5.5263\n",
      "batch: 25104/60157............. Loss: 5.5242\n",
      "batch: 25120/60157............. Loss: 5.5184\n",
      "batch: 25136/60157............. Loss: 5.5167\n",
      "batch: 25152/60157............. Loss: 5.5231\n",
      "batch: 25168/60157............. Loss: 5.5252\n",
      "batch: 25184/60157............. Loss: 5.5222\n",
      "batch: 25200/60157............. Loss: 5.5285\n",
      "batch: 25216/60157............. Loss: 5.5210\n",
      "batch: 25232/60157............. Loss: 5.5217\n",
      "batch: 25248/60157............. Loss: 5.5207\n",
      "batch: 25264/60157............. Loss: 5.5256\n",
      "batch: 25280/60157............. Loss: 5.5291\n",
      "batch: 25296/60157............. Loss: 5.5225\n",
      "batch: 25312/60157............. Loss: 5.5210\n",
      "batch: 25328/60157............. Loss: 5.5191\n",
      "batch: 25344/60157............. Loss: 5.5182\n",
      "batch: 25360/60157............. Loss: 5.5229\n",
      "batch: 25376/60157............. Loss: 5.5219\n",
      "batch: 25392/60157............. Loss: 5.5294\n",
      "batch: 25408/60157............. Loss: 5.5209\n",
      "batch: 25424/60157............. Loss: 5.5234\n",
      "batch: 25440/60157............. Loss: 5.5241\n",
      "batch: 25456/60157............. Loss: 5.5199\n",
      "batch: 25472/60157............. Loss: 5.5191\n",
      "batch: 25488/60157............. Loss: 5.5237\n",
      "batch: 25504/60157............. Loss: 5.5243\n",
      "batch: 25520/60157............. Loss: 5.5214\n",
      "batch: 25536/60157............. Loss: 5.5226\n",
      "batch: 25552/60157............. Loss: 5.5252\n",
      "batch: 25568/60157............. Loss: 5.5259\n",
      "batch: 25584/60157............. Loss: 5.5235\n",
      "batch: 25600/60157............. Loss: 5.5205\n",
      "batch: 25616/60157............. Loss: 5.5205\n",
      "batch: 25632/60157............. Loss: 5.5211\n",
      "batch: 25648/60157............. Loss: 5.5230\n",
      "batch: 25664/60157............. Loss: 5.5217\n",
      "batch: 25680/60157............. Loss: 5.5248\n",
      "batch: 25696/60157............. Loss: 5.5220\n",
      "batch: 25712/60157............. Loss: 5.5197\n",
      "batch: 25728/60157............. Loss: 5.5215\n",
      "batch: 25744/60157............. Loss: 5.5302\n",
      "batch: 25760/60157............. Loss: 5.5223\n",
      "batch: 25776/60157............. Loss: 5.5246\n",
      "batch: 25792/60157............. Loss: 5.5151\n",
      "batch: 25808/60157............. Loss: 5.5281\n",
      "batch: 25824/60157............. Loss: 5.5243\n",
      "batch: 25840/60157............. Loss: 5.5234\n",
      "batch: 25856/60157............. Loss: 5.5290\n",
      "batch: 25872/60157............. Loss: 5.5253\n",
      "batch: 25888/60157............. Loss: 5.5253\n",
      "batch: 25904/60157............. Loss: 5.5248\n",
      "batch: 25920/60157............. Loss: 5.5223\n",
      "batch: 25936/60157............. Loss: 5.5237\n",
      "batch: 25952/60157............. Loss: 5.5198\n",
      "batch: 25968/60157............. Loss: 5.5233\n",
      "batch: 25984/60157............. Loss: 5.5223\n",
      "batch: 26000/60157............. Loss: 5.5253\n",
      "batch: 26016/60157............. Loss: 5.5228\n",
      "batch: 26032/60157............. Loss: 5.5228\n",
      "batch: 26048/60157............. Loss: 5.5229\n",
      "batch: 26064/60157............. Loss: 5.5298\n",
      "batch: 26080/60157............. Loss: 5.5299\n",
      "batch: 26096/60157............. Loss: 5.5230\n",
      "batch: 26112/60157............. Loss: 5.5239\n",
      "batch: 26128/60157............. Loss: 5.5249\n",
      "batch: 26144/60157............. Loss: 5.5213\n",
      "batch: 26160/60157............. Loss: 5.5215\n",
      "batch: 26176/60157............. Loss: 5.5211\n",
      "batch: 26192/60157............. Loss: 5.5195\n",
      "batch: 26208/60157............. Loss: 5.5210\n",
      "batch: 26224/60157............. Loss: 5.5204\n",
      "batch: 26240/60157............. Loss: 5.5261\n",
      "batch: 26256/60157............. Loss: 5.5278\n",
      "batch: 26272/60157............. Loss: 5.5244\n",
      "batch: 26288/60157............. Loss: 5.5253\n",
      "batch: 26304/60157............. Loss: 5.5281\n",
      "batch: 26320/60157............. Loss: 5.5281\n",
      "batch: 26336/60157............. Loss: 5.5195\n",
      "batch: 26352/60157............. Loss: 5.5292\n",
      "batch: 26368/60157............. Loss: 5.5269\n",
      "batch: 26384/60157............. Loss: 5.5245\n",
      "batch: 26400/60157............. Loss: 5.5254\n",
      "batch: 26416/60157............. Loss: 5.5250\n",
      "batch: 26432/60157............. Loss: 5.5281\n",
      "batch: 26448/60157............. Loss: 5.5201\n",
      "batch: 26464/60157............. Loss: 5.5146\n",
      "batch: 26480/60157............. Loss: 5.5179\n",
      "batch: 26496/60157............. Loss: 5.5235\n",
      "batch: 26512/60157............. Loss: 5.5251\n",
      "batch: 26528/60157............. Loss: 5.5291\n",
      "batch: 26544/60157............. Loss: 5.5216\n",
      "batch: 26560/60157............. Loss: 5.5187\n",
      "batch: 26576/60157............. Loss: 5.5176\n",
      "batch: 26592/60157............. Loss: 5.5228\n",
      "batch: 26608/60157............. Loss: 5.5325\n",
      "batch: 26624/60157............. Loss: 5.5226\n",
      "batch: 26640/60157............. Loss: 5.5203\n",
      "batch: 26656/60157............. Loss: 5.5246\n",
      "batch: 26672/60157............. Loss: 5.5218\n",
      "batch: 26688/60157............. Loss: 5.5244\n",
      "batch: 26704/60157............. Loss: 5.5234\n",
      "batch: 26720/60157............. Loss: 5.5219\n",
      "batch: 26736/60157............. Loss: 5.5224\n",
      "batch: 26752/60157............. Loss: 5.5233\n",
      "batch: 26768/60157............. Loss: 5.5231\n",
      "batch: 26784/60157............. Loss: 5.5221\n",
      "batch: 26800/60157............. Loss: 5.5255\n",
      "batch: 26816/60157............. Loss: 5.5270\n",
      "batch: 26832/60157............. Loss: 5.5207\n",
      "batch: 26848/60157............. Loss: 5.5194\n",
      "batch: 26864/60157............. Loss: 5.5208\n",
      "batch: 26880/60157............. Loss: 5.5270\n",
      "batch: 26896/60157............. Loss: 5.5236\n",
      "batch: 26912/60157............. Loss: 5.5271\n",
      "batch: 26928/60157............. Loss: 5.5225\n",
      "batch: 26944/60157............. Loss: 5.5252\n",
      "batch: 26960/60157............. Loss: 5.5230\n",
      "batch: 26976/60157............. Loss: 5.5174\n",
      "batch: 26992/60157............. Loss: 5.5214\n",
      "batch: 27008/60157............. Loss: 5.5303\n",
      "batch: 27024/60157............. Loss: 5.5252\n",
      "batch: 27040/60157............. Loss: 5.5183\n",
      "batch: 27056/60157............. Loss: 5.5194\n",
      "batch: 27072/60157............. Loss: 5.5200\n",
      "batch: 27088/60157............. Loss: 5.5224\n",
      "batch: 27104/60157............. Loss: 5.5284\n",
      "batch: 27120/60157............. Loss: 5.5178\n",
      "batch: 27136/60157............. Loss: 5.5239\n",
      "batch: 27152/60157............. Loss: 5.5254\n",
      "batch: 27168/60157............. Loss: 5.5191\n",
      "batch: 27184/60157............. Loss: 5.5243\n",
      "batch: 27200/60157............. Loss: 5.5204\n",
      "batch: 27216/60157............. Loss: 5.5234\n",
      "batch: 27232/60157............. Loss: 5.5236\n",
      "batch: 27248/60157............. Loss: 5.5219\n",
      "batch: 27264/60157............. Loss: 5.5256\n",
      "batch: 27280/60157............. Loss: 5.5203\n",
      "batch: 27296/60157............. Loss: 5.5217\n",
      "batch: 27312/60157............. Loss: 5.5264\n",
      "batch: 27328/60157............. Loss: 5.5188\n",
      "batch: 27344/60157............. Loss: 5.5206\n",
      "batch: 27360/60157............. Loss: 5.5222\n",
      "batch: 27376/60157............. Loss: 5.5236\n",
      "batch: 27392/60157............. Loss: 5.5167\n",
      "batch: 27408/60157............. Loss: 5.5199\n",
      "batch: 27424/60157............. Loss: 5.5186\n",
      "batch: 27440/60157............. Loss: 5.5173\n",
      "batch: 27456/60157............. Loss: 5.5231\n",
      "batch: 27472/60157............. Loss: 5.5277\n",
      "batch: 27488/60157............. Loss: 5.5186\n",
      "batch: 27504/60157............. Loss: 5.5240\n",
      "batch: 27520/60157............. Loss: 5.5169\n",
      "batch: 27536/60157............. Loss: 5.5209\n",
      "batch: 27552/60157............. Loss: 5.5236\n",
      "batch: 27568/60157............. Loss: 5.5234\n",
      "batch: 27584/60157............. Loss: 5.5203\n",
      "batch: 27600/60157............. Loss: 5.5181\n",
      "batch: 27616/60157............. Loss: 5.5253\n",
      "batch: 27632/60157............. Loss: 5.5240\n",
      "batch: 27648/60157............. Loss: 5.5198\n",
      "batch: 27664/60157............. Loss: 5.5253\n",
      "batch: 27680/60157............. Loss: 5.5254\n",
      "batch: 27696/60157............. Loss: 5.5224\n",
      "batch: 27712/60157............. Loss: 5.5246\n",
      "batch: 27728/60157............. Loss: 5.5210\n",
      "batch: 27744/60157............. Loss: 5.5191\n",
      "batch: 27760/60157............. Loss: 5.5180\n",
      "batch: 27776/60157............. Loss: 5.5231\n",
      "batch: 27792/60157............. Loss: 5.5150\n",
      "batch: 27808/60157............. Loss: 5.5210\n",
      "batch: 27824/60157............. Loss: 5.5157\n",
      "batch: 27840/60157............. Loss: 5.5214\n",
      "batch: 27856/60157............. Loss: 5.5187\n",
      "batch: 27872/60157............. Loss: 5.5201\n",
      "batch: 27888/60157............. Loss: 5.5213\n",
      "batch: 27904/60157............. Loss: 5.5222\n",
      "batch: 27920/60157............. Loss: 5.5210\n",
      "batch: 27936/60157............. Loss: 5.5188\n",
      "batch: 27952/60157............. Loss: 5.5183\n",
      "batch: 27968/60157............. Loss: 5.5148\n",
      "batch: 27984/60157............. Loss: 5.5309\n",
      "batch: 28000/60157............. Loss: 5.5277\n",
      "batch: 28016/60157............. Loss: 5.5302\n",
      "batch: 28032/60157............. Loss: 5.5215\n",
      "batch: 28048/60157............. Loss: 5.5172\n",
      "batch: 28064/60157............. Loss: 5.5209\n",
      "batch: 28080/60157............. Loss: 5.5160\n",
      "batch: 28096/60157............. Loss: 5.5231\n",
      "batch: 28112/60157............. Loss: 5.5236\n",
      "batch: 28128/60157............. Loss: 5.5211\n",
      "batch: 28144/60157............. Loss: 5.5288\n",
      "batch: 28160/60157............. Loss: 5.5217\n",
      "batch: 28176/60157............. Loss: 5.5158\n",
      "batch: 28192/60157............. Loss: 5.5227\n",
      "batch: 28208/60157............. Loss: 5.5230\n",
      "batch: 28224/60157............. Loss: 5.5250\n",
      "batch: 28240/60157............. Loss: 5.5238\n",
      "batch: 28256/60157............. Loss: 5.5213\n",
      "batch: 28272/60157............. Loss: 5.5213\n",
      "batch: 28288/60157............. Loss: 5.5192\n",
      "batch: 28304/60157............. Loss: 5.5236\n",
      "batch: 28320/60157............. Loss: 5.5230\n",
      "batch: 28336/60157............. Loss: 5.5274\n",
      "batch: 28352/60157............. Loss: 5.5188\n",
      "batch: 28368/60157............. Loss: 5.5215\n",
      "batch: 28384/60157............. Loss: 5.5221\n",
      "batch: 28400/60157............. Loss: 5.5258\n",
      "batch: 28416/60157............. Loss: 5.5243\n",
      "batch: 28432/60157............. Loss: 5.5217\n",
      "batch: 28448/60157............. Loss: 5.5239\n",
      "batch: 28464/60157............. Loss: 5.5189\n",
      "batch: 28480/60157............. Loss: 5.5278\n",
      "batch: 28496/60157............. Loss: 5.5211\n",
      "batch: 28512/60157............. Loss: 5.5270\n",
      "batch: 28528/60157............. Loss: 5.5249\n",
      "batch: 28544/60157............. Loss: 5.5167\n",
      "batch: 28560/60157............. Loss: 5.5200\n",
      "batch: 28576/60157............. Loss: 5.5232\n",
      "batch: 28592/60157............. Loss: 5.5221\n",
      "batch: 28608/60157............. Loss: 5.5253\n",
      "batch: 28624/60157............. Loss: 5.5182\n",
      "batch: 28640/60157............. Loss: 5.5217\n",
      "batch: 28656/60157............. Loss: 5.5239\n",
      "batch: 28672/60157............. Loss: 5.5178\n",
      "batch: 28688/60157............. Loss: 5.5220\n",
      "batch: 28704/60157............. Loss: 5.5147\n",
      "batch: 28720/60157............. Loss: 5.5241\n",
      "batch: 28736/60157............. Loss: 5.5272\n",
      "batch: 28752/60157............. Loss: 5.5284\n",
      "batch: 28768/60157............. Loss: 5.5225\n",
      "batch: 28784/60157............. Loss: 5.5244\n",
      "batch: 28800/60157............. Loss: 5.5213\n",
      "batch: 28816/60157............. Loss: 5.5218\n",
      "batch: 28832/60157............. Loss: 5.5231\n",
      "batch: 28848/60157............. Loss: 5.5216\n",
      "batch: 28864/60157............. Loss: 5.5245\n",
      "batch: 28880/60157............. Loss: 5.5212\n",
      "batch: 28896/60157............. Loss: 5.5237\n",
      "batch: 28912/60157............. Loss: 5.5287\n",
      "batch: 28928/60157............. Loss: 5.5210\n",
      "batch: 28944/60157............. Loss: 5.5170\n",
      "batch: 28960/60157............. Loss: 5.5267\n",
      "batch: 28976/60157............. Loss: 5.5221\n",
      "batch: 28992/60157............. Loss: 5.5208\n",
      "batch: 29008/60157............. Loss: 5.5261\n",
      "batch: 29024/60157............. Loss: 5.5235\n",
      "batch: 29040/60157............. Loss: 5.5278\n",
      "batch: 29056/60157............. Loss: 5.5202\n",
      "batch: 29072/60157............. Loss: 5.5197\n",
      "batch: 29088/60157............. Loss: 5.5224\n",
      "batch: 29104/60157............. Loss: 5.5223\n",
      "batch: 29120/60157............. Loss: 5.5205\n",
      "batch: 29136/60157............. Loss: 5.5256\n",
      "batch: 29152/60157............. Loss: 5.5227\n",
      "batch: 29168/60157............. Loss: 5.5190\n",
      "batch: 29184/60157............. Loss: 5.5190\n",
      "batch: 29200/60157............. Loss: 5.5280\n",
      "batch: 29216/60157............. Loss: 5.5190\n",
      "batch: 29232/60157............. Loss: 5.5225\n",
      "batch: 29248/60157............. Loss: 5.5214\n",
      "batch: 29264/60157............. Loss: 5.5218\n",
      "batch: 29280/60157............. Loss: 5.5278\n",
      "batch: 29296/60157............. Loss: 5.5185\n",
      "batch: 29312/60157............. Loss: 5.5260\n",
      "batch: 29328/60157............. Loss: 5.5172\n",
      "batch: 29344/60157............. Loss: 5.5252\n",
      "batch: 29360/60157............. Loss: 5.5202\n",
      "batch: 29376/60157............. Loss: 5.5264\n",
      "batch: 29392/60157............. Loss: 5.5194\n",
      "batch: 29408/60157............. Loss: 5.5215\n",
      "batch: 29424/60157............. Loss: 5.5226\n",
      "batch: 29440/60157............. Loss: 5.5244\n",
      "batch: 29456/60157............. Loss: 5.5242\n",
      "batch: 29472/60157............. Loss: 5.5264\n",
      "batch: 29488/60157............. Loss: 5.5238\n",
      "batch: 29504/60157............. Loss: 5.5177\n",
      "batch: 29520/60157............. Loss: 5.5255\n",
      "batch: 29536/60157............. Loss: 5.5122\n",
      "batch: 29552/60157............. Loss: 5.5245\n",
      "batch: 29568/60157............. Loss: 5.5243\n",
      "batch: 29584/60157............. Loss: 5.5190\n",
      "batch: 29600/60157............. Loss: 5.5255\n",
      "batch: 29616/60157............. Loss: 5.5250\n",
      "batch: 29632/60157............. Loss: 5.5253\n",
      "batch: 29648/60157............. Loss: 5.5205\n",
      "batch: 29664/60157............. Loss: 5.5226\n",
      "batch: 29680/60157............. Loss: 5.5230\n",
      "batch: 29696/60157............. Loss: 5.5274\n",
      "batch: 29712/60157............. Loss: 5.5180\n",
      "batch: 29728/60157............. Loss: 5.5209\n",
      "batch: 29744/60157............. Loss: 5.5281\n",
      "batch: 29760/60157............. Loss: 5.5172\n",
      "batch: 29776/60157............. Loss: 5.5234\n",
      "batch: 29792/60157............. Loss: 5.5179\n",
      "batch: 29808/60157............. Loss: 5.5200\n",
      "batch: 29824/60157............. Loss: 5.5229\n",
      "batch: 29840/60157............. Loss: 5.5219\n",
      "batch: 29856/60157............. Loss: 5.5232\n",
      "batch: 29872/60157............. Loss: 5.5231\n",
      "batch: 29888/60157............. Loss: 5.5253\n",
      "batch: 29904/60157............. Loss: 5.5185\n",
      "batch: 29920/60157............. Loss: 5.5191\n",
      "batch: 29936/60157............. Loss: 5.5202\n",
      "batch: 29952/60157............. Loss: 5.5213\n",
      "batch: 29968/60157............. Loss: 5.5204\n",
      "batch: 29984/60157............. Loss: 5.5169\n",
      "batch: 30000/60157............. Loss: 5.5252\n",
      "batch: 30016/60157............. Loss: 5.5242\n",
      "batch: 30032/60157............. Loss: 5.5305\n",
      "batch: 30048/60157............. Loss: 5.5260\n",
      "batch: 30064/60157............. Loss: 5.5234\n",
      "batch: 30080/60157............. Loss: 5.5206\n",
      "batch: 30096/60157............. Loss: 5.5248\n",
      "batch: 30112/60157............. Loss: 5.5276\n",
      "batch: 30128/60157............. Loss: 5.5266\n",
      "batch: 30144/60157............. Loss: 5.5284\n",
      "batch: 30160/60157............. Loss: 5.5122\n",
      "batch: 30176/60157............. Loss: 5.5248\n",
      "batch: 30192/60157............. Loss: 5.5245\n",
      "batch: 30208/60157............. Loss: 5.5201\n",
      "batch: 30224/60157............. Loss: 5.5233\n",
      "batch: 30240/60157............. Loss: 5.5174\n",
      "batch: 30256/60157............. Loss: 5.5240\n",
      "batch: 30272/60157............. Loss: 5.5226\n",
      "batch: 30288/60157............. Loss: 5.5265\n",
      "batch: 30304/60157............. Loss: 5.5244\n",
      "batch: 30320/60157............. Loss: 5.5207\n",
      "batch: 30336/60157............. Loss: 5.5226\n",
      "batch: 30352/60157............. Loss: 5.5239\n",
      "batch: 30368/60157............. Loss: 5.5258\n",
      "batch: 30384/60157............. Loss: 5.5257\n",
      "batch: 30400/60157............. Loss: 5.5217\n",
      "batch: 30416/60157............. Loss: 5.5185\n",
      "batch: 30432/60157............. Loss: 5.5216\n",
      "batch: 30448/60157............. Loss: 5.5215\n",
      "batch: 30464/60157............. Loss: 5.5244\n",
      "batch: 30480/60157............. Loss: 5.5315\n",
      "batch: 30496/60157............. Loss: 5.5202\n",
      "batch: 30512/60157............. Loss: 5.5189\n",
      "batch: 30528/60157............. Loss: 5.5211\n",
      "batch: 30544/60157............. Loss: 5.5273\n",
      "batch: 30560/60157............. Loss: 5.5215\n",
      "batch: 30576/60157............. Loss: 5.5264\n",
      "batch: 30592/60157............. Loss: 5.5215\n",
      "batch: 30608/60157............. Loss: 5.5104\n",
      "batch: 30624/60157............. Loss: 5.5246\n",
      "batch: 30640/60157............. Loss: 5.5227\n",
      "batch: 30656/60157............. Loss: 5.5238\n",
      "batch: 30672/60157............. Loss: 5.5200\n",
      "batch: 30688/60157............. Loss: 5.5245\n",
      "batch: 30704/60157............. Loss: 5.5248\n",
      "batch: 30720/60157............. Loss: 5.5214\n",
      "batch: 30736/60157............. Loss: 5.5236\n",
      "batch: 30752/60157............. Loss: 5.5225\n",
      "batch: 30768/60157............. Loss: 5.5214\n",
      "batch: 30784/60157............. Loss: 5.5253\n",
      "batch: 30800/60157............. Loss: 5.5240\n",
      "batch: 30816/60157............. Loss: 5.5219\n",
      "batch: 30832/60157............. Loss: 5.5216\n",
      "batch: 30848/60157............. Loss: 5.5233\n",
      "batch: 30864/60157............. Loss: 5.5223\n",
      "batch: 30880/60157............. Loss: 5.5181\n",
      "batch: 30896/60157............. Loss: 5.5231\n",
      "batch: 30912/60157............. Loss: 5.5278\n",
      "batch: 30928/60157............. Loss: 5.5177\n",
      "batch: 30944/60157............. Loss: 5.5246\n",
      "batch: 30960/60157............. Loss: 5.5236\n",
      "batch: 30976/60157............. Loss: 5.5205\n",
      "batch: 30992/60157............. Loss: 5.5255\n",
      "batch: 31008/60157............. Loss: 5.5196\n",
      "batch: 31024/60157............. Loss: 5.5161\n",
      "batch: 31040/60157............. Loss: 5.5236\n",
      "batch: 31056/60157............. Loss: 5.5179\n",
      "batch: 31072/60157............. Loss: 5.5276\n",
      "batch: 31088/60157............. Loss: 5.5177\n",
      "batch: 31104/60157............. Loss: 5.5222\n",
      "batch: 31120/60157............. Loss: 5.5305\n",
      "batch: 31136/60157............. Loss: 5.5240\n",
      "batch: 31152/60157............. Loss: 5.5213\n",
      "batch: 31168/60157............. Loss: 5.5224\n",
      "batch: 31184/60157............. Loss: 5.5193\n",
      "batch: 31200/60157............. Loss: 5.5219\n",
      "batch: 31216/60157............. Loss: 5.5174\n",
      "batch: 31232/60157............. Loss: 5.5226\n",
      "batch: 31248/60157............. Loss: 5.5228\n",
      "batch: 31264/60157............. Loss: 5.5274\n",
      "batch: 31280/60157............. Loss: 5.5251\n",
      "batch: 31296/60157............. Loss: 5.5222\n",
      "batch: 31312/60157............. Loss: 5.5200\n",
      "batch: 31328/60157............. Loss: 5.5228\n",
      "batch: 31344/60157............. Loss: 5.5160\n",
      "batch: 31360/60157............. Loss: 5.5196\n",
      "batch: 31376/60157............. Loss: 5.5173\n",
      "batch: 31392/60157............. Loss: 5.5229\n",
      "batch: 31408/60157............. Loss: 5.5217\n",
      "batch: 31424/60157............. Loss: 5.5193\n",
      "batch: 31440/60157............. Loss: 5.5198\n",
      "batch: 31456/60157............. Loss: 5.5188\n",
      "batch: 31472/60157............. Loss: 5.5263\n",
      "batch: 31488/60157............. Loss: 5.5194\n",
      "batch: 31504/60157............. Loss: 5.5226\n",
      "batch: 31520/60157............. Loss: 5.5244\n",
      "batch: 31536/60157............. Loss: 5.5112\n",
      "batch: 31552/60157............. Loss: 5.5247\n",
      "batch: 31568/60157............. Loss: 5.5191\n",
      "batch: 31584/60157............. Loss: 5.5239\n",
      "batch: 31600/60157............. Loss: 5.5200\n",
      "batch: 31616/60157............. Loss: 5.5229\n",
      "batch: 31632/60157............. Loss: 5.5234\n",
      "batch: 31648/60157............. Loss: 5.5169\n",
      "batch: 31664/60157............. Loss: 5.5286\n",
      "batch: 31680/60157............. Loss: 5.5220\n",
      "batch: 31696/60157............. Loss: 5.5236\n",
      "batch: 31712/60157............. Loss: 5.5228\n",
      "batch: 31728/60157............. Loss: 5.5182\n",
      "batch: 31744/60157............. Loss: 5.5180\n",
      "batch: 31760/60157............. Loss: 5.5204\n",
      "batch: 31776/60157............. Loss: 5.5226\n",
      "batch: 31792/60157............. Loss: 5.5202\n",
      "batch: 31808/60157............. Loss: 5.5235\n",
      "batch: 31824/60157............. Loss: 5.5219\n",
      "batch: 31840/60157............. Loss: 5.5283\n",
      "batch: 31856/60157............. Loss: 5.5263\n",
      "batch: 31872/60157............. Loss: 5.5127\n",
      "batch: 31888/60157............. Loss: 5.5246\n",
      "batch: 31904/60157............. Loss: 5.5241\n",
      "batch: 31920/60157............. Loss: 5.5262\n",
      "batch: 31936/60157............. Loss: 5.5308\n",
      "batch: 31952/60157............. Loss: 5.5292\n",
      "batch: 31968/60157............. Loss: 5.5234\n",
      "batch: 31984/60157............. Loss: 5.5265\n",
      "batch: 32000/60157............. Loss: 5.5285\n",
      "batch: 32016/60157............. Loss: 5.5249\n",
      "batch: 32032/60157............. Loss: 5.5165\n",
      "batch: 32048/60157............. Loss: 5.5287\n",
      "batch: 32064/60157............. Loss: 5.5269\n",
      "batch: 32080/60157............. Loss: 5.5269\n",
      "batch: 32096/60157............. Loss: 5.5265\n",
      "batch: 32112/60157............. Loss: 5.5262\n",
      "batch: 32128/60157............. Loss: 5.5255\n",
      "batch: 32144/60157............. Loss: 5.5267\n",
      "batch: 32160/60157............. Loss: 5.5272\n",
      "batch: 32176/60157............. Loss: 5.5257\n",
      "batch: 32192/60157............. Loss: 5.5227\n",
      "batch: 32208/60157............. Loss: 5.5279\n",
      "batch: 32224/60157............. Loss: 5.5250\n",
      "batch: 32240/60157............. Loss: 5.5257\n",
      "batch: 32256/60157............. Loss: 5.5285\n",
      "batch: 32272/60157............. Loss: 5.5269\n",
      "batch: 32288/60157............. Loss: 5.5295\n",
      "batch: 32304/60157............. Loss: 5.5227\n",
      "batch: 32320/60157............. Loss: 5.5248\n",
      "batch: 32336/60157............. Loss: 5.5257\n",
      "batch: 32352/60157............. Loss: 5.5292\n",
      "batch: 32368/60157............. Loss: 5.5297\n",
      "batch: 32384/60157............. Loss: 5.5236\n",
      "batch: 32400/60157............. Loss: 5.5277\n",
      "batch: 32416/60157............. Loss: 5.5292\n",
      "batch: 32432/60157............. Loss: 5.5277\n",
      "batch: 32448/60157............. Loss: 5.5238\n",
      "batch: 32464/60157............. Loss: 5.5294\n",
      "batch: 32480/60157............. Loss: 5.5267\n",
      "batch: 32496/60157............. Loss: 5.5219\n",
      "batch: 32512/60157............. Loss: 5.5236\n",
      "batch: 32528/60157............. Loss: 5.5244\n",
      "batch: 32544/60157............. Loss: 5.5275\n",
      "batch: 32560/60157............. Loss: 5.5268\n",
      "batch: 32576/60157............. Loss: 5.5249\n",
      "batch: 32592/60157............. Loss: 5.5265\n",
      "batch: 32608/60157............. Loss: 5.5277\n",
      "batch: 32624/60157............. Loss: 5.5237\n",
      "batch: 32640/60157............. Loss: 5.5259\n",
      "batch: 32656/60157............. Loss: 5.5212\n",
      "batch: 32672/60157............. Loss: 5.5268\n",
      "batch: 32688/60157............. Loss: 5.5292\n",
      "batch: 32704/60157............. Loss: 5.5235\n",
      "batch: 32720/60157............. Loss: 5.5287\n",
      "batch: 32736/60157............. Loss: 5.5300\n",
      "batch: 32752/60157............. Loss: 5.5284\n",
      "batch: 32768/60157............. Loss: 5.5322\n",
      "batch: 32784/60157............. Loss: 5.5280\n",
      "batch: 32800/60157............. Loss: 5.5299\n",
      "batch: 32816/60157............. Loss: 5.5308\n",
      "batch: 32832/60157............. Loss: 5.5197\n",
      "batch: 32848/60157............. Loss: 5.5280\n",
      "batch: 32864/60157............. Loss: 5.5275\n",
      "batch: 32880/60157............. Loss: 5.5231\n",
      "batch: 32896/60157............. Loss: 5.5265\n",
      "batch: 32912/60157............. Loss: 5.5268\n",
      "batch: 32928/60157............. Loss: 5.5327\n",
      "batch: 32944/60157............. Loss: 5.5209\n",
      "batch: 32960/60157............. Loss: 5.5257\n",
      "batch: 32976/60157............. Loss: 5.5272\n",
      "batch: 32992/60157............. Loss: 5.5201\n",
      "batch: 33008/60157............. Loss: 5.5210\n",
      "batch: 33024/60157............. Loss: 5.5293\n",
      "batch: 33040/60157............. Loss: 5.5226\n",
      "batch: 33056/60157............. Loss: 5.5336\n",
      "batch: 33072/60157............. Loss: 5.5286\n",
      "batch: 33088/60157............. Loss: 5.5198\n",
      "batch: 33104/60157............. Loss: 5.5288\n",
      "batch: 33120/60157............. Loss: 5.5261\n",
      "batch: 33136/60157............. Loss: 5.5221\n",
      "batch: 33152/60157............. Loss: 5.5297\n",
      "batch: 33168/60157............. Loss: 5.5264\n",
      "batch: 33184/60157............. Loss: 5.5168\n",
      "batch: 33200/60157............. Loss: 5.5249\n",
      "batch: 33216/60157............. Loss: 5.5259\n",
      "batch: 33232/60157............. Loss: 5.5252\n",
      "batch: 33248/60157............. Loss: 5.5268\n",
      "batch: 33264/60157............. Loss: 5.5226\n",
      "batch: 33280/60157............. Loss: 5.5250\n",
      "batch: 33296/60157............. Loss: 5.5311\n",
      "batch: 33312/60157............. Loss: 5.5248\n",
      "batch: 33328/60157............. Loss: 5.5312\n",
      "batch: 33344/60157............. Loss: 5.5224\n",
      "batch: 33360/60157............. Loss: 5.5201\n",
      "batch: 33376/60157............. Loss: 5.5250\n",
      "batch: 33392/60157............. Loss: 5.5234\n",
      "batch: 33408/60157............. Loss: 5.5273\n",
      "batch: 33424/60157............. Loss: 5.5256\n",
      "batch: 33440/60157............. Loss: 5.5245\n",
      "batch: 33456/60157............. Loss: 5.5249\n",
      "batch: 33472/60157............. Loss: 5.5254\n",
      "batch: 33488/60157............. Loss: 5.5297\n",
      "batch: 33504/60157............. Loss: 5.5264\n",
      "batch: 33520/60157............. Loss: 5.5313\n",
      "batch: 33536/60157............. Loss: 5.5301\n",
      "batch: 33552/60157............. Loss: 5.5249\n",
      "batch: 33568/60157............. Loss: 5.5287\n",
      "batch: 33584/60157............. Loss: 5.5269\n",
      "batch: 33600/60157............. Loss: 5.5210\n",
      "batch: 33616/60157............. Loss: 5.5231\n",
      "batch: 33632/60157............. Loss: 5.5214\n",
      "batch: 33648/60157............. Loss: 5.5286\n",
      "batch: 33664/60157............. Loss: 5.5241\n",
      "batch: 33680/60157............. Loss: 5.5203\n",
      "batch: 33696/60157............. Loss: 5.5195\n",
      "batch: 33712/60157............. Loss: 5.5286\n",
      "batch: 33728/60157............. Loss: 5.5277\n",
      "batch: 33744/60157............. Loss: 5.5285\n",
      "batch: 33760/60157............. Loss: 5.5151\n",
      "batch: 33776/60157............. Loss: 5.5270\n",
      "batch: 33792/60157............. Loss: 5.5303\n",
      "batch: 33808/60157............. Loss: 5.5266\n",
      "batch: 33824/60157............. Loss: 5.5234\n",
      "batch: 33840/60157............. Loss: 5.5223\n",
      "batch: 33856/60157............. Loss: 5.5245\n",
      "batch: 33872/60157............. Loss: 5.5195\n",
      "batch: 33888/60157............. Loss: 5.5222\n",
      "batch: 33904/60157............. Loss: 5.5264\n",
      "batch: 33920/60157............. Loss: 5.5266\n",
      "batch: 33936/60157............. Loss: 5.5206\n",
      "batch: 33952/60157............. Loss: 5.5242\n",
      "batch: 33968/60157............. Loss: 5.5250\n",
      "batch: 33984/60157............. Loss: 5.5258\n",
      "batch: 34000/60157............. Loss: 5.5286\n",
      "batch: 34016/60157............. Loss: 5.5283\n",
      "batch: 34032/60157............. Loss: 5.5291\n",
      "batch: 34048/60157............. Loss: 5.5213\n",
      "batch: 34064/60157............. Loss: 5.5238\n",
      "batch: 34080/60157............. Loss: 5.5248\n",
      "batch: 34096/60157............. Loss: 5.5298\n",
      "batch: 34112/60157............. Loss: 5.5307\n",
      "batch: 34128/60157............. Loss: 5.5279\n",
      "batch: 34144/60157............. Loss: 5.5280\n",
      "batch: 34160/60157............. Loss: 5.5282\n",
      "batch: 34176/60157............. Loss: 5.5210\n",
      "batch: 34192/60157............. Loss: 5.5261\n",
      "batch: 34208/60157............. Loss: 5.5195\n",
      "batch: 34224/60157............. Loss: 5.5248\n",
      "batch: 34240/60157............. Loss: 5.5175\n",
      "batch: 34256/60157............. Loss: 5.5226\n",
      "batch: 34272/60157............. Loss: 5.5301\n",
      "batch: 34288/60157............. Loss: 5.5256\n",
      "batch: 34304/60157............. Loss: 5.5269\n",
      "batch: 34320/60157............. Loss: 5.5215\n",
      "batch: 34336/60157............. Loss: 5.5220\n",
      "batch: 34352/60157............. Loss: 5.5161\n",
      "batch: 34368/60157............. Loss: 5.5193\n",
      "batch: 34384/60157............. Loss: 5.5269\n",
      "batch: 34400/60157............. Loss: 5.5256\n",
      "batch: 34416/60157............. Loss: 5.5222\n",
      "batch: 34432/60157............. Loss: 5.5261\n",
      "batch: 34448/60157............. Loss: 5.5234\n",
      "batch: 34464/60157............. Loss: 5.5290\n",
      "batch: 34480/60157............. Loss: 5.5251\n",
      "batch: 34496/60157............. Loss: 5.5203\n",
      "batch: 34512/60157............. Loss: 5.5204\n",
      "batch: 34528/60157............. Loss: 5.5183\n",
      "batch: 34544/60157............. Loss: 5.5314\n",
      "batch: 34560/60157............. Loss: 5.5224\n",
      "batch: 34576/60157............. Loss: 5.5234\n",
      "batch: 34592/60157............. Loss: 5.5234\n",
      "batch: 34608/60157............. Loss: 5.5272\n",
      "batch: 34624/60157............. Loss: 5.5228\n",
      "batch: 34640/60157............. Loss: 5.5207\n",
      "batch: 34656/60157............. Loss: 5.5257\n",
      "batch: 34672/60157............. Loss: 5.5222\n",
      "batch: 34688/60157............. Loss: 5.5231\n",
      "batch: 34704/60157............. Loss: 5.5210\n",
      "batch: 34720/60157............. Loss: 5.5236\n",
      "batch: 34736/60157............. Loss: 5.5245\n",
      "batch: 34752/60157............. Loss: 5.5246\n",
      "batch: 34768/60157............. Loss: 5.5199\n",
      "batch: 34784/60157............. Loss: 5.5213\n",
      "batch: 34800/60157............. Loss: 5.5203\n",
      "batch: 34816/60157............. Loss: 5.5214\n",
      "batch: 34832/60157............. Loss: 5.5259\n",
      "batch: 34848/60157............. Loss: 5.5191\n",
      "batch: 34864/60157............. Loss: 5.5169\n",
      "batch: 34880/60157............. Loss: 5.5216\n",
      "batch: 34896/60157............. Loss: 5.5278\n",
      "batch: 34912/60157............. Loss: 5.5262\n",
      "batch: 34928/60157............. Loss: 5.5264\n",
      "batch: 34944/60157............. Loss: 5.5224\n",
      "batch: 34960/60157............. Loss: 5.5185\n",
      "batch: 34976/60157............. Loss: 5.5266\n",
      "batch: 34992/60157............. Loss: 5.5235\n",
      "batch: 35008/60157............. Loss: 5.5142\n",
      "batch: 35024/60157............. Loss: 5.5213\n",
      "batch: 35040/60157............. Loss: 5.5270\n",
      "batch: 35056/60157............. Loss: 5.5247\n",
      "batch: 35072/60157............. Loss: 5.5171\n",
      "batch: 35088/60157............. Loss: 5.5201\n",
      "batch: 35104/60157............. Loss: 5.5193\n",
      "batch: 35120/60157............. Loss: 5.5241\n",
      "batch: 35136/60157............. Loss: 5.5249\n",
      "batch: 35152/60157............. Loss: 5.5227\n",
      "batch: 35168/60157............. Loss: 5.5229\n",
      "batch: 35184/60157............. Loss: 5.5234\n",
      "batch: 35200/60157............. Loss: 5.5199\n",
      "batch: 35216/60157............. Loss: 5.5198\n",
      "batch: 35232/60157............. Loss: 5.5220\n",
      "batch: 35248/60157............. Loss: 5.5194\n",
      "batch: 35264/60157............. Loss: 5.5263\n",
      "batch: 35280/60157............. Loss: 5.5182\n",
      "batch: 35296/60157............. Loss: 5.5242\n",
      "batch: 35312/60157............. Loss: 5.5237\n",
      "batch: 35328/60157............. Loss: 5.5217\n",
      "batch: 35344/60157............. Loss: 5.5222\n",
      "batch: 35360/60157............. Loss: 5.5238\n",
      "batch: 35376/60157............. Loss: 5.5220\n",
      "batch: 35392/60157............. Loss: 5.5236\n",
      "batch: 35408/60157............. Loss: 5.5195\n",
      "batch: 35424/60157............. Loss: 5.5201\n",
      "batch: 35440/60157............. Loss: 5.5237\n",
      "batch: 35456/60157............. Loss: 5.5227\n",
      "batch: 35472/60157............. Loss: 5.5205\n",
      "batch: 35488/60157............. Loss: 5.5269\n",
      "batch: 35504/60157............. Loss: 5.5292\n",
      "batch: 35520/60157............. Loss: 5.5260\n",
      "batch: 35536/60157............. Loss: 5.5190\n",
      "batch: 35552/60157............. Loss: 5.5197\n",
      "batch: 35568/60157............. Loss: 5.5209\n",
      "batch: 35584/60157............. Loss: 5.5148\n",
      "batch: 35600/60157............. Loss: 5.5245\n",
      "batch: 35616/60157............. Loss: 5.5231\n",
      "batch: 35632/60157............. Loss: 5.5257\n",
      "batch: 35648/60157............. Loss: 5.5259\n",
      "batch: 35664/60157............. Loss: 5.5184\n",
      "batch: 35680/60157............. Loss: 5.5188\n",
      "batch: 35696/60157............. Loss: 5.5154\n",
      "batch: 35712/60157............. Loss: 5.5247\n",
      "batch: 35728/60157............. Loss: 5.5291\n",
      "batch: 35744/60157............. Loss: 5.5276\n",
      "batch: 35760/60157............. Loss: 5.5276\n",
      "batch: 35776/60157............. Loss: 5.5281\n",
      "batch: 35792/60157............. Loss: 5.5221\n",
      "batch: 35808/60157............. Loss: 5.5214\n",
      "batch: 35824/60157............. Loss: 5.5216\n",
      "batch: 35840/60157............. Loss: 5.5249\n",
      "batch: 35856/60157............. Loss: 5.5227\n",
      "batch: 35872/60157............. Loss: 5.5283\n",
      "batch: 35888/60157............. Loss: 5.5192\n",
      "batch: 35904/60157............. Loss: 5.5239\n",
      "batch: 35920/60157............. Loss: 5.5216\n",
      "batch: 35936/60157............. Loss: 5.5256\n",
      "batch: 35952/60157............. Loss: 5.5207\n",
      "batch: 35968/60157............. Loss: 5.5225\n",
      "batch: 35984/60157............. Loss: 5.5258\n",
      "batch: 36000/60157............. Loss: 5.5222\n",
      "batch: 36016/60157............. Loss: 5.5291\n",
      "batch: 36032/60157............. Loss: 5.5253\n",
      "batch: 36048/60157............. Loss: 5.5237\n",
      "batch: 36064/60157............. Loss: 5.5233\n",
      "batch: 36080/60157............. Loss: 5.5265\n",
      "batch: 36096/60157............. Loss: 5.5230\n",
      "batch: 36112/60157............. Loss: 5.5262\n",
      "batch: 36128/60157............. Loss: 5.5240\n",
      "batch: 36144/60157............. Loss: 5.5206\n",
      "batch: 36160/60157............. Loss: 5.5280\n",
      "batch: 36176/60157............. Loss: 5.5287\n",
      "batch: 36192/60157............. Loss: 5.5251\n",
      "batch: 36208/60157............. Loss: 5.5252\n",
      "batch: 36224/60157............. Loss: 5.5199\n",
      "batch: 36240/60157............. Loss: 5.5268\n",
      "batch: 36256/60157............. Loss: 5.5277\n",
      "batch: 36272/60157............. Loss: 5.5188\n",
      "batch: 36288/60157............. Loss: 5.5277\n",
      "batch: 36304/60157............. Loss: 5.5227\n",
      "batch: 36320/60157............. Loss: 5.5239\n",
      "batch: 36336/60157............. Loss: 5.5226\n",
      "batch: 36352/60157............. Loss: 5.5274\n",
      "batch: 36368/60157............. Loss: 5.5260\n",
      "batch: 36384/60157............. Loss: 5.5311\n",
      "batch: 36400/60157............. Loss: 5.5222\n",
      "batch: 36416/60157............. Loss: 5.5235\n",
      "batch: 36432/60157............. Loss: 5.5201\n",
      "batch: 36448/60157............. Loss: 5.5287\n",
      "batch: 36464/60157............. Loss: 5.5266\n",
      "batch: 36480/60157............. Loss: 5.5277\n",
      "batch: 36496/60157............. Loss: 5.5281\n",
      "batch: 36512/60157............. Loss: 5.5284\n",
      "batch: 36528/60157............. Loss: 5.5197\n",
      "batch: 36544/60157............. Loss: 5.5230\n",
      "batch: 36560/60157............. Loss: 5.5251\n",
      "batch: 36576/60157............. Loss: 5.5278\n",
      "batch: 36592/60157............. Loss: 5.5230\n",
      "batch: 36608/60157............. Loss: 5.5260\n",
      "batch: 36624/60157............. Loss: 5.5237\n",
      "batch: 36640/60157............. Loss: 5.5287\n",
      "batch: 36656/60157............. Loss: 5.5295\n",
      "batch: 36672/60157............. Loss: 5.5292\n",
      "batch: 36688/60157............. Loss: 5.5240\n",
      "batch: 36704/60157............. Loss: 5.5208\n",
      "batch: 36720/60157............. Loss: 5.5243\n",
      "batch: 36736/60157............. Loss: 5.5243\n",
      "batch: 36752/60157............. Loss: 5.5272\n",
      "batch: 36768/60157............. Loss: 5.5236\n",
      "batch: 36784/60157............. Loss: 5.5274\n",
      "batch: 36800/60157............. Loss: 5.5278\n",
      "batch: 36816/60157............. Loss: 5.5248\n",
      "batch: 36832/60157............. Loss: 5.5279\n",
      "batch: 36848/60157............. Loss: 5.5259\n",
      "batch: 36864/60157............. Loss: 5.5220\n",
      "batch: 36880/60157............. Loss: 5.5207\n",
      "batch: 36896/60157............. Loss: 5.5289\n",
      "batch: 36912/60157............. Loss: 5.5293\n",
      "batch: 36928/60157............. Loss: 5.5233\n",
      "batch: 36944/60157............. Loss: 5.5226\n",
      "batch: 36960/60157............. Loss: 5.5181\n",
      "batch: 36976/60157............. Loss: 5.5300\n",
      "batch: 36992/60157............. Loss: 5.5288\n",
      "batch: 37008/60157............. Loss: 5.5262\n",
      "batch: 37024/60157............. Loss: 5.5292\n",
      "batch: 37040/60157............. Loss: 5.5278\n",
      "batch: 37056/60157............. Loss: 5.5258\n",
      "batch: 37072/60157............. Loss: 5.5301\n",
      "batch: 37088/60157............. Loss: 5.5249\n",
      "batch: 37104/60157............. Loss: 5.5248\n",
      "batch: 37120/60157............. Loss: 5.5304\n",
      "batch: 37136/60157............. Loss: 5.5236\n",
      "batch: 37152/60157............. Loss: 5.5303\n",
      "batch: 37168/60157............. Loss: 5.5276\n",
      "batch: 37184/60157............. Loss: 5.5300\n",
      "batch: 37200/60157............. Loss: 5.5340\n",
      "batch: 37216/60157............. Loss: 5.5301\n",
      "batch: 37232/60157............. Loss: 5.5251\n",
      "batch: 37248/60157............. Loss: 5.5236\n",
      "batch: 37264/60157............. Loss: 5.5221\n",
      "batch: 37280/60157............. Loss: 5.5267\n",
      "batch: 37296/60157............. Loss: 5.5268\n",
      "batch: 37312/60157............. Loss: 5.5277\n",
      "batch: 37328/60157............. Loss: 5.5222\n",
      "batch: 37344/60157............. Loss: 5.5253\n",
      "batch: 37360/60157............. Loss: 5.5263\n",
      "batch: 37376/60157............. Loss: 5.5216\n",
      "batch: 37392/60157............. Loss: 5.5240\n",
      "batch: 37408/60157............. Loss: 5.5273\n",
      "batch: 37424/60157............. Loss: 5.5318\n",
      "batch: 37440/60157............. Loss: 5.5246\n",
      "batch: 37456/60157............. Loss: 5.5274\n",
      "batch: 37472/60157............. Loss: 5.5262\n",
      "batch: 37488/60157............. Loss: 5.5270\n",
      "batch: 37504/60157............. Loss: 5.5254\n",
      "batch: 37520/60157............. Loss: 5.5301\n",
      "batch: 37536/60157............. Loss: 5.5282\n",
      "batch: 37552/60157............. Loss: 5.5244\n",
      "batch: 37568/60157............. Loss: 5.5257\n",
      "batch: 37584/60157............. Loss: 5.5261\n",
      "batch: 37600/60157............. Loss: 5.5258\n",
      "batch: 37616/60157............. Loss: 5.5265\n",
      "batch: 37632/60157............. Loss: 5.5220\n",
      "batch: 37648/60157............. Loss: 5.5291\n",
      "batch: 37664/60157............. Loss: 5.5273\n",
      "batch: 37680/60157............. Loss: 5.5293\n",
      "batch: 37696/60157............. Loss: 5.5259\n",
      "batch: 37712/60157............. Loss: 5.5303\n",
      "batch: 37728/60157............. Loss: 5.5270\n",
      "batch: 37744/60157............. Loss: 5.5305\n",
      "batch: 37760/60157............. Loss: 5.5280\n",
      "batch: 37776/60157............. Loss: 5.5242\n",
      "batch: 37792/60157............. Loss: 5.5318\n",
      "batch: 37808/60157............. Loss: 5.5249\n",
      "batch: 37824/60157............. Loss: 5.5287\n",
      "batch: 37840/60157............. Loss: 5.5286\n",
      "batch: 37856/60157............. Loss: 5.5270\n",
      "batch: 37872/60157............. Loss: 5.5273\n",
      "batch: 37888/60157............. Loss: 5.5256\n",
      "batch: 37904/60157............. Loss: 5.5242\n",
      "batch: 37920/60157............. Loss: 5.5261\n",
      "batch: 37936/60157............. Loss: 5.5281\n",
      "batch: 37952/60157............. Loss: 5.5329\n",
      "batch: 37968/60157............. Loss: 5.5242\n",
      "batch: 37984/60157............. Loss: 5.5270\n",
      "batch: 38000/60157............. Loss: 5.5242\n",
      "batch: 38016/60157............. Loss: 5.5300\n",
      "batch: 38032/60157............. Loss: 5.5262\n",
      "batch: 38048/60157............. Loss: 5.5255\n",
      "batch: 38064/60157............. Loss: 5.5272\n",
      "batch: 38080/60157............. Loss: 5.5271\n",
      "batch: 38096/60157............. Loss: 5.5289\n",
      "batch: 38112/60157............. Loss: 5.5303\n",
      "batch: 38128/60157............. Loss: 5.5320\n",
      "batch: 38144/60157............. Loss: 5.5254\n",
      "batch: 38160/60157............. Loss: 5.5254\n",
      "batch: 38176/60157............. Loss: 5.5295\n",
      "batch: 38192/60157............. Loss: 5.5243\n",
      "batch: 38208/60157............. Loss: 5.5279\n",
      "batch: 38224/60157............. Loss: 5.5270\n",
      "batch: 38240/60157............. Loss: 5.5302\n",
      "batch: 38256/60157............. Loss: 5.5239\n",
      "batch: 38272/60157............. Loss: 5.5274\n",
      "batch: 38288/60157............. Loss: 5.5237\n",
      "batch: 38304/60157............. Loss: 5.5290\n",
      "batch: 38320/60157............. Loss: 5.5262\n",
      "batch: 38336/60157............. Loss: 5.5233\n",
      "batch: 38352/60157............. Loss: 5.5237\n",
      "batch: 38368/60157............. Loss: 5.5284\n",
      "batch: 38384/60157............. Loss: 5.5191\n",
      "batch: 38400/60157............. Loss: 5.5243\n",
      "batch: 38416/60157............. Loss: 5.5277\n",
      "batch: 38432/60157............. Loss: 5.5285\n",
      "batch: 38448/60157............. Loss: 5.5245\n",
      "batch: 38464/60157............. Loss: 5.5268\n",
      "batch: 38480/60157............. Loss: 5.5277\n",
      "batch: 38496/60157............. Loss: 5.5265\n",
      "batch: 38512/60157............. Loss: 5.5205\n",
      "batch: 38528/60157............. Loss: 5.5266\n",
      "batch: 38544/60157............. Loss: 5.5292\n",
      "batch: 38560/60157............. Loss: 5.5246\n",
      "batch: 38576/60157............. Loss: 5.5278\n",
      "batch: 38592/60157............. Loss: 5.5215\n",
      "batch: 38608/60157............. Loss: 5.5285\n",
      "batch: 38624/60157............. Loss: 5.5270\n",
      "batch: 38640/60157............. Loss: 5.5295\n",
      "batch: 38656/60157............. Loss: 5.5315\n",
      "batch: 38672/60157............. Loss: 5.5225\n",
      "batch: 38688/60157............. Loss: 5.5269\n",
      "batch: 38704/60157............. Loss: 5.5282\n",
      "batch: 38720/60157............. Loss: 5.5251\n",
      "batch: 38736/60157............. Loss: 5.5250\n",
      "batch: 38752/60157............. Loss: 5.5292\n",
      "batch: 38768/60157............. Loss: 5.5247\n",
      "batch: 38784/60157............. Loss: 5.5245\n",
      "batch: 38800/60157............. Loss: 5.5290\n",
      "batch: 38816/60157............. Loss: 5.5236\n",
      "batch: 38832/60157............. Loss: 5.5271\n",
      "batch: 38848/60157............. Loss: 5.5246\n",
      "batch: 38864/60157............. Loss: 5.5253\n",
      "batch: 38880/60157............. Loss: 5.5258\n",
      "batch: 38896/60157............. Loss: 5.5285\n",
      "batch: 38912/60157............. Loss: 5.5283\n",
      "batch: 38928/60157............. Loss: 5.5282\n",
      "batch: 38944/60157............. Loss: 5.5209\n",
      "batch: 38960/60157............. Loss: 5.5105\n",
      "batch: 38976/60157............. Loss: 5.5239\n",
      "batch: 38992/60157............. Loss: 5.5230\n",
      "batch: 39008/60157............. Loss: 5.5243\n",
      "batch: 39024/60157............. Loss: 5.5301\n",
      "batch: 39040/60157............. Loss: 5.5253\n",
      "batch: 39056/60157............. Loss: 5.5257\n",
      "batch: 39072/60157............. Loss: 5.5260\n",
      "batch: 39088/60157............. Loss: 5.5264\n",
      "batch: 39104/60157............. Loss: 5.5237\n",
      "batch: 39120/60157............. Loss: 5.5251\n",
      "batch: 39136/60157............. Loss: 5.5230\n",
      "batch: 39152/60157............. Loss: 5.5304\n",
      "batch: 39168/60157............. Loss: 5.5254\n",
      "batch: 39184/60157............. Loss: 5.5258\n",
      "batch: 39200/60157............. Loss: 5.5267\n",
      "batch: 39216/60157............. Loss: 5.5216\n",
      "batch: 39232/60157............. Loss: 5.5289\n",
      "batch: 39248/60157............. Loss: 5.5270\n",
      "batch: 39264/60157............. Loss: 5.5283\n",
      "batch: 39280/60157............. Loss: 5.5247\n",
      "batch: 39296/60157............. Loss: 5.5295\n",
      "batch: 39312/60157............. Loss: 5.5273\n",
      "batch: 39328/60157............. Loss: 5.5314\n",
      "batch: 39344/60157............. Loss: 5.5279\n",
      "batch: 39360/60157............. Loss: 5.5239\n",
      "batch: 39376/60157............. Loss: 5.5189\n",
      "batch: 39392/60157............. Loss: 5.5261\n",
      "batch: 39408/60157............. Loss: 5.5234\n",
      "batch: 39424/60157............. Loss: 5.5291\n",
      "batch: 39440/60157............. Loss: 5.5266\n",
      "batch: 39456/60157............. Loss: 5.5262\n",
      "batch: 39472/60157............. Loss: 5.5289\n",
      "batch: 39488/60157............. Loss: 5.5319\n",
      "batch: 39504/60157............. Loss: 5.5285\n",
      "batch: 39520/60157............. Loss: 5.5296\n",
      "batch: 39536/60157............. Loss: 5.5227\n",
      "batch: 39552/60157............. Loss: 5.5234\n",
      "batch: 39568/60157............. Loss: 5.5273\n",
      "batch: 39584/60157............. Loss: 5.5276\n",
      "batch: 39600/60157............. Loss: 5.5253\n",
      "batch: 39616/60157............. Loss: 5.5275\n",
      "batch: 39632/60157............. Loss: 5.5230\n",
      "batch: 39648/60157............. Loss: 5.5236\n",
      "batch: 39664/60157............. Loss: 5.5244\n",
      "batch: 39680/60157............. Loss: 5.5277\n",
      "batch: 39696/60157............. Loss: 5.5270\n",
      "batch: 39712/60157............. Loss: 5.5246\n",
      "batch: 39728/60157............. Loss: 5.5262\n",
      "batch: 39744/60157............. Loss: 5.5240\n",
      "batch: 39760/60157............. Loss: 5.5235\n",
      "batch: 39776/60157............. Loss: 5.5311\n",
      "batch: 39792/60157............. Loss: 5.5239\n",
      "batch: 39808/60157............. Loss: 5.5209\n",
      "batch: 39824/60157............. Loss: 5.5287\n",
      "batch: 39840/60157............. Loss: 5.5291\n",
      "batch: 39856/60157............. Loss: 5.5258\n",
      "batch: 39872/60157............. Loss: 5.5274\n",
      "batch: 39888/60157............. Loss: 5.5273\n",
      "batch: 39904/60157............. Loss: 5.5209\n",
      "batch: 39920/60157............. Loss: 5.5255\n",
      "batch: 39936/60157............. Loss: 5.5234\n",
      "batch: 39952/60157............. Loss: 5.5243\n",
      "batch: 39968/60157............. Loss: 5.5225\n",
      "batch: 39984/60157............. Loss: 5.5256\n",
      "batch: 40000/60157............. Loss: 5.5225\n",
      "batch: 40016/60157............. Loss: 5.5231\n",
      "batch: 40032/60157............. Loss: 5.5302\n",
      "batch: 40048/60157............. Loss: 5.5256\n",
      "batch: 40064/60157............. Loss: 5.5323\n",
      "batch: 40080/60157............. Loss: 5.5258\n",
      "batch: 40096/60157............. Loss: 5.5256\n",
      "batch: 40112/60157............. Loss: 5.5233\n",
      "batch: 40128/60157............. Loss: 5.5315\n",
      "batch: 40144/60157............. Loss: 5.5206\n",
      "batch: 40160/60157............. Loss: 5.5225\n",
      "batch: 40176/60157............. Loss: 5.5217\n",
      "batch: 40192/60157............. Loss: 5.5291\n",
      "batch: 40208/60157............. Loss: 5.5291\n",
      "batch: 40224/60157............. Loss: 5.5270\n",
      "batch: 40240/60157............. Loss: 5.5242\n",
      "batch: 40256/60157............. Loss: 5.5302\n",
      "batch: 40272/60157............. Loss: 5.5273\n",
      "batch: 40288/60157............. Loss: 5.5258\n",
      "batch: 40304/60157............. Loss: 5.5287\n",
      "batch: 40320/60157............. Loss: 5.5272\n",
      "batch: 40336/60157............. Loss: 5.5198\n",
      "batch: 40352/60157............. Loss: 5.5286\n",
      "batch: 40368/60157............. Loss: 5.5268\n",
      "batch: 40384/60157............. Loss: 5.5255\n",
      "batch: 40400/60157............. Loss: 5.5221\n",
      "batch: 40416/60157............. Loss: 5.5240\n",
      "batch: 40432/60157............. Loss: 5.5259\n",
      "batch: 40448/60157............. Loss: 5.5273\n",
      "batch: 40464/60157............. Loss: 5.5255\n",
      "batch: 40480/60157............. Loss: 5.5261\n",
      "batch: 40496/60157............. Loss: 5.5230\n",
      "batch: 40512/60157............. Loss: 5.5242\n",
      "batch: 40528/60157............. Loss: 5.5283\n",
      "batch: 40544/60157............. Loss: 5.5273\n",
      "batch: 40560/60157............. Loss: 5.5272\n",
      "batch: 40576/60157............. Loss: 5.5247\n",
      "batch: 40592/60157............. Loss: 5.5309\n",
      "batch: 40608/60157............. Loss: 5.5258\n",
      "batch: 40624/60157............. Loss: 5.5228\n",
      "batch: 40640/60157............. Loss: 5.5234\n",
      "batch: 40656/60157............. Loss: 5.5173\n",
      "batch: 40672/60157............. Loss: 5.5287\n",
      "batch: 40688/60157............. Loss: 5.5274\n",
      "batch: 40704/60157............. Loss: 5.5220\n",
      "batch: 40720/60157............. Loss: 5.5274\n",
      "batch: 40736/60157............. Loss: 5.5287\n",
      "batch: 40752/60157............. Loss: 5.5288\n",
      "batch: 40768/60157............. Loss: 5.5280\n",
      "batch: 40784/60157............. Loss: 5.5232\n",
      "batch: 40800/60157............. Loss: 5.5205\n",
      "batch: 40816/60157............. Loss: 5.5246\n",
      "batch: 40832/60157............. Loss: 5.5265\n",
      "batch: 40848/60157............. Loss: 5.5293\n",
      "batch: 40864/60157............. Loss: 5.5168\n",
      "batch: 40880/60157............. Loss: 5.5242\n",
      "batch: 40896/60157............. Loss: 5.5285\n",
      "batch: 40912/60157............. Loss: 5.5269\n",
      "batch: 40928/60157............. Loss: 5.5265\n",
      "batch: 40944/60157............. Loss: 5.5249\n",
      "batch: 40960/60157............. Loss: 5.5230\n",
      "batch: 40976/60157............. Loss: 5.5263\n",
      "batch: 40992/60157............. Loss: 5.5277\n",
      "batch: 41008/60157............. Loss: 5.5218\n",
      "batch: 41024/60157............. Loss: 5.5222\n",
      "batch: 41040/60157............. Loss: 5.5268\n",
      "batch: 41056/60157............. Loss: 5.5181\n",
      "batch: 41072/60157............. Loss: 5.5207\n",
      "batch: 41088/60157............. Loss: 5.5306\n",
      "batch: 41104/60157............. Loss: 5.5242\n",
      "batch: 41120/60157............. Loss: 5.5310\n",
      "batch: 41136/60157............. Loss: 5.5272\n",
      "batch: 41152/60157............. Loss: 5.5253\n",
      "batch: 41168/60157............. Loss: 5.5241\n",
      "batch: 41184/60157............. Loss: 5.5258\n",
      "batch: 41200/60157............. Loss: 5.5258\n",
      "batch: 41216/60157............. Loss: 5.5289\n",
      "batch: 41232/60157............. Loss: 5.5265\n",
      "batch: 41248/60157............. Loss: 5.5307\n",
      "batch: 41264/60157............. Loss: 5.5261\n",
      "batch: 41280/60157............. Loss: 5.5237\n",
      "batch: 41296/60157............. Loss: 5.5245\n",
      "batch: 41312/60157............. Loss: 5.5307\n",
      "batch: 41328/60157............. Loss: 5.5280\n",
      "batch: 41344/60157............. Loss: 5.5191\n",
      "batch: 41360/60157............. Loss: 5.5231\n",
      "batch: 41376/60157............. Loss: 5.5279\n",
      "batch: 41392/60157............. Loss: 5.5242\n",
      "batch: 41408/60157............. Loss: 5.5291\n",
      "batch: 41424/60157............. Loss: 5.5201\n",
      "batch: 41440/60157............. Loss: 5.5270\n",
      "batch: 41456/60157............. Loss: 5.5242\n",
      "batch: 41472/60157............. Loss: 5.5269\n",
      "batch: 41488/60157............. Loss: 5.5245\n",
      "batch: 41504/60157............. Loss: 5.5224\n",
      "batch: 41520/60157............. Loss: 5.5257\n",
      "batch: 41536/60157............. Loss: 5.5147\n",
      "batch: 41552/60157............. Loss: 5.5266\n",
      "batch: 41568/60157............. Loss: 5.5277\n",
      "batch: 41584/60157............. Loss: 5.5269\n",
      "batch: 41600/60157............. Loss: 5.5262\n",
      "batch: 41616/60157............. Loss: 5.5284\n",
      "batch: 41632/60157............. Loss: 5.5275\n",
      "batch: 41648/60157............. Loss: 5.5315\n",
      "batch: 41664/60157............. Loss: 5.5308\n",
      "batch: 41680/60157............. Loss: 5.5271\n",
      "batch: 41696/60157............. Loss: 5.5241\n",
      "batch: 41712/60157............. Loss: 5.5280\n",
      "batch: 41728/60157............. Loss: 5.5207\n",
      "batch: 41744/60157............. Loss: 5.5288\n",
      "batch: 41760/60157............. Loss: 5.5219\n",
      "batch: 41776/60157............. Loss: 5.5285\n",
      "batch: 41792/60157............. Loss: 5.5243\n",
      "batch: 41808/60157............. Loss: 5.5294\n",
      "batch: 41824/60157............. Loss: 5.5278\n",
      "batch: 41840/60157............. Loss: 5.5248\n",
      "batch: 41856/60157............. Loss: 5.5284\n",
      "batch: 41872/60157............. Loss: 5.5314\n",
      "batch: 41888/60157............. Loss: 5.5233\n",
      "batch: 41904/60157............. Loss: 5.5238\n",
      "batch: 41920/60157............. Loss: 5.5261\n",
      "batch: 41936/60157............. Loss: 5.5261\n",
      "batch: 41952/60157............. Loss: 5.5270\n",
      "batch: 41968/60157............. Loss: 5.5241\n",
      "batch: 41984/60157............. Loss: 5.5238\n",
      "batch: 42000/60157............. Loss: 5.5269\n",
      "batch: 42016/60157............. Loss: 5.5253\n",
      "batch: 42032/60157............. Loss: 5.5263\n",
      "batch: 42048/60157............. Loss: 5.5217\n",
      "batch: 42064/60157............. Loss: 5.5230\n",
      "batch: 42080/60157............. Loss: 5.5234\n",
      "batch: 42096/60157............. Loss: 5.5288\n",
      "batch: 42112/60157............. Loss: 5.5279\n",
      "batch: 42128/60157............. Loss: 5.5232\n",
      "batch: 42144/60157............. Loss: 5.5260\n",
      "batch: 42160/60157............. Loss: 5.5277\n",
      "batch: 42176/60157............. Loss: 5.5222\n",
      "batch: 42192/60157............. Loss: 5.5343\n",
      "batch: 42208/60157............. Loss: 5.5229\n",
      "batch: 42224/60157............. Loss: 5.5270\n",
      "batch: 42240/60157............. Loss: 5.5242\n",
      "batch: 42256/60157............. Loss: 5.5271\n",
      "batch: 42272/60157............. Loss: 5.5253\n",
      "batch: 42288/60157............. Loss: 5.5288\n",
      "batch: 42304/60157............. Loss: 5.5298\n",
      "batch: 42320/60157............. Loss: 5.5269\n",
      "batch: 42336/60157............. Loss: 5.5244\n",
      "batch: 42352/60157............. Loss: 5.5201\n",
      "batch: 42368/60157............. Loss: 5.5299\n",
      "batch: 42384/60157............. Loss: 5.5251\n",
      "batch: 42400/60157............. Loss: 5.5215\n",
      "batch: 42416/60157............. Loss: 5.5200\n",
      "batch: 42432/60157............. Loss: 5.5276\n",
      "batch: 42448/60157............. Loss: 5.5281\n",
      "batch: 42464/60157............. Loss: 5.5302\n",
      "batch: 42480/60157............. Loss: 5.5290\n",
      "batch: 42496/60157............. Loss: 5.5259\n",
      "batch: 42512/60157............. Loss: 5.5287\n",
      "batch: 42528/60157............. Loss: 5.5261\n",
      "batch: 42544/60157............. Loss: 5.5275\n",
      "batch: 42560/60157............. Loss: 5.5266\n",
      "batch: 42576/60157............. Loss: 5.5261\n",
      "batch: 42592/60157............. Loss: 5.5236\n",
      "batch: 42608/60157............. Loss: 5.5166\n",
      "batch: 42624/60157............. Loss: 5.5221\n",
      "batch: 42640/60157............. Loss: 5.5219\n",
      "batch: 42656/60157............. Loss: 5.5277\n",
      "batch: 42672/60157............. Loss: 5.5291\n",
      "batch: 42688/60157............. Loss: 5.5240\n",
      "batch: 42704/60157............. Loss: 5.5272\n",
      "batch: 42720/60157............. Loss: 5.5268\n",
      "batch: 42736/60157............. Loss: 5.5249\n",
      "batch: 42752/60157............. Loss: 5.5265\n",
      "batch: 42768/60157............. Loss: 5.5253\n",
      "batch: 42784/60157............. Loss: 5.5144\n",
      "batch: 42800/60157............. Loss: 5.5189\n",
      "batch: 42816/60157............. Loss: 5.5230\n",
      "batch: 42832/60157............. Loss: 5.5235\n",
      "batch: 42848/60157............. Loss: 5.5212\n",
      "batch: 42864/60157............. Loss: 5.5268\n",
      "batch: 42880/60157............. Loss: 5.5253\n",
      "batch: 42896/60157............. Loss: 5.5270\n",
      "batch: 42912/60157............. Loss: 5.5258\n",
      "batch: 42928/60157............. Loss: 5.5222\n",
      "batch: 42944/60157............. Loss: 5.5287\n",
      "batch: 42960/60157............. Loss: 5.5225\n",
      "batch: 42976/60157............. Loss: 5.5305\n",
      "batch: 42992/60157............. Loss: 5.5263\n",
      "batch: 43008/60157............. Loss: 5.5164\n",
      "batch: 43024/60157............. Loss: 5.5284\n",
      "batch: 43040/60157............. Loss: 5.5282\n",
      "batch: 43056/60157............. Loss: 5.5269\n",
      "batch: 43072/60157............. Loss: 5.5254\n",
      "batch: 43088/60157............. Loss: 5.5212\n",
      "batch: 43104/60157............. Loss: 5.5257\n",
      "batch: 43120/60157............. Loss: 5.5283\n",
      "batch: 43136/60157............. Loss: 5.5233\n",
      "batch: 43152/60157............. Loss: 5.5323\n",
      "batch: 43168/60157............. Loss: 5.5242\n",
      "batch: 43184/60157............. Loss: 5.5295\n",
      "batch: 43200/60157............. Loss: 5.5259\n",
      "batch: 43216/60157............. Loss: 5.5240\n",
      "batch: 43232/60157............. Loss: 5.5343\n",
      "batch: 43248/60157............. Loss: 5.5232\n",
      "batch: 43264/60157............. Loss: 5.5321\n",
      "batch: 43280/60157............. Loss: 5.5207\n",
      "batch: 43296/60157............. Loss: 5.5238\n",
      "batch: 43312/60157............. Loss: 5.5203\n",
      "batch: 43328/60157............. Loss: 5.5305\n",
      "batch: 43344/60157............. Loss: 5.5289\n",
      "batch: 43360/60157............. Loss: 5.5270\n",
      "batch: 43376/60157............. Loss: 5.5275\n",
      "batch: 43392/60157............. Loss: 5.5224\n",
      "batch: 43408/60157............. Loss: 5.5275\n",
      "batch: 43424/60157............. Loss: 5.5280\n",
      "batch: 43440/60157............. Loss: 5.5248\n",
      "batch: 43456/60157............. Loss: 5.5161\n",
      "batch: 43472/60157............. Loss: 5.5214\n",
      "batch: 43488/60157............. Loss: 5.5234\n",
      "batch: 43504/60157............. Loss: 5.5314\n",
      "batch: 43520/60157............. Loss: 5.5279\n",
      "batch: 43536/60157............. Loss: 5.5261\n",
      "batch: 43552/60157............. Loss: 5.5222\n",
      "batch: 43568/60157............. Loss: 5.5298\n",
      "batch: 43584/60157............. Loss: 5.5296\n",
      "batch: 43600/60157............. Loss: 5.5327\n",
      "batch: 43616/60157............. Loss: 5.5307\n",
      "batch: 43632/60157............. Loss: 5.5251\n",
      "batch: 43648/60157............. Loss: 5.5277\n",
      "batch: 43664/60157............. Loss: 5.5197\n",
      "batch: 43680/60157............. Loss: 5.5296\n",
      "batch: 43696/60157............. Loss: 5.5204\n",
      "batch: 43712/60157............. Loss: 5.5256\n",
      "batch: 43728/60157............. Loss: 5.5249\n",
      "batch: 43744/60157............. Loss: 5.5231\n",
      "batch: 43760/60157............. Loss: 5.5233\n",
      "batch: 43776/60157............. Loss: 5.5304\n",
      "batch: 43792/60157............. Loss: 5.5225\n",
      "batch: 43808/60157............. Loss: 5.5242\n",
      "batch: 43824/60157............. Loss: 5.5252\n",
      "batch: 43840/60157............. Loss: 5.5262\n",
      "batch: 43856/60157............. Loss: 5.5260\n",
      "batch: 43872/60157............. Loss: 5.5218\n",
      "batch: 43888/60157............. Loss: 5.5247\n",
      "batch: 43904/60157............. Loss: 5.5269\n",
      "batch: 43920/60157............. Loss: 5.5290\n",
      "batch: 43936/60157............. Loss: 5.5231\n",
      "batch: 43952/60157............. Loss: 5.5280\n",
      "batch: 43968/60157............. Loss: 5.5265\n",
      "batch: 43984/60157............. Loss: 5.5248\n",
      "batch: 44000/60157............. Loss: 5.5231\n",
      "batch: 44016/60157............. Loss: 5.5284\n",
      "batch: 44032/60157............. Loss: 5.5302\n",
      "batch: 44048/60157............. Loss: 5.5267\n",
      "batch: 44064/60157............. Loss: 5.5281\n",
      "batch: 44080/60157............. Loss: 5.5275\n",
      "batch: 44096/60157............. Loss: 5.5253\n",
      "batch: 44112/60157............. Loss: 5.5228\n",
      "batch: 44128/60157............. Loss: 5.5275\n",
      "batch: 44144/60157............. Loss: 5.5267\n",
      "batch: 44160/60157............. Loss: 5.5301\n",
      "batch: 44176/60157............. Loss: 5.5308\n",
      "batch: 44192/60157............. Loss: 5.5237\n",
      "batch: 44208/60157............. Loss: 5.5272\n",
      "batch: 44224/60157............. Loss: 5.5335\n",
      "batch: 44240/60157............. Loss: 5.5186\n",
      "batch: 44256/60157............. Loss: 5.5302\n",
      "batch: 44272/60157............. Loss: 5.5255\n",
      "batch: 44288/60157............. Loss: 5.5298\n",
      "batch: 44304/60157............. Loss: 5.5288\n",
      "batch: 44320/60157............. Loss: 5.5304\n",
      "batch: 44336/60157............. Loss: 5.5263\n",
      "batch: 44352/60157............. Loss: 5.5278\n",
      "batch: 44368/60157............. Loss: 5.5242\n",
      "batch: 44384/60157............. Loss: 5.5254\n",
      "batch: 44400/60157............. Loss: 5.5227\n",
      "batch: 44416/60157............. Loss: 5.5271\n",
      "batch: 44432/60157............. Loss: 5.5267\n",
      "batch: 44448/60157............. Loss: 5.5262\n",
      "batch: 44464/60157............. Loss: 5.5256\n",
      "batch: 44480/60157............. Loss: 5.5295\n",
      "batch: 44496/60157............. Loss: 5.5265\n",
      "batch: 44512/60157............. Loss: 5.5259\n",
      "batch: 44528/60157............. Loss: 5.5296\n",
      "batch: 44544/60157............. Loss: 5.5281\n",
      "batch: 44560/60157............. Loss: 5.5243\n",
      "batch: 44576/60157............. Loss: 5.5226\n",
      "batch: 44592/60157............. Loss: 5.5296\n",
      "batch: 44608/60157............. Loss: 5.5323\n",
      "batch: 44624/60157............. Loss: 5.5282\n",
      "batch: 44640/60157............. Loss: 5.5261\n",
      "batch: 44656/60157............. Loss: 5.5262\n",
      "batch: 44672/60157............. Loss: 5.5171\n",
      "batch: 44688/60157............. Loss: 5.5252\n",
      "batch: 44704/60157............. Loss: 5.5282\n",
      "batch: 44720/60157............. Loss: 5.5314\n",
      "batch: 44736/60157............. Loss: 5.5274\n",
      "batch: 44752/60157............. Loss: 5.5277\n",
      "batch: 44768/60157............. Loss: 5.5251\n",
      "batch: 44784/60157............. Loss: 5.5274\n",
      "batch: 44800/60157............. Loss: 5.5244\n",
      "batch: 44816/60157............. Loss: 5.5249\n",
      "batch: 44832/60157............. Loss: 5.5282\n",
      "batch: 44848/60157............. Loss: 5.5259\n",
      "batch: 44864/60157............. Loss: 5.5261\n",
      "batch: 44880/60157............. Loss: 5.5255\n",
      "batch: 44896/60157............. Loss: 5.5310\n",
      "batch: 44912/60157............. Loss: 5.5229\n",
      "batch: 44928/60157............. Loss: 5.5256\n",
      "batch: 44944/60157............. Loss: 5.5228\n",
      "batch: 44960/60157............. Loss: 5.5262\n",
      "batch: 44976/60157............. Loss: 5.5266\n",
      "batch: 44992/60157............. Loss: 5.5286\n",
      "batch: 45008/60157............. Loss: 5.5191\n",
      "batch: 45024/60157............. Loss: 5.5209\n",
      "batch: 45040/60157............. Loss: 5.5228\n",
      "batch: 45056/60157............. Loss: 5.5295\n",
      "batch: 45072/60157............. Loss: 5.5286\n",
      "batch: 45088/60157............. Loss: 5.5250\n",
      "batch: 45104/60157............. Loss: 5.5280\n",
      "batch: 45120/60157............. Loss: 5.5277\n",
      "batch: 45136/60157............. Loss: 5.5234\n",
      "batch: 45152/60157............. Loss: 5.5245\n",
      "batch: 45168/60157............. Loss: 5.5232\n",
      "batch: 45184/60157............. Loss: 5.5259\n",
      "batch: 45200/60157............. Loss: 5.5260\n",
      "batch: 45216/60157............. Loss: 5.5236\n",
      "batch: 45232/60157............. Loss: 5.5246\n",
      "batch: 45248/60157............. Loss: 5.5223\n",
      "batch: 45264/60157............. Loss: 5.5200\n",
      "batch: 45280/60157............. Loss: 5.5299\n",
      "batch: 45296/60157............. Loss: 5.5274\n",
      "batch: 45312/60157............. Loss: 5.5212\n",
      "batch: 45328/60157............. Loss: 5.5184\n",
      "batch: 45344/60157............. Loss: 5.5256\n",
      "batch: 45360/60157............. Loss: 5.5254\n",
      "batch: 45376/60157............. Loss: 5.5265\n",
      "batch: 45392/60157............. Loss: 5.5263\n",
      "batch: 45408/60157............. Loss: 5.5220\n",
      "batch: 45424/60157............. Loss: 5.5250\n",
      "batch: 45440/60157............. Loss: 5.5242\n",
      "batch: 45456/60157............. Loss: 5.5250\n",
      "batch: 45472/60157............. Loss: 5.5172\n",
      "batch: 45488/60157............. Loss: 5.5230\n",
      "batch: 45504/60157............. Loss: 5.5293\n",
      "batch: 45520/60157............. Loss: 5.5267\n",
      "batch: 45536/60157............. Loss: 5.5152\n",
      "batch: 45552/60157............. Loss: 5.5151\n",
      "batch: 45568/60157............. Loss: 5.5243\n",
      "batch: 45584/60157............. Loss: 5.5264\n",
      "batch: 45600/60157............. Loss: 5.5230\n",
      "batch: 45616/60157............. Loss: 5.5146\n",
      "batch: 45632/60157............. Loss: 5.5192\n",
      "batch: 45648/60157............. Loss: 5.5254\n",
      "batch: 45664/60157............. Loss: 5.5265\n",
      "batch: 45680/60157............. Loss: 5.5256\n",
      "batch: 45696/60157............. Loss: 5.5242\n",
      "batch: 45712/60157............. Loss: 5.5272\n",
      "batch: 45728/60157............. Loss: 5.5253\n",
      "batch: 45744/60157............. Loss: 5.5254\n",
      "batch: 45760/60157............. Loss: 5.5161\n",
      "batch: 45776/60157............. Loss: 5.5275\n",
      "batch: 45792/60157............. Loss: 5.5198\n",
      "batch: 45808/60157............. Loss: 5.5297\n",
      "batch: 45824/60157............. Loss: 5.5304\n",
      "batch: 45840/60157............. Loss: 5.5282\n",
      "batch: 45856/60157............. Loss: 5.5260\n",
      "batch: 45872/60157............. Loss: 5.5257\n",
      "batch: 45888/60157............. Loss: 5.5253\n",
      "batch: 45904/60157............. Loss: 5.5197\n",
      "batch: 45920/60157............. Loss: 5.5275\n",
      "batch: 45936/60157............. Loss: 5.5275\n",
      "batch: 45952/60157............. Loss: 5.5287\n",
      "batch: 45968/60157............. Loss: 5.5226\n",
      "batch: 45984/60157............. Loss: 5.5296\n",
      "batch: 46000/60157............. Loss: 5.5275\n",
      "batch: 46016/60157............. Loss: 5.5281\n",
      "batch: 46032/60157............. Loss: 5.5229\n",
      "batch: 46048/60157............. Loss: 5.5230\n",
      "batch: 46064/60157............. Loss: 5.5258\n",
      "batch: 46080/60157............. Loss: 5.5210\n",
      "batch: 46096/60157............. Loss: 5.5284\n",
      "batch: 46112/60157............. Loss: 5.5275\n",
      "batch: 46128/60157............. Loss: 5.5232\n",
      "batch: 46144/60157............. Loss: 5.5275\n",
      "batch: 46160/60157............. Loss: 5.5227\n",
      "batch: 46176/60157............. Loss: 5.5273\n",
      "batch: 46192/60157............. Loss: 5.5281\n",
      "batch: 46208/60157............. Loss: 5.5243\n",
      "batch: 46224/60157............. Loss: 5.5253\n",
      "batch: 46240/60157............. Loss: 5.5244\n",
      "batch: 46256/60157............. Loss: 5.5259\n",
      "batch: 46272/60157............. Loss: 5.5271\n",
      "batch: 46288/60157............. Loss: 5.5259\n",
      "batch: 46304/60157............. Loss: 5.5277\n",
      "batch: 46320/60157............. Loss: 5.5303\n",
      "batch: 46336/60157............. Loss: 5.5289\n",
      "batch: 46352/60157............. Loss: 5.5257\n",
      "batch: 46368/60157............. Loss: 5.5259\n",
      "batch: 46384/60157............. Loss: 5.5239\n",
      "batch: 46400/60157............. Loss: 5.5313\n",
      "batch: 46416/60157............. Loss: 5.5238\n",
      "batch: 46432/60157............. Loss: 5.5268\n",
      "batch: 46448/60157............. Loss: 5.5285\n",
      "batch: 46464/60157............. Loss: 5.5188\n",
      "batch: 46480/60157............. Loss: 5.5296\n",
      "batch: 46496/60157............. Loss: 5.5261\n",
      "batch: 46512/60157............. Loss: 5.5297\n",
      "batch: 46528/60157............. Loss: 5.5299\n",
      "batch: 46544/60157............. Loss: 5.5294\n",
      "batch: 46560/60157............. Loss: 5.5269\n",
      "batch: 46576/60157............. Loss: 5.5248\n",
      "batch: 46592/60157............. Loss: 5.5251\n",
      "batch: 46608/60157............. Loss: 5.5241\n",
      "batch: 46624/60157............. Loss: 5.5235\n",
      "batch: 46640/60157............. Loss: 5.5295\n",
      "batch: 46656/60157............. Loss: 5.5234\n",
      "batch: 46672/60157............. Loss: 5.5302\n",
      "batch: 46688/60157............. Loss: 5.5232\n",
      "batch: 46704/60157............. Loss: 5.5241\n",
      "batch: 46720/60157............. Loss: 5.5265\n",
      "batch: 46736/60157............. Loss: 5.5279\n",
      "batch: 46752/60157............. Loss: 5.5233\n",
      "batch: 46768/60157............. Loss: 5.5275\n",
      "batch: 46784/60157............. Loss: 5.5286\n",
      "batch: 46800/60157............. Loss: 5.5228\n",
      "batch: 46816/60157............. Loss: 5.5220\n",
      "batch: 46832/60157............. Loss: 5.5323\n",
      "batch: 46848/60157............. Loss: 5.5275\n",
      "batch: 46864/60157............. Loss: 5.5249\n",
      "batch: 46880/60157............. Loss: 5.5297\n",
      "batch: 46896/60157............. Loss: 5.5101\n",
      "batch: 46912/60157............. Loss: 5.5273\n",
      "batch: 46928/60157............. Loss: 5.5287\n",
      "batch: 46944/60157............. Loss: 5.5290\n",
      "batch: 46960/60157............. Loss: 5.5228\n",
      "batch: 46976/60157............. Loss: 5.5305\n",
      "batch: 46992/60157............. Loss: 5.5249\n",
      "batch: 47008/60157............. Loss: 5.5284\n",
      "batch: 47024/60157............. Loss: 5.5254\n",
      "batch: 47040/60157............. Loss: 5.5250\n",
      "batch: 47056/60157............. Loss: 5.5273\n",
      "batch: 47072/60157............. Loss: 5.5285\n",
      "batch: 47088/60157............. Loss: 5.5260\n",
      "batch: 47104/60157............. Loss: 5.5251\n",
      "batch: 47120/60157............. Loss: 5.5234\n",
      "batch: 47136/60157............. Loss: 5.5249\n",
      "batch: 47152/60157............. Loss: 5.5280\n",
      "batch: 47168/60157............. Loss: 5.5224\n",
      "batch: 47184/60157............. Loss: 5.5293\n",
      "batch: 47200/60157............. Loss: 5.5243\n",
      "batch: 47216/60157............. Loss: 5.5214\n",
      "batch: 47232/60157............. Loss: 5.5210\n",
      "batch: 47248/60157............. Loss: 5.5260\n",
      "batch: 47264/60157............. Loss: 5.5245\n",
      "batch: 47280/60157............. Loss: 5.5254\n",
      "batch: 47296/60157............. Loss: 5.5235\n",
      "batch: 47312/60157............. Loss: 5.5229\n",
      "batch: 47328/60157............. Loss: 5.5274\n",
      "batch: 47344/60157............. Loss: 5.5234\n",
      "batch: 47360/60157............. Loss: 5.5286\n",
      "batch: 47376/60157............. Loss: 5.5270\n",
      "batch: 47392/60157............. Loss: 5.5204\n",
      "batch: 47408/60157............. Loss: 5.5265\n",
      "batch: 47424/60157............. Loss: 5.5262\n",
      "batch: 47440/60157............. Loss: 5.5303\n",
      "batch: 47456/60157............. Loss: 5.5210\n",
      "batch: 47472/60157............. Loss: 5.5228\n",
      "batch: 47488/60157............. Loss: 5.5233\n",
      "batch: 47504/60157............. Loss: 5.5263\n",
      "batch: 47520/60157............. Loss: 5.5225\n",
      "batch: 47536/60157............. Loss: 5.5246\n",
      "batch: 47552/60157............. Loss: 5.5272\n",
      "batch: 47568/60157............. Loss: 5.5223\n",
      "batch: 47584/60157............. Loss: 5.5215\n",
      "batch: 47600/60157............. Loss: 5.5267\n",
      "batch: 47616/60157............. Loss: 5.5127\n",
      "batch: 47632/60157............. Loss: 5.5267\n",
      "batch: 47648/60157............. Loss: 5.5265\n",
      "batch: 47664/60157............. Loss: 5.5263\n",
      "batch: 47680/60157............. Loss: 5.5284\n",
      "batch: 47696/60157............. Loss: 5.5296\n",
      "batch: 47712/60157............. Loss: 5.5295\n",
      "batch: 47728/60157............. Loss: 5.5293\n",
      "batch: 47744/60157............. Loss: 5.5258\n",
      "batch: 47760/60157............. Loss: 5.5233\n",
      "batch: 47776/60157............. Loss: 5.5271\n",
      "batch: 47792/60157............. Loss: 5.5255\n",
      "batch: 47808/60157............. Loss: 5.5237\n",
      "batch: 47824/60157............. Loss: 5.5275\n",
      "batch: 47840/60157............. Loss: 5.5255\n",
      "batch: 47856/60157............. Loss: 5.5249\n",
      "batch: 47872/60157............. Loss: 5.5209\n",
      "batch: 47888/60157............. Loss: 5.5227\n",
      "batch: 47904/60157............. Loss: 5.5251\n",
      "batch: 47920/60157............. Loss: 5.5272\n",
      "batch: 47936/60157............. Loss: 5.5277\n",
      "batch: 47952/60157............. Loss: 5.5280\n",
      "batch: 47968/60157............. Loss: 5.5265\n",
      "batch: 47984/60157............. Loss: 5.5294\n",
      "batch: 48000/60157............. Loss: 5.5264\n",
      "batch: 48016/60157............. Loss: 5.5241\n",
      "batch: 48032/60157............. Loss: 5.5213\n",
      "batch: 48048/60157............. Loss: 5.5350\n",
      "batch: 48064/60157............. Loss: 5.5252\n",
      "batch: 48080/60157............. Loss: 5.5269\n",
      "batch: 48096/60157............. Loss: 5.5245\n",
      "batch: 48112/60157............. Loss: 5.5220\n",
      "batch: 48128/60157............. Loss: 5.5328\n",
      "batch: 48144/60157............. Loss: 5.5280\n",
      "batch: 48160/60157............. Loss: 5.5236\n",
      "batch: 48176/60157............. Loss: 5.5288\n",
      "batch: 48192/60157............. Loss: 5.5282\n",
      "batch: 48208/60157............. Loss: 5.5248\n",
      "batch: 48224/60157............. Loss: 5.5216\n",
      "batch: 48240/60157............. Loss: 5.5271\n",
      "batch: 48256/60157............. Loss: 5.5278\n",
      "batch: 48272/60157............. Loss: 5.5279\n",
      "batch: 48288/60157............. Loss: 5.5255\n",
      "batch: 48304/60157............. Loss: 5.5290\n",
      "batch: 48320/60157............. Loss: 5.5285\n",
      "batch: 48336/60157............. Loss: 5.5241\n",
      "batch: 48352/60157............. Loss: 5.5281\n",
      "batch: 48368/60157............. Loss: 5.5228\n",
      "batch: 48384/60157............. Loss: 5.5287\n",
      "batch: 48400/60157............. Loss: 5.5300\n",
      "batch: 48416/60157............. Loss: 5.5246\n",
      "batch: 48432/60157............. Loss: 5.5278\n",
      "batch: 48448/60157............. Loss: 5.5302\n",
      "batch: 48464/60157............. Loss: 5.5258\n",
      "batch: 48480/60157............. Loss: 5.5220\n",
      "batch: 48496/60157............. Loss: 5.5303\n",
      "batch: 48512/60157............. Loss: 5.5258\n",
      "batch: 48528/60157............. Loss: 5.5221\n",
      "batch: 48544/60157............. Loss: 5.5306\n",
      "batch: 48560/60157............. Loss: 5.5268\n",
      "batch: 48576/60157............. Loss: 5.5281\n",
      "batch: 48592/60157............. Loss: 5.5279\n",
      "batch: 48608/60157............. Loss: 5.5271\n",
      "batch: 48624/60157............. Loss: 5.5286\n",
      "batch: 48640/60157............. Loss: 5.5245\n",
      "batch: 48656/60157............. Loss: 5.5254\n",
      "batch: 48672/60157............. Loss: 5.5226\n",
      "batch: 48688/60157............. Loss: 5.5220\n",
      "batch: 48704/60157............. Loss: 5.5226\n",
      "batch: 48720/60157............. Loss: 5.5263\n",
      "batch: 48736/60157............. Loss: 5.5221\n",
      "batch: 48752/60157............. Loss: 5.5268\n",
      "batch: 48768/60157............. Loss: 5.5295\n",
      "batch: 48784/60157............. Loss: 5.5273\n",
      "batch: 48800/60157............. Loss: 5.5243\n",
      "batch: 48816/60157............. Loss: 5.5274\n",
      "batch: 48832/60157............. Loss: 5.5216\n",
      "batch: 48848/60157............. Loss: 5.5223\n",
      "batch: 48864/60157............. Loss: 5.5270\n",
      "batch: 48880/60157............. Loss: 5.5240\n",
      "batch: 48896/60157............. Loss: 5.5323\n",
      "batch: 48912/60157............. Loss: 5.5214\n",
      "batch: 48928/60157............. Loss: 5.5281\n",
      "batch: 48944/60157............. Loss: 5.5296\n",
      "batch: 48960/60157............. Loss: 5.5251\n",
      "batch: 48976/60157............. Loss: 5.5261\n",
      "batch: 48992/60157............. Loss: 5.5236\n",
      "batch: 49008/60157............. Loss: 5.5263\n",
      "batch: 49024/60157............. Loss: 5.5252\n",
      "batch: 49040/60157............. Loss: 5.5253\n",
      "batch: 49056/60157............. Loss: 5.5233\n",
      "batch: 49072/60157............. Loss: 5.5255\n",
      "batch: 49088/60157............. Loss: 5.5284\n",
      "batch: 49104/60157............. Loss: 5.5198\n",
      "batch: 49120/60157............. Loss: 5.5256\n",
      "batch: 49136/60157............. Loss: 5.5263\n",
      "batch: 49152/60157............. Loss: 5.5271\n",
      "batch: 49168/60157............. Loss: 5.5242\n",
      "batch: 49184/60157............. Loss: 5.5246\n",
      "batch: 49200/60157............. Loss: 5.5284\n",
      "batch: 49216/60157............. Loss: 5.5286\n",
      "batch: 49232/60157............. Loss: 5.5235\n",
      "batch: 49248/60157............. Loss: 5.5297\n",
      "batch: 49264/60157............. Loss: 5.5260\n",
      "batch: 49280/60157............. Loss: 5.5271\n",
      "batch: 49296/60157............. Loss: 5.5285\n",
      "batch: 49312/60157............. Loss: 5.5281\n",
      "batch: 49328/60157............. Loss: 5.5204\n",
      "batch: 49344/60157............. Loss: 5.5203\n",
      "batch: 49360/60157............. Loss: 5.5248\n",
      "batch: 49376/60157............. Loss: 5.5182\n",
      "batch: 49392/60157............. Loss: 5.5240\n",
      "batch: 49408/60157............. Loss: 5.5255\n",
      "batch: 49424/60157............. Loss: 5.5251\n",
      "batch: 49440/60157............. Loss: 5.5280\n",
      "batch: 49456/60157............. Loss: 5.5222\n",
      "batch: 49472/60157............. Loss: 5.5315\n",
      "batch: 49488/60157............. Loss: 5.5228\n",
      "batch: 49504/60157............. Loss: 5.5246\n",
      "batch: 49520/60157............. Loss: 5.5258\n",
      "batch: 49536/60157............. Loss: 5.5218\n",
      "batch: 49552/60157............. Loss: 5.5248\n",
      "batch: 49568/60157............. Loss: 5.5272\n",
      "batch: 49584/60157............. Loss: 5.5250\n",
      "batch: 49600/60157............. Loss: 5.5288\n",
      "batch: 49616/60157............. Loss: 5.5210\n",
      "batch: 49632/60157............. Loss: 5.5379\n",
      "batch: 49648/60157............. Loss: 5.5254\n",
      "batch: 49664/60157............. Loss: 5.5234\n",
      "batch: 49680/60157............. Loss: 5.5273\n",
      "batch: 49696/60157............. Loss: 5.5203\n",
      "batch: 49712/60157............. Loss: 5.5270\n",
      "batch: 49728/60157............. Loss: 5.5161\n",
      "batch: 49744/60157............. Loss: 5.5271\n",
      "batch: 49760/60157............. Loss: 5.5237\n",
      "batch: 49776/60157............. Loss: 5.5212\n",
      "batch: 49792/60157............. Loss: 5.5233\n",
      "batch: 49808/60157............. Loss: 5.5272\n",
      "batch: 49824/60157............. Loss: 5.5264\n",
      "batch: 49840/60157............. Loss: 5.5248\n",
      "batch: 49856/60157............. Loss: 5.5251\n",
      "batch: 49872/60157............. Loss: 5.5257\n",
      "batch: 49888/60157............. Loss: 5.5214\n",
      "batch: 49904/60157............. Loss: 5.5273\n",
      "batch: 49920/60157............. Loss: 5.5244\n",
      "batch: 49936/60157............. Loss: 5.5239\n",
      "batch: 49952/60157............. Loss: 5.5215\n",
      "batch: 49968/60157............. Loss: 5.5256\n",
      "batch: 49984/60157............. Loss: 5.5275\n",
      "batch: 50000/60157............. Loss: 5.5243\n",
      "batch: 50016/60157............. Loss: 5.5252\n",
      "batch: 50032/60157............. Loss: 5.5291\n",
      "batch: 50048/60157............. Loss: 5.5259\n",
      "batch: 50064/60157............. Loss: 5.5221\n",
      "batch: 50080/60157............. Loss: 5.5256\n",
      "batch: 50096/60157............. Loss: 5.5237\n",
      "batch: 50112/60157............. Loss: 5.5263\n",
      "batch: 50128/60157............. Loss: 5.5273\n",
      "batch: 50144/60157............. Loss: 5.5270\n",
      "batch: 50160/60157............. Loss: 5.5214\n",
      "batch: 50176/60157............. Loss: 5.5236\n",
      "batch: 50192/60157............. Loss: 5.5250\n",
      "batch: 50208/60157............. Loss: 5.5284\n",
      "batch: 50224/60157............. Loss: 5.5256\n",
      "batch: 50240/60157............. Loss: 5.5255\n",
      "batch: 50256/60157............. Loss: 5.5232\n",
      "batch: 50272/60157............. Loss: 5.5252\n",
      "batch: 50288/60157............. Loss: 5.5304\n",
      "batch: 50304/60157............. Loss: 5.5197\n",
      "batch: 50320/60157............. Loss: 5.5287\n",
      "batch: 50336/60157............. Loss: 5.5196\n",
      "batch: 50352/60157............. Loss: 5.5245\n",
      "batch: 50368/60157............. Loss: 5.5270\n",
      "batch: 50384/60157............. Loss: 5.5261\n",
      "batch: 50400/60157............. Loss: 5.5272\n",
      "batch: 50416/60157............. Loss: 5.5286\n",
      "batch: 50432/60157............. Loss: 5.5262\n",
      "batch: 50448/60157............. Loss: 5.5239\n",
      "batch: 50464/60157............. Loss: 5.5222\n",
      "batch: 50480/60157............. Loss: 5.5265\n",
      "batch: 50496/60157............. Loss: 5.5285\n",
      "batch: 50512/60157............. Loss: 5.5285\n",
      "batch: 50528/60157............. Loss: 5.5192\n",
      "batch: 50544/60157............. Loss: 5.5258\n",
      "batch: 50560/60157............. Loss: 5.5219\n",
      "batch: 50576/60157............. Loss: 5.5260\n",
      "batch: 50592/60157............. Loss: 5.5271\n",
      "batch: 50608/60157............. Loss: 5.5338\n",
      "batch: 50624/60157............. Loss: 5.5237\n",
      "batch: 50640/60157............. Loss: 5.5305\n",
      "batch: 50656/60157............. Loss: 5.5317\n",
      "batch: 50672/60157............. Loss: 5.5275\n",
      "batch: 50688/60157............. Loss: 5.5226\n",
      "batch: 50704/60157............. Loss: 5.5260\n",
      "batch: 50720/60157............. Loss: 5.5266\n",
      "batch: 50736/60157............. Loss: 5.5229\n",
      "batch: 50752/60157............. Loss: 5.5269\n",
      "batch: 50768/60157............. Loss: 5.5253\n",
      "batch: 50784/60157............. Loss: 5.5278\n",
      "batch: 50800/60157............. Loss: 5.5277\n",
      "batch: 50816/60157............. Loss: 5.5290\n",
      "batch: 50832/60157............. Loss: 5.5261\n",
      "batch: 50848/60157............. Loss: 5.5248\n",
      "batch: 50864/60157............. Loss: 5.5231\n",
      "batch: 50880/60157............. Loss: 5.5238\n",
      "batch: 50896/60157............. Loss: 5.5240\n",
      "batch: 50912/60157............. Loss: 5.5184\n",
      "batch: 50928/60157............. Loss: 5.5296\n",
      "batch: 50944/60157............. Loss: 5.5273\n",
      "batch: 50960/60157............. Loss: 5.5287\n",
      "batch: 50976/60157............. Loss: 5.5243\n",
      "batch: 50992/60157............. Loss: 5.5320\n",
      "batch: 51008/60157............. Loss: 5.5215\n",
      "batch: 51024/60157............. Loss: 5.5231\n",
      "batch: 51040/60157............. Loss: 5.5241\n",
      "batch: 51056/60157............. Loss: 5.5327\n",
      "batch: 51072/60157............. Loss: 5.5326\n",
      "batch: 51088/60157............. Loss: 5.5235\n",
      "batch: 51104/60157............. Loss: 5.5243\n",
      "batch: 51120/60157............. Loss: 5.5245\n",
      "batch: 51136/60157............. Loss: 5.5250\n",
      "batch: 51152/60157............. Loss: 5.5244\n",
      "batch: 51168/60157............. Loss: 5.5243\n",
      "batch: 51184/60157............. Loss: 5.5279\n",
      "batch: 51200/60157............. Loss: 5.5218\n",
      "batch: 51216/60157............. Loss: 5.5238\n",
      "batch: 51232/60157............. Loss: 5.5208\n",
      "batch: 51248/60157............. Loss: 5.5190\n",
      "batch: 51264/60157............. Loss: 5.5272\n",
      "batch: 51280/60157............. Loss: 5.5308\n",
      "batch: 51296/60157............. Loss: 5.5287\n",
      "batch: 51312/60157............. Loss: 5.5239\n",
      "batch: 51328/60157............. Loss: 5.5272\n",
      "batch: 51344/60157............. Loss: 5.5282\n",
      "batch: 51360/60157............. Loss: 5.5232\n",
      "batch: 51376/60157............. Loss: 5.5248\n",
      "batch: 51392/60157............. Loss: 5.5252\n",
      "batch: 51408/60157............. Loss: 5.5184\n",
      "batch: 51424/60157............. Loss: 5.5208\n",
      "batch: 51440/60157............. Loss: 5.5303\n",
      "batch: 51456/60157............. Loss: 5.5224\n",
      "batch: 51472/60157............. Loss: 5.5256\n",
      "batch: 51488/60157............. Loss: 5.5304\n",
      "batch: 51504/60157............. Loss: 5.5288\n",
      "batch: 51520/60157............. Loss: 5.5211\n",
      "batch: 51536/60157............. Loss: 5.5223\n",
      "batch: 51552/60157............. Loss: 5.5230\n",
      "batch: 51568/60157............. Loss: 5.5260\n",
      "batch: 51584/60157............. Loss: 5.5273\n",
      "batch: 51600/60157............. Loss: 5.5239\n",
      "batch: 51616/60157............. Loss: 5.5258\n",
      "batch: 51632/60157............. Loss: 5.5229\n",
      "batch: 51648/60157............. Loss: 5.5229\n",
      "batch: 51664/60157............. Loss: 5.5219\n",
      "batch: 51680/60157............. Loss: 5.5278\n",
      "batch: 51696/60157............. Loss: 5.5287\n",
      "batch: 51712/60157............. Loss: 5.5242\n",
      "batch: 51728/60157............. Loss: 5.5273\n",
      "batch: 51744/60157............. Loss: 5.5197\n",
      "batch: 51760/60157............. Loss: 5.5241\n",
      "batch: 51776/60157............. Loss: 5.5199\n",
      "batch: 51792/60157............. Loss: 5.5248\n",
      "batch: 51808/60157............. Loss: 5.5260\n",
      "batch: 51824/60157............. Loss: 5.5259\n",
      "batch: 51840/60157............. Loss: 5.5227\n",
      "batch: 51856/60157............. Loss: 5.5273\n",
      "batch: 51872/60157............. Loss: 5.5277\n",
      "batch: 51888/60157............. Loss: 5.5251\n",
      "batch: 51904/60157............. Loss: 5.5251\n",
      "batch: 51920/60157............. Loss: 5.5265\n",
      "batch: 51936/60157............. Loss: 5.5242\n",
      "batch: 51952/60157............. Loss: 5.5282\n",
      "batch: 51968/60157............. Loss: 5.5272\n",
      "batch: 51984/60157............. Loss: 5.5257\n",
      "batch: 52000/60157............. Loss: 5.5172\n",
      "batch: 52016/60157............. Loss: 5.5292\n",
      "batch: 52032/60157............. Loss: 5.5219\n",
      "batch: 52048/60157............. Loss: 5.5178\n",
      "batch: 52064/60157............. Loss: 5.5244\n",
      "batch: 52080/60157............. Loss: 5.5300\n",
      "batch: 52096/60157............. Loss: 5.5297\n",
      "batch: 52112/60157............. Loss: 5.5247\n",
      "batch: 52128/60157............. Loss: 5.5267\n",
      "batch: 52144/60157............. Loss: 5.5187\n",
      "batch: 52160/60157............. Loss: 5.5239\n",
      "batch: 52176/60157............. Loss: 5.5241\n",
      "batch: 52192/60157............. Loss: 5.5236\n",
      "batch: 52208/60157............. Loss: 5.5267\n",
      "batch: 52224/60157............. Loss: 5.5238\n",
      "batch: 52240/60157............. Loss: 5.5303\n",
      "batch: 52256/60157............. Loss: 5.5182\n",
      "batch: 52272/60157............. Loss: 5.5224\n",
      "batch: 52288/60157............. Loss: 5.5224\n",
      "batch: 52304/60157............. Loss: 5.5203\n",
      "batch: 52320/60157............. Loss: 5.5220\n",
      "batch: 52336/60157............. Loss: 5.5138\n",
      "batch: 52352/60157............. Loss: 5.5258\n",
      "batch: 52368/60157............. Loss: 5.5200\n",
      "batch: 52384/60157............. Loss: 5.5252\n",
      "batch: 52400/60157............. Loss: 5.5197\n",
      "batch: 52416/60157............. Loss: 5.5257\n",
      "batch: 52432/60157............. Loss: 5.5204\n",
      "batch: 52448/60157............. Loss: 5.5219\n",
      "batch: 52464/60157............. Loss: 5.5221\n",
      "batch: 52480/60157............. Loss: 5.5227\n",
      "batch: 52496/60157............. Loss: 5.5271\n",
      "batch: 52512/60157............. Loss: 5.5255\n",
      "batch: 52528/60157............. Loss: 5.5202\n",
      "batch: 52544/60157............. Loss: 5.5280\n",
      "batch: 52560/60157............. Loss: 5.5261\n",
      "batch: 52576/60157............. Loss: 5.5206\n",
      "batch: 52592/60157............. Loss: 5.5284\n",
      "batch: 52608/60157............. Loss: 5.5267\n",
      "batch: 52624/60157............. Loss: 5.5219\n",
      "batch: 52640/60157............. Loss: 5.5264\n",
      "batch: 52656/60157............. Loss: 5.5206\n",
      "batch: 52672/60157............. Loss: 5.5207\n",
      "batch: 52688/60157............. Loss: 5.5288\n",
      "batch: 52704/60157............. Loss: 5.5237\n",
      "batch: 52720/60157............. Loss: 5.5218\n",
      "batch: 52736/60157............. Loss: 5.5275\n",
      "batch: 52752/60157............. Loss: 5.5268\n",
      "batch: 52768/60157............. Loss: 5.5195\n",
      "batch: 52784/60157............. Loss: 5.5241\n",
      "batch: 52800/60157............. Loss: 5.5209\n",
      "batch: 52816/60157............. Loss: 5.5213\n",
      "batch: 52832/60157............. Loss: 5.5211\n",
      "batch: 52848/60157............. Loss: 5.5194\n",
      "batch: 52864/60157............. Loss: 5.5203\n",
      "batch: 52880/60157............. Loss: 5.5225\n",
      "batch: 52896/60157............. Loss: 5.5218\n",
      "batch: 52912/60157............. Loss: 5.5193\n",
      "batch: 52928/60157............. Loss: 5.5263\n",
      "batch: 52944/60157............. Loss: 5.5242\n",
      "batch: 52960/60157............. Loss: 5.5213\n",
      "batch: 52976/60157............. Loss: 5.5274\n",
      "batch: 52992/60157............. Loss: 5.5267\n",
      "batch: 53008/60157............. Loss: 5.5161\n",
      "batch: 53024/60157............. Loss: 5.5222\n",
      "batch: 53040/60157............. Loss: 5.5214\n",
      "batch: 53056/60157............. Loss: 5.5283\n",
      "batch: 53072/60157............. Loss: 5.5190\n",
      "batch: 53088/60157............. Loss: 5.5306\n",
      "batch: 53104/60157............. Loss: 5.5256\n",
      "batch: 53120/60157............. Loss: 5.5204\n",
      "batch: 53136/60157............. Loss: 5.5239\n",
      "batch: 53152/60157............. Loss: 5.5246\n",
      "batch: 53168/60157............. Loss: 5.5219\n",
      "batch: 53184/60157............. Loss: 5.5199\n",
      "batch: 53200/60157............. Loss: 5.5232\n",
      "batch: 53216/60157............. Loss: 5.5220\n",
      "batch: 53232/60157............. Loss: 5.5231\n",
      "batch: 53248/60157............. Loss: 5.5253\n",
      "batch: 53264/60157............. Loss: 5.5238\n",
      "batch: 53280/60157............. Loss: 5.5220\n",
      "batch: 53296/60157............. Loss: 5.5191\n",
      "batch: 53312/60157............. Loss: 5.5268\n",
      "batch: 53328/60157............. Loss: 5.5228\n",
      "batch: 53344/60157............. Loss: 5.5239\n",
      "batch: 53360/60157............. Loss: 5.5262\n",
      "batch: 53376/60157............. Loss: 5.5264\n",
      "batch: 53392/60157............. Loss: 5.5177\n",
      "batch: 53408/60157............. Loss: 5.5252\n",
      "batch: 53424/60157............. Loss: 5.5294\n",
      "batch: 53440/60157............. Loss: 5.5167\n",
      "batch: 53456/60157............. Loss: 5.5270\n",
      "batch: 53472/60157............. Loss: 5.5207\n",
      "batch: 53488/60157............. Loss: 5.5262\n",
      "batch: 53504/60157............. Loss: 5.5270\n",
      "batch: 53520/60157............. Loss: 5.5278\n",
      "batch: 53536/60157............. Loss: 5.5276\n",
      "batch: 53552/60157............. Loss: 5.5269\n",
      "batch: 53568/60157............. Loss: 5.5244\n",
      "batch: 53584/60157............. Loss: 5.5295\n",
      "batch: 53600/60157............. Loss: 5.5218\n",
      "batch: 53616/60157............. Loss: 5.5284\n",
      "batch: 53632/60157............. Loss: 5.5265\n",
      "batch: 53648/60157............. Loss: 5.5297\n",
      "batch: 53664/60157............. Loss: 5.5293\n",
      "batch: 53680/60157............. Loss: 5.5299\n",
      "batch: 53696/60157............. Loss: 5.5244\n",
      "batch: 53712/60157............. Loss: 5.5258\n",
      "batch: 53728/60157............. Loss: 5.5257\n",
      "batch: 53744/60157............. Loss: 5.5245\n",
      "batch: 53760/60157............. Loss: 5.5264\n",
      "batch: 53776/60157............. Loss: 5.5281\n",
      "batch: 53792/60157............. Loss: 5.5261\n",
      "batch: 53808/60157............. Loss: 5.5282\n",
      "batch: 53824/60157............. Loss: 5.5227\n",
      "batch: 53840/60157............. Loss: 5.5240\n",
      "batch: 53856/60157............. Loss: 5.5218\n",
      "batch: 53872/60157............. Loss: 5.5244\n",
      "batch: 53888/60157............. Loss: 5.5239\n",
      "batch: 53904/60157............. Loss: 5.5259\n",
      "batch: 53920/60157............. Loss: 5.5262\n",
      "batch: 53936/60157............. Loss: 5.5276\n",
      "batch: 53952/60157............. Loss: 5.5176\n",
      "batch: 53968/60157............. Loss: 5.5277\n",
      "batch: 53984/60157............. Loss: 5.5323\n",
      "batch: 54000/60157............. Loss: 5.5261\n",
      "batch: 54016/60157............. Loss: 5.5271\n",
      "batch: 54032/60157............. Loss: 5.5271\n",
      "batch: 54048/60157............. Loss: 5.5303\n",
      "batch: 54064/60157............. Loss: 5.5275\n",
      "batch: 54080/60157............. Loss: 5.5270\n",
      "batch: 54096/60157............. Loss: 5.5257\n",
      "batch: 54112/60157............. Loss: 5.5240\n",
      "batch: 54128/60157............. Loss: 5.5282\n",
      "batch: 54144/60157............. Loss: 5.5324\n",
      "batch: 54160/60157............. Loss: 5.5207\n",
      "batch: 54176/60157............. Loss: 5.5224\n",
      "batch: 54192/60157............. Loss: 5.5249\n",
      "batch: 54208/60157............. Loss: 5.5242\n",
      "batch: 54224/60157............. Loss: 5.5215\n",
      "batch: 54240/60157............. Loss: 5.5281\n",
      "batch: 54256/60157............. Loss: 5.5278\n",
      "batch: 54272/60157............. Loss: 5.5258\n",
      "batch: 54288/60157............. Loss: 5.5321\n",
      "batch: 54304/60157............. Loss: 5.5252\n",
      "batch: 54320/60157............. Loss: 5.5230\n",
      "batch: 54336/60157............. Loss: 5.5289\n",
      "batch: 54352/60157............. Loss: 5.5276\n",
      "batch: 54368/60157............. Loss: 5.5321\n",
      "batch: 54384/60157............. Loss: 5.5285\n",
      "batch: 54400/60157............. Loss: 5.5258\n",
      "batch: 54416/60157............. Loss: 5.5241\n",
      "batch: 54432/60157............. Loss: 5.5282\n",
      "batch: 54448/60157............. Loss: 5.5223\n",
      "batch: 54464/60157............. Loss: 5.5275\n",
      "batch: 54480/60157............. Loss: 5.5247\n",
      "batch: 54496/60157............. Loss: 5.5294\n",
      "batch: 54512/60157............. Loss: 5.5252\n",
      "batch: 54528/60157............. Loss: 5.5265\n",
      "batch: 54544/60157............. Loss: 5.5214\n",
      "batch: 54560/60157............. Loss: 5.5236\n",
      "batch: 54576/60157............. Loss: 5.5239\n",
      "batch: 54592/60157............. Loss: 5.5294\n",
      "batch: 54608/60157............. Loss: 5.5273\n",
      "batch: 54624/60157............. Loss: 5.5249\n",
      "batch: 54640/60157............. Loss: 5.5263\n",
      "batch: 54656/60157............. Loss: 5.5219\n",
      "batch: 54672/60157............. Loss: 5.5236\n",
      "batch: 54688/60157............. Loss: 5.5274\n",
      "batch: 54704/60157............. Loss: 5.5318\n",
      "batch: 54720/60157............. Loss: 5.5252\n",
      "batch: 54736/60157............. Loss: 5.5248\n",
      "batch: 54752/60157............. Loss: 5.5288\n",
      "batch: 54768/60157............. Loss: 5.5212\n",
      "batch: 54784/60157............. Loss: 5.5283\n",
      "batch: 54800/60157............. Loss: 5.5231\n",
      "batch: 54816/60157............. Loss: 5.5257\n",
      "batch: 54832/60157............. Loss: 5.5260\n",
      "batch: 54848/60157............. Loss: 5.5250\n",
      "batch: 54864/60157............. Loss: 5.5236\n",
      "batch: 54880/60157............. Loss: 5.5242\n",
      "batch: 54896/60157............. Loss: 5.5271\n",
      "batch: 54912/60157............. Loss: 5.5247\n",
      "batch: 54928/60157............. Loss: 5.5256\n",
      "batch: 54944/60157............. Loss: 5.5197\n",
      "batch: 54960/60157............. Loss: 5.5230\n",
      "batch: 54976/60157............. Loss: 5.5229\n",
      "batch: 54992/60157............. Loss: 5.5192\n",
      "batch: 55008/60157............. Loss: 5.5286\n",
      "batch: 55024/60157............. Loss: 5.5264\n",
      "batch: 55040/60157............. Loss: 5.5254\n",
      "batch: 55056/60157............. Loss: 5.5263\n",
      "batch: 55072/60157............. Loss: 5.5244\n",
      "batch: 55088/60157............. Loss: 5.5266\n",
      "batch: 55104/60157............. Loss: 5.5219\n",
      "batch: 55120/60157............. Loss: 5.5238\n",
      "batch: 55136/60157............. Loss: 5.5240\n",
      "batch: 55152/60157............. Loss: 5.5292\n",
      "batch: 55168/60157............. Loss: 5.5314\n",
      "batch: 55184/60157............. Loss: 5.5246\n",
      "batch: 55200/60157............. Loss: 5.5226\n",
      "batch: 55216/60157............. Loss: 5.5211\n",
      "batch: 55232/60157............. Loss: 5.5255\n",
      "batch: 55248/60157............. Loss: 5.5224\n",
      "batch: 55264/60157............. Loss: 5.5242\n",
      "batch: 55280/60157............. Loss: 5.5302\n",
      "batch: 55296/60157............. Loss: 5.5240\n",
      "batch: 55312/60157............. Loss: 5.5242\n",
      "batch: 55328/60157............. Loss: 5.5224\n",
      "batch: 55344/60157............. Loss: 5.5220\n",
      "batch: 55360/60157............. Loss: 5.5289\n",
      "batch: 55376/60157............. Loss: 5.5296\n",
      "batch: 55392/60157............. Loss: 5.5205\n",
      "batch: 55408/60157............. Loss: 5.5233\n",
      "batch: 55424/60157............. Loss: 5.5203\n",
      "batch: 55440/60157............. Loss: 5.5140\n",
      "batch: 55456/60157............. Loss: 5.5223\n",
      "batch: 55472/60157............. Loss: 5.5202\n",
      "batch: 55488/60157............. Loss: 5.5241\n",
      "batch: 55504/60157............. Loss: 5.5276\n",
      "batch: 55520/60157............. Loss: 5.5238\n",
      "batch: 55536/60157............. Loss: 5.5225\n",
      "batch: 55552/60157............. Loss: 5.5291\n",
      "batch: 55568/60157............. Loss: 5.5256\n",
      "batch: 55584/60157............. Loss: 5.5259\n",
      "batch: 55600/60157............. Loss: 5.5294\n",
      "batch: 55616/60157............. Loss: 5.5197\n",
      "batch: 55632/60157............. Loss: 5.5201\n",
      "batch: 55648/60157............. Loss: 5.5109\n",
      "batch: 55664/60157............. Loss: 5.5184\n",
      "batch: 55680/60157............. Loss: 5.5228\n",
      "batch: 55696/60157............. Loss: 5.5250\n",
      "batch: 55712/60157............. Loss: 5.5283\n",
      "batch: 55728/60157............. Loss: 5.5238\n",
      "batch: 55744/60157............. Loss: 5.5221\n",
      "batch: 55760/60157............. Loss: 5.5252\n",
      "batch: 55776/60157............. Loss: 5.5262\n",
      "batch: 55792/60157............. Loss: 5.5264\n",
      "batch: 55808/60157............. Loss: 5.5273\n",
      "batch: 55824/60157............. Loss: 5.5271\n",
      "batch: 55840/60157............. Loss: 5.5269\n",
      "batch: 55856/60157............. Loss: 5.5279\n",
      "batch: 55872/60157............. Loss: 5.5209\n",
      "batch: 55888/60157............. Loss: 5.5253\n",
      "batch: 55904/60157............. Loss: 5.5258\n",
      "batch: 55920/60157............. Loss: 5.5308\n",
      "batch: 55936/60157............. Loss: 5.5231\n",
      "batch: 55952/60157............. Loss: 5.5207\n",
      "batch: 55968/60157............. Loss: 5.5276\n",
      "batch: 55984/60157............. Loss: 5.5276\n",
      "batch: 56000/60157............. Loss: 5.5218\n",
      "batch: 56016/60157............. Loss: 5.5273\n",
      "batch: 56032/60157............. Loss: 5.5270\n",
      "batch: 56048/60157............. Loss: 5.5151\n",
      "batch: 56064/60157............. Loss: 5.5259\n",
      "batch: 56080/60157............. Loss: 5.5268\n",
      "batch: 56096/60157............. Loss: 5.5234\n",
      "batch: 56112/60157............. Loss: 5.5293\n",
      "batch: 56128/60157............. Loss: 5.5245\n",
      "batch: 56144/60157............. Loss: 5.5210\n",
      "batch: 56160/60157............. Loss: 5.5310\n",
      "batch: 56176/60157............. Loss: 5.5221\n",
      "batch: 56192/60157............. Loss: 5.5251\n",
      "batch: 56208/60157............. Loss: 5.5283\n",
      "batch: 56224/60157............. Loss: 5.5253\n",
      "batch: 56240/60157............. Loss: 5.5239\n",
      "batch: 56256/60157............. Loss: 5.5271\n",
      "batch: 56272/60157............. Loss: 5.5230\n",
      "batch: 56288/60157............. Loss: 5.5265\n",
      "batch: 56304/60157............. Loss: 5.5207\n",
      "batch: 56320/60157............. Loss: 5.5260\n",
      "batch: 56336/60157............. Loss: 5.5223\n",
      "batch: 56352/60157............. Loss: 5.5202\n",
      "batch: 56368/60157............. Loss: 5.5256\n",
      "batch: 56384/60157............. Loss: 5.5209\n",
      "batch: 56400/60157............. Loss: 5.5230\n",
      "batch: 56416/60157............. Loss: 5.5251\n",
      "batch: 56432/60157............. Loss: 5.5186\n",
      "batch: 56448/60157............. Loss: 5.5257\n",
      "batch: 56464/60157............. Loss: 5.5277\n",
      "batch: 56480/60157............. Loss: 5.5223\n",
      "batch: 56496/60157............. Loss: 5.5190\n",
      "batch: 56512/60157............. Loss: 5.5249\n",
      "batch: 56528/60157............. Loss: 5.5260\n",
      "batch: 56544/60157............. Loss: 5.5272\n",
      "batch: 56560/60157............. Loss: 5.5276\n",
      "batch: 56576/60157............. Loss: 5.5281\n",
      "batch: 56592/60157............. Loss: 5.5204\n",
      "batch: 56608/60157............. Loss: 5.5279\n",
      "batch: 56624/60157............. Loss: 5.5256\n",
      "batch: 56640/60157............. Loss: 5.5252\n",
      "batch: 56656/60157............. Loss: 5.5302\n",
      "batch: 56672/60157............. Loss: 5.5273\n",
      "batch: 56688/60157............. Loss: 5.5297\n",
      "batch: 56704/60157............. Loss: 5.5196\n",
      "batch: 56720/60157............. Loss: 5.5285\n",
      "batch: 56736/60157............. Loss: 5.5266\n",
      "batch: 56752/60157............. Loss: 5.5295\n",
      "batch: 56768/60157............. Loss: 5.5285\n",
      "batch: 56784/60157............. Loss: 5.5292\n",
      "batch: 56800/60157............. Loss: 5.5276\n",
      "batch: 56816/60157............. Loss: 5.5244\n",
      "batch: 56832/60157............. Loss: 5.5283\n",
      "batch: 56848/60157............. Loss: 5.5253\n",
      "batch: 56864/60157............. Loss: 5.5311\n",
      "batch: 56880/60157............. Loss: 5.5299\n",
      "batch: 56896/60157............. Loss: 5.5229\n",
      "batch: 56912/60157............. Loss: 5.5285\n",
      "batch: 56928/60157............. Loss: 5.5279\n",
      "batch: 56944/60157............. Loss: 5.5225\n",
      "batch: 56960/60157............. Loss: 5.5262\n",
      "batch: 56976/60157............. Loss: 5.5259\n",
      "batch: 56992/60157............. Loss: 5.5298\n",
      "batch: 57008/60157............. Loss: 5.5273\n",
      "batch: 57024/60157............. Loss: 5.5319\n",
      "batch: 57040/60157............. Loss: 5.5267\n",
      "batch: 57056/60157............. Loss: 5.5239\n",
      "batch: 57072/60157............. Loss: 5.5284\n",
      "batch: 57088/60157............. Loss: 5.5263\n",
      "batch: 57104/60157............. Loss: 5.5292\n",
      "batch: 57120/60157............. Loss: 5.5257\n",
      "batch: 57136/60157............. Loss: 5.5257\n",
      "batch: 57152/60157............. Loss: 5.5243\n",
      "batch: 57168/60157............. Loss: 5.5250\n",
      "batch: 57184/60157............. Loss: 5.5279\n",
      "batch: 57200/60157............. Loss: 5.5206\n",
      "batch: 57216/60157............. Loss: 5.5295\n",
      "batch: 57232/60157............. Loss: 5.5278\n",
      "batch: 57248/60157............. Loss: 5.5259\n",
      "batch: 57264/60157............. Loss: 5.5315\n",
      "batch: 57280/60157............. Loss: 5.5277\n",
      "batch: 57296/60157............. Loss: 5.5259\n",
      "batch: 57312/60157............. Loss: 5.5302\n",
      "batch: 57328/60157............. Loss: 5.5275\n",
      "batch: 57344/60157............. Loss: 5.5288\n",
      "batch: 57360/60157............. Loss: 5.5298\n",
      "batch: 57376/60157............. Loss: 5.5281\n",
      "batch: 57392/60157............. Loss: 5.5246\n",
      "batch: 57408/60157............. Loss: 5.5262\n",
      "batch: 57424/60157............. Loss: 5.5198\n",
      "batch: 57440/60157............. Loss: 5.5298\n",
      "batch: 57456/60157............. Loss: 5.5243\n",
      "batch: 57472/60157............. Loss: 5.5263\n",
      "batch: 57488/60157............. Loss: 5.5275\n",
      "batch: 57504/60157............. Loss: 5.5252\n",
      "batch: 57520/60157............. Loss: 5.5265\n",
      "batch: 57536/60157............. Loss: 5.5233\n",
      "batch: 57552/60157............. Loss: 5.5255\n",
      "batch: 57568/60157............. Loss: 5.5233\n",
      "batch: 57584/60157............. Loss: 5.5297\n",
      "batch: 57600/60157............. Loss: 5.5283\n",
      "batch: 57616/60157............. Loss: 5.5244\n",
      "batch: 57632/60157............. Loss: 5.5305\n",
      "batch: 57648/60157............. Loss: 5.5278\n",
      "batch: 57664/60157............. Loss: 5.5269\n",
      "batch: 57680/60157............. Loss: 5.5309\n",
      "batch: 57696/60157............. Loss: 5.5285\n",
      "batch: 57712/60157............. Loss: 5.5237\n",
      "batch: 57728/60157............. Loss: 5.5138\n",
      "batch: 57744/60157............. Loss: 5.5274\n",
      "batch: 57760/60157............. Loss: 5.5253\n",
      "batch: 57776/60157............. Loss: 5.5260\n",
      "batch: 57792/60157............. Loss: 5.5287\n",
      "batch: 57808/60157............. Loss: 5.5250\n",
      "batch: 57824/60157............. Loss: 5.5295\n",
      "batch: 57840/60157............. Loss: 5.5279\n",
      "batch: 57856/60157............. Loss: 5.5246\n",
      "batch: 57872/60157............. Loss: 5.5285\n",
      "batch: 57888/60157............. Loss: 5.5253\n",
      "batch: 57904/60157............. Loss: 5.5208\n",
      "batch: 57920/60157............. Loss: 5.5238\n",
      "batch: 57936/60157............. Loss: 5.5297\n",
      "batch: 57952/60157............. Loss: 5.5301\n",
      "batch: 57968/60157............. Loss: 5.5219\n",
      "batch: 57984/60157............. Loss: 5.5253\n",
      "batch: 58000/60157............. Loss: 5.5255\n",
      "batch: 58016/60157............. Loss: 5.5284\n",
      "batch: 58032/60157............. Loss: 5.5284\n",
      "batch: 58048/60157............. Loss: 5.5334\n",
      "batch: 58064/60157............. Loss: 5.5304\n",
      "batch: 58080/60157............. Loss: 5.5281\n",
      "batch: 58096/60157............. Loss: 5.5310\n",
      "batch: 58112/60157............. Loss: 5.5271\n",
      "batch: 58128/60157............. Loss: 5.5304\n",
      "batch: 58144/60157............. Loss: 5.5314\n",
      "batch: 58160/60157............. Loss: 5.5268\n",
      "batch: 58176/60157............. Loss: 5.5261\n",
      "batch: 58192/60157............. Loss: 5.5258\n",
      "batch: 58208/60157............. Loss: 5.5250\n",
      "batch: 58224/60157............. Loss: 5.5282\n",
      "batch: 58240/60157............. Loss: 5.5284\n",
      "batch: 58256/60157............. Loss: 5.5339\n",
      "batch: 58272/60157............. Loss: 5.5300\n",
      "batch: 58288/60157............. Loss: 5.5290\n",
      "batch: 58304/60157............. Loss: 5.5256\n",
      "batch: 58320/60157............. Loss: 5.5246\n",
      "batch: 58336/60157............. Loss: 5.5222\n",
      "batch: 58352/60157............. Loss: 5.5253\n",
      "batch: 58368/60157............. Loss: 5.5301\n",
      "batch: 58384/60157............. Loss: 5.5294\n",
      "batch: 58400/60157............. Loss: 5.5275\n",
      "batch: 58416/60157............. Loss: 5.5251\n",
      "batch: 58432/60157............. Loss: 5.5246\n",
      "batch: 58448/60157............. Loss: 5.5243\n",
      "batch: 58464/60157............. Loss: 5.5301\n",
      "batch: 58480/60157............. Loss: 5.5272\n",
      "batch: 58496/60157............. Loss: 5.5274\n",
      "batch: 58512/60157............. Loss: 5.5259\n",
      "batch: 58528/60157............. Loss: 5.5214\n",
      "batch: 58544/60157............. Loss: 5.5227\n",
      "batch: 58560/60157............. Loss: 5.5267\n",
      "batch: 58576/60157............. Loss: 5.5300\n",
      "batch: 58592/60157............. Loss: 5.5338\n",
      "batch: 58608/60157............. Loss: 5.5273\n",
      "batch: 58624/60157............. Loss: 5.5303\n",
      "batch: 58640/60157............. Loss: 5.5249\n",
      "batch: 58656/60157............. Loss: 5.5287\n",
      "batch: 58672/60157............. Loss: 5.5273\n",
      "batch: 58688/60157............. Loss: 5.5262\n",
      "batch: 58704/60157............. Loss: 5.5243\n",
      "batch: 58720/60157............. Loss: 5.5228\n",
      "batch: 58736/60157............. Loss: 5.5262\n",
      "batch: 58752/60157............. Loss: 5.5260\n",
      "batch: 58768/60157............. Loss: 5.5305\n",
      "batch: 58784/60157............. Loss: 5.5253\n",
      "batch: 58800/60157............. Loss: 5.5262\n",
      "batch: 58816/60157............. Loss: 5.5321\n",
      "batch: 58832/60157............. Loss: 5.5273\n",
      "batch: 58848/60157............. Loss: 5.5266\n",
      "batch: 58864/60157............. Loss: 5.5254\n",
      "batch: 58880/60157............. Loss: 5.5270\n",
      "batch: 58896/60157............. Loss: 5.5258\n",
      "batch: 58912/60157............. Loss: 5.5202\n",
      "batch: 58928/60157............. Loss: 5.5307\n",
      "batch: 58944/60157............. Loss: 5.5273\n",
      "batch: 58960/60157............. Loss: 5.5179\n",
      "batch: 58976/60157............. Loss: 5.5286\n",
      "batch: 58992/60157............. Loss: 5.5145\n",
      "batch: 59008/60157............. Loss: 5.5256\n",
      "batch: 59024/60157............. Loss: 5.5270\n",
      "batch: 59040/60157............. Loss: 5.5290\n",
      "batch: 59056/60157............. Loss: 5.5236\n",
      "batch: 59072/60157............. Loss: 5.5291\n",
      "batch: 59088/60157............. Loss: 5.5279\n",
      "batch: 59104/60157............. Loss: 5.5277\n",
      "batch: 59120/60157............. Loss: 5.5300\n",
      "batch: 59136/60157............. Loss: 5.5260\n",
      "batch: 59152/60157............. Loss: 5.5287\n",
      "batch: 59168/60157............. Loss: 5.5287\n",
      "batch: 59184/60157............. Loss: 5.5275\n",
      "batch: 59200/60157............. Loss: 5.5250\n",
      "batch: 59216/60157............. Loss: 5.5257\n",
      "batch: 59232/60157............. Loss: 5.5311\n",
      "batch: 59248/60157............. Loss: 5.5311\n",
      "batch: 59264/60157............. Loss: 5.5265\n",
      "batch: 59280/60157............. Loss: 5.5261\n",
      "batch: 59296/60157............. Loss: 5.5249\n",
      "batch: 59312/60157............. Loss: 5.5320\n",
      "batch: 59328/60157............. Loss: 5.5246\n",
      "batch: 59344/60157............. Loss: 5.5264\n",
      "batch: 59360/60157............. Loss: 5.5298\n",
      "batch: 59376/60157............. Loss: 5.5215\n",
      "batch: 59392/60157............. Loss: 5.5276\n",
      "batch: 59408/60157............. Loss: 5.5266\n",
      "batch: 59424/60157............. Loss: 5.5291\n",
      "batch: 59440/60157............. Loss: 5.5226\n",
      "batch: 59456/60157............. Loss: 5.5305\n",
      "batch: 59472/60157............. Loss: 5.5285\n",
      "batch: 59488/60157............. Loss: 5.5282\n",
      "batch: 59504/60157............. Loss: 5.5138\n",
      "batch: 59520/60157............. Loss: 5.5300\n",
      "batch: 59536/60157............. Loss: 5.5280\n",
      "batch: 59552/60157............. Loss: 5.5272\n",
      "batch: 59568/60157............. Loss: 5.5252\n",
      "batch: 59584/60157............. Loss: 5.5284\n",
      "batch: 59600/60157............. Loss: 5.5241\n",
      "batch: 59616/60157............. Loss: 5.5195\n",
      "batch: 59632/60157............. Loss: 5.5242\n",
      "batch: 59648/60157............. Loss: 5.5313\n",
      "batch: 59664/60157............. Loss: 5.5333\n",
      "batch: 59680/60157............. Loss: 5.5333\n",
      "batch: 59696/60157............. Loss: 5.5232\n",
      "batch: 59712/60157............. Loss: 5.5283\n",
      "batch: 59728/60157............. Loss: 5.5264\n",
      "batch: 59744/60157............. Loss: 5.5243\n",
      "batch: 59760/60157............. Loss: 5.5286\n",
      "batch: 59776/60157............. Loss: 5.5233\n",
      "batch: 59792/60157............. Loss: 5.5243\n",
      "batch: 59808/60157............. Loss: 5.5302\n",
      "batch: 59824/60157............. Loss: 5.5247\n",
      "batch: 59840/60157............. Loss: 5.5266\n",
      "batch: 59856/60157............. Loss: 5.5255\n",
      "batch: 59872/60157............. Loss: 5.5297\n",
      "batch: 59888/60157............. Loss: 5.5252\n",
      "batch: 59904/60157............. Loss: 5.5271\n",
      "batch: 59920/60157............. Loss: 5.5247\n",
      "batch: 59936/60157............. Loss: 5.5237\n",
      "batch: 59952/60157............. Loss: 5.5296\n",
      "batch: 59968/60157............. Loss: 5.5250\n",
      "batch: 59984/60157............. Loss: 5.5271\n",
      "batch: 60000/60157............. Loss: 5.5269\n",
      "batch: 60016/60157............. Loss: 5.5279\n",
      "batch: 60032/60157............. Loss: 5.5305\n",
      "batch: 60048/60157............. Loss: 5.5195\n",
      "batch: 60064/60157............. Loss: 5.5267\n",
      "batch: 60080/60157............. Loss: 5.5254\n",
      "batch: 60096/60157............. Loss: 5.5274\n",
      "batch: 60112/60157............. Loss: 5.5222\n",
      "batch: 60128/60157............. Loss: 5.5293\n",
      "batch: 60144/60157............. Loss: 5.5293\n",
      "batch: 60160/60157............. Loss: 5.5305\n",
      "Epoch: 1/1............. Loss: 5.5305\n",
      "CPU times: user 4h 3min 48s, sys: 29min 51s, total: 4h 33min 40s\n",
      "Wall time: 3h 40min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs=1\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad()\n",
    "        input_seq = input_seq.cuda()\n",
    "        target_seq = target_seq.cuda()\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_batch += BATCH_SIZE\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b5c1e-718e-41f2-8389-6bab1cc74704",
   "metadata": {},
   "source": [
    "torch.save(model, \"model3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba31536-9c6c-49b7-a550-3acc606241a6",
   "metadata": {},
   "source": [
    "Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06219fd6-678a-4d15-bdb4-ed67e7c9fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(input_seq, target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523b6df-cf04-406a-99f2-02c1a1d626a1",
   "metadata": {},
   "source": [
    "## **4. RNN con audio como input y embedding de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac379830-12ef-45b5-8d55-7b11299fdb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdfa895b-ae9e-4f10-8d98-cc8e98878ee3",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 1\n",
    "dataset = LocalVideoDatasetAprox2(get_image_embeddings=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for batch in iter(dataloader):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9415713a-912a-4f8e-ad77-bcb30e00f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalVideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb11198-2bdd-49f9-a224-8c9c0219fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con 60157 instancias con las que poder trabajar\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar\"%(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d04619-586c-443c-bdf2-0afab9963630",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228d870b-6ab4-40f4-8461-337e22b7ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef0b44b-6a95-4d69-83a4-ba5f1e465152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox4(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(0)\n",
    "model.cuda()\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0af40-2bdf-467a-bf0f-7106e33f86ce",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890dc610-5455-4692-845b-85a67be0e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daba4ae-d8e9-454e-aa14-40c8acd6906a",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e420988-16b8-4c15-8fae-1bd4af2636db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos_mds/train/../src/Dataset.py:230: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sound_frames = torch.tensor(sound_frames, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 20/60157............. Loss: 5.5455\n",
      "batch: 40/60157............. Loss: 5.5441\n",
      "batch: 60/60157............. Loss: 5.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid new backstep -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 80/60157............. Loss: 5.5428\n",
      "batch: 100/60157............. Loss: 5.5428\n",
      "batch: 120/60157............. Loss: 5.5421\n",
      "batch: 140/60157............. Loss: 5.5398\n",
      "batch: 160/60157............. Loss: 5.5397\n",
      "batch: 180/60157............. Loss: 5.5376\n",
      "batch: 200/60157............. Loss: 5.5381\n",
      "batch: 220/60157............. Loss: 5.5378\n",
      "batch: 240/60157............. Loss: 5.5364\n",
      "batch: 260/60157............. Loss: 5.5377\n",
      "batch: 280/60157............. Loss: 5.5368\n",
      "batch: 300/60157............. Loss: 5.5342\n",
      "batch: 320/60157............. Loss: 5.5349\n",
      "batch: 340/60157............. Loss: 5.5350\n",
      "batch: 360/60157............. Loss: 5.5330\n",
      "batch: 380/60157............. Loss: 5.5326\n",
      "batch: 400/60157............. Loss: 5.5340\n",
      "batch: 420/60157............. Loss: 5.5330\n",
      "batch: 440/60157............. Loss: 5.5333\n",
      "batch: 460/60157............. Loss: 5.5329\n",
      "batch: 480/60157............. Loss: 5.5314\n",
      "batch: 500/60157............. Loss: 5.5331\n",
      "batch: 520/60157............. Loss: 5.5328\n",
      "batch: 540/60157............. Loss: 5.5305\n",
      "batch: 560/60157............. Loss: 5.5321\n",
      "batch: 580/60157............. Loss: 5.5322\n",
      "batch: 600/60157............. Loss: 5.5351\n",
      "batch: 620/60157............. Loss: 5.5324\n",
      "batch: 640/60157............. Loss: 5.5308\n",
      "batch: 660/60157............. Loss: 5.5314\n",
      "batch: 680/60157............. Loss: 5.5328\n",
      "batch: 700/60157............. Loss: 5.5319\n",
      "batch: 720/60157............. Loss: 5.5309\n",
      "batch: 740/60157............. Loss: 5.5270\n",
      "batch: 760/60157............. Loss: 5.5313\n",
      "batch: 780/60157............. Loss: 5.5339\n",
      "batch: 800/60157............. Loss: 5.5294\n",
      "batch: 820/60157............. Loss: 5.5287\n",
      "batch: 840/60157............. Loss: 5.5298\n",
      "batch: 860/60157............. Loss: 5.5271\n",
      "batch: 880/60157............. Loss: 5.5313\n",
      "batch: 900/60157............. Loss: 5.5315\n",
      "batch: 920/60157............. Loss: 5.5263\n",
      "batch: 940/60157............. Loss: 5.5301\n",
      "batch: 960/60157............. Loss: 5.5267\n",
      "batch: 980/60157............. Loss: 5.5280\n",
      "batch: 1000/60157............. Loss: 5.5273\n",
      "batch: 1020/60157............. Loss: 5.5237\n",
      "batch: 1040/60157............. Loss: 5.5270\n",
      "batch: 1060/60157............. Loss: 5.5284\n",
      "batch: 1080/60157............. Loss: 5.5269\n",
      "batch: 1100/60157............. Loss: 5.5272\n",
      "batch: 1120/60157............. Loss: 5.5273\n",
      "batch: 1140/60157............. Loss: 5.5294\n",
      "batch: 1160/60157............. Loss: 5.5254\n",
      "batch: 1180/60157............. Loss: 5.5337\n",
      "batch: 1200/60157............. Loss: 5.5270\n",
      "batch: 1220/60157............. Loss: 5.5305\n",
      "batch: 1240/60157............. Loss: 5.5218\n",
      "batch: 1260/60157............. Loss: 5.5276\n",
      "batch: 1280/60157............. Loss: 5.5277\n",
      "batch: 1300/60157............. Loss: 5.5277\n",
      "batch: 1320/60157............. Loss: 5.5304\n",
      "batch: 1340/60157............. Loss: 5.5263\n",
      "batch: 1360/60157............. Loss: 5.5291\n",
      "batch: 1380/60157............. Loss: 5.5309\n",
      "batch: 1400/60157............. Loss: 5.5255\n",
      "batch: 1420/60157............. Loss: 5.5235\n",
      "batch: 1440/60157............. Loss: 5.5254\n",
      "batch: 1460/60157............. Loss: 5.5269\n",
      "batch: 1480/60157............. Loss: 5.5254\n",
      "batch: 1500/60157............. Loss: 5.5252\n",
      "batch: 1520/60157............. Loss: 5.5279\n",
      "batch: 1540/60157............. Loss: 5.5277\n",
      "batch: 1560/60157............. Loss: 5.5294\n",
      "batch: 1580/60157............. Loss: 5.5311\n",
      "batch: 1600/60157............. Loss: 5.5255\n",
      "batch: 1620/60157............. Loss: 5.5249\n",
      "batch: 1640/60157............. Loss: 5.5267\n",
      "batch: 1660/60157............. Loss: 5.5240\n",
      "batch: 1680/60157............. Loss: 5.5253\n",
      "batch: 1700/60157............. Loss: 5.5306\n",
      "batch: 1720/60157............. Loss: 5.5274\n",
      "batch: 1740/60157............. Loss: 5.5251\n",
      "batch: 1760/60157............. Loss: 5.5258\n",
      "batch: 1780/60157............. Loss: 5.5264\n",
      "batch: 1800/60157............. Loss: 5.5242\n",
      "batch: 1820/60157............. Loss: 5.5231\n",
      "batch: 1840/60157............. Loss: 5.5230\n",
      "batch: 1860/60157............. Loss: 5.5267\n",
      "batch: 1880/60157............. Loss: 5.5269\n",
      "batch: 1900/60157............. Loss: 5.5285\n",
      "batch: 1920/60157............. Loss: 5.5286\n",
      "batch: 1940/60157............. Loss: 5.5258\n",
      "batch: 1960/60157............. Loss: 5.5267\n",
      "batch: 1980/60157............. Loss: 5.5225\n",
      "batch: 2000/60157............. Loss: 5.5255\n",
      "batch: 2020/60157............. Loss: 5.5229\n",
      "batch: 2040/60157............. Loss: 5.5270\n",
      "batch: 2060/60157............. Loss: 5.5260\n",
      "batch: 2080/60157............. Loss: 5.5270\n",
      "batch: 2100/60157............. Loss: 5.5303\n",
      "batch: 2120/60157............. Loss: 5.5274\n",
      "batch: 2140/60157............. Loss: 5.5269\n",
      "batch: 2160/60157............. Loss: 5.5211\n",
      "batch: 2180/60157............. Loss: 5.5235\n",
      "batch: 2200/60157............. Loss: 5.5251\n",
      "batch: 2220/60157............. Loss: 5.5237\n",
      "batch: 2240/60157............. Loss: 5.5259\n",
      "batch: 2260/60157............. Loss: 5.5263\n",
      "batch: 2280/60157............. Loss: 5.5258\n",
      "batch: 2300/60157............. Loss: 5.5216\n",
      "batch: 2320/60157............. Loss: 5.5213\n",
      "batch: 2340/60157............. Loss: 5.5217\n",
      "batch: 2360/60157............. Loss: 5.5221\n",
      "batch: 2380/60157............. Loss: 5.5277\n",
      "batch: 2400/60157............. Loss: 5.5213\n",
      "batch: 2420/60157............. Loss: 5.5248\n",
      "batch: 2440/60157............. Loss: 5.5227\n",
      "batch: 2460/60157............. Loss: 5.5264\n",
      "batch: 2480/60157............. Loss: 5.5206\n",
      "batch: 2500/60157............. Loss: 5.5186\n",
      "batch: 2520/60157............. Loss: 5.5272\n",
      "batch: 2540/60157............. Loss: 5.5234\n",
      "batch: 2560/60157............. Loss: 5.5286\n",
      "batch: 2580/60157............. Loss: 5.5195\n",
      "batch: 2600/60157............. Loss: 5.5260\n"
     ]
    }
   ],
   "source": [
    "n_epochs=1\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        batch = batch\n",
    "        target_seq = target_seq.cuda()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_batch += BATCH_SIZE\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5150f5-1799-4667-97a3-20a5c22e834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8c936-81f6-4188-b1cc-30a31903b05d",
   "metadata": {},
   "source": [
    "## **5. LSTM con audio como input y embedding de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ee234-1ab3-40ca-a180-4dacdfe3dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbee17-b0b5-4493-880f-c95e3eca48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140374fa-f12c-4b78-bf9c-2a9b63276057",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d66be-8db5-4fd8-8c63-cbc33d84a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bea01-4857-4992-8027-81a0fbca2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox5(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04307d38-5d67-46f8-bfc2-922465e6afc8",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba735e-faac-4864-a26d-1796b8e6b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc84b1d-166b-48ac-b97b-420f50e81877",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e303b15-b43a-4f19-939c-1867d02fd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea168d-d255-481e-9e50-5d6c3a3e5874",
   "metadata": {},
   "source": [
    "## **6. GRU con audio como input y embedding de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db8925-f3b5-4d9e-9d71-881f6e3273aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ac9f1-47f4-4b4f-b8bf-2f315bb9e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bb0a4-21ff-484d-9823-a47b4e72959c",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fdc31-6d99-47fb-8992-cf29f5992f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6bae6-a7d9-4752-b0b8-5fd319c81de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox6(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87fd65-4c3f-47fc-ac26-33fee2fd678d",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23f62b-06fc-4af6-810e-709d9292a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6571a7-f6c1-41b3-ac41-caee09d0551b",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a05010-71a7-4e26-88f5-967b7d7848e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a61daf-2559-4034-8db4-9fb4c3507f07",
   "metadata": {},
   "source": [
    "## **7. RNN con audio como input y 10 embeddings de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124fd39-7737-4898-9fde-5ab0a15b2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493bf297-a115-4397-a601-948f9e572772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cedda-a0e9-41dd-be0e-a4adecf90ad9",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c280f62-a6a6-468b-99d3-7dfe776b9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151e356-8bb8-4eb7-a0b3-9d4810203c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox7(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07424b2-0722-4f3f-8d36-a526726acc2f",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787701d-8e46-4e96-9c66-798deb22decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b06a8-fbec-4bdd-bd2c-dff952e85758",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd879c-95c7-43e6-84cb-e8455450008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4c9c2-7e7b-4e67-9556-501756462999",
   "metadata": {},
   "source": [
    "## **8. LSTM con audio como input y 10 embeddings de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67799df0-377d-420e-a57a-efc264c34310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe1457-f69d-479c-a068-376aed8c8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217590d-f03d-4320-82c5-938d150fd593",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484e59a-beed-422a-a6d9-1f60924f2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7ed03-0841-4a73-827f-f74bb22edb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox8(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8541d1f-2896-4a8e-9c40-8cf86ee4bae3",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbaf505-a40a-4963-b394-c433f2ed49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f08f3-b2ee-4fa8-a18d-fb05beb0ace7",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9cec0-a355-4bf2-96ff-4917a252fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9275f-9246-49d5-8700-157c0148348a",
   "metadata": {},
   "source": [
    "## **9. GRU con audio como input y 10 embeddings de video inception v3 como valor inicial del hidden state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562557fb-51c4-4048-89e2-66da52fcc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d0408-8678-4381-82f8-14fd1215a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e8c7a-0f37-4ea8-bd75-10a6cf0939dc",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510906b-d369-4805-96bb-9410296ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b777c4-0950-445d-abb2-a9ff39bd98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox9(input_size=1, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755c7a3-ec13-4df4-8642-80e838d09f51",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6531f-bc93-4fae-b5d7-16780b76796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09377ad3-e504-4b09-99f2-29ec15843fab",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365debe7-6c69-44c7-b793-49d4c479907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75930114-dd22-4e33-bcb1-04d5731594c3",
   "metadata": {},
   "source": [
    "## **10. RNN con audio como input y todos video embedding upsampleado como segunda serie temporal de dimension 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ace5a-9245-44f6-897e-f607626c0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11e7df-bb27-4543-8113-d4c471415539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4c190d-879b-4128-8400-f11bea56b09f",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf293d-490f-498d-966c-492e219a3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e510d5-d5e5-442b-8b85-6f0bc71a577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox10(input_size=1025, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599e01e-e6be-4ee4-b7f6-95dab0206269",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefbf82-3600-4210-ab4c-89f10e98218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022777cf-0824-4b99-aa80-cffc9447ddb9",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42f675-767b-4d2b-be61-3f6fb7d4363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db513b-2ffa-4cb5-9cb1-25cb8dd409b6",
   "metadata": {},
   "source": [
    "## **11. LSTM con audio como input y todos video embedding upsampleado como segunda serie temporal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214cf042-2323-44e1-ba8b-3ba3cf266631",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110c6dd-3831-4430-8213-58e780d16d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1c149-7d2c-4c55-afc8-6225dd9a7ffa",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e9dd8-ccab-4ca6-9257-80b6bee6bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119047a8-5311-4cac-a70c-607492db3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox11(input_size=1025, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da488e-8822-4d9e-9731-29d15384d624",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c52a0-97c3-4db4-ac9e-511c0701ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd637a74-3c42-4c7d-9628-d1820d733dd9",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ced142-6c92-443c-9e89-7493d1a41798",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106d7df-540e-427b-aa91-41ae4ce7c389",
   "metadata": {},
   "source": [
    "## **12. GRU con audio como input y todos video embedding upsampleado como segunda serie temporal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e16ff9-d8e9-4262-abea-d707fcd199ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719fc49-2911-46d5-972e-24b91e6cff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352a903-9c58-494d-ad6c-1e500fb7452f",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ccd93-6d03-4a24-8569-fefb0eea673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55ff2b-dbbb-4f8a-9c7d-452550a3ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox12(input_size=1025, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ed3d9-7208-440f-bee2-781bced6c500",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42d00f-1ef0-4b2b-85c8-63a060addff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d60e2-e11f-4629-86a7-026036bb80db",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0923c58-ad83-4eda-91c9-51a46f3192ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235cb2d-d5bd-4323-a92b-2df2dfb8291b",
   "metadata": {},
   "source": [
    "## **13. RNN con audio como input y todos video embedding upsampleado (linear) como segunda serie temporal**\n",
    "Mismas condiciones que nearest\n",
    "## **14. LSTM con audio como input y todos video embedding upsampleado (linear) como segunda serie temporal**\n",
    "Mismas condiciones que nearest\n",
    "## **15. GRU con audio como input y todos video embedding upsampleado (linear) como segunda serie temporal**\n",
    "Mismas condiciones que nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ed5f9-8b6f-4a9d-a127-8c8916c723f7",
   "metadata": {},
   "source": [
    "## **16. RNN con audio como input y todos video embedding deconvolucionado como segunda serie temporal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f709c-7908-4539-bf72-94ca05fa8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b98ea7-0868-4a1e-8838-fcf4c3ccc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a0b0e-e5d7-41f2-b2e2-72058a6c80d1",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf79eaf-f6f5-4c74-8aa7-0fc00c22d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807807c-6668-4774-96ce-af0a55cbc3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox13(input_size=1025, output_size=256, hidden_dim=64, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ceb753-10cb-44cf-915e-0a93684819e3",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1572af-bd4a-417b-99a9-65a08fa4038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72e552-ef44-4262-8f76-5fd3b7145479",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8eb6d-0915-49ce-8e68-4c295312a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3bd18-d2af-454c-8985-98ac532050fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17eda361-277b-48b1-9e5a-c06e883bbc47",
   "metadata": {},
   "source": [
    "## **17. LSTM con audio como input y todos video embedding deconvolucionado como segunda serie temporal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7a3e7-d206-432c-8c47-808e40aba2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa76c8c-94b9-484f-b205-83e721529b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df14956-e075-447c-884e-7130db3a5b09",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28451c6f-4c73-4bb3-bf71-8845185d2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6985a50-d44d-493a-b855-e9b180fa38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox14(input_size=1025, output_size=256, hidden_dim=12, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df89c5-be86-4708-bf8a-ad407ff32de6",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074eb8b3-6081-426b-b76e-be1dbe27bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ade8a-a8d5-4f69-8371-1bd883e6f779",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb381d6-256c-4c9b-9605-7d7bc964da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c3859-97af-4dc0-9a2d-2e9990067d3a",
   "metadata": {},
   "source": [
    "## **18. GRU con audio como input y todos video embedding deconvolucionado como segunda serie temporal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37705001-2aa6-4892-9bc2-fedc52d66f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300fa433-b8e9-409b-b9c4-0e7ed4d6a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630fc35-c2c5-401c-9869-c88a211b8a6f",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5dcdd-f11b-4af5-a1cc-e99fd8bfcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc2264-280b-4565-b332-27ead93f5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox15(input_size=1025, output_size=256, hidden_dim=12, n_layers=1)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986680e-da12-4dd0-8e9c-4668fbf073a3",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b76439-46f7-469f-99da-945355c989d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366d52e-7620-436b-b85f-85e5e0a0ae03",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bc1b2-b77f-44f8-b674-bfceaf9cf0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        target_seq = input_seq.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128b9d4-b95c-4c09-9da4-ba86c3cb959b",
   "metadata": {},
   "source": [
    "## **19. WaveNet solo audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b892e-9362-4ad4-8d48-2916c8ed9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9779d-178a-4534-9f02-b586ec5488a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c7b3c-ba0b-4be7-b9f8-92adb665ba11",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165c332-c5ce-4d81-a7ab-ea421b84c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95241321-6412-4889-a194-494d0db9952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox16(in_channels=256)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5febc-5bfc-4acc-b854-32427db138c0",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef83d2c-2c42-4c7d-bdd9-164896875182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7812960-9433-4347-b7c5-e13e804df567",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50704c33-d7db-433f-98f8-f1e3fee11c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cdb8c-fd1a-46fa-88d6-f3e3dfade9da",
   "metadata": {},
   "source": [
    "## **20. WaveNet con video upsampleado (nearest) y audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad58b07-32b3-485b-be58-7d30f771f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483ee0b-b591-4142-95b6-981f369789f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ff4ea-283b-4c19-99c3-cc996d4caece",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d18a7-1c82-410e-b199-4c6d3744bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8234aed-0420-4837-afaa-5e59f9732fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox17(in_channels=1280)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee2d66-cb2f-449b-91ce-96994b125025",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f974358-b9bf-4b3c-8f42-317516ec714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aeabb-4199-4497-afa8-c16e4ede675b",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5abd8-abdf-4b83-a090-991d37ac2b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch[0].view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model((input_seq,batch[1]))\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ab965-0793-438e-90ed-9b6465e34e68",
   "metadata": {},
   "source": [
    "## **21. WaveNet con video deconvolucionado y audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978949f4-ac8c-4e50-90bc-785c6577c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf40c2-d3f0-4bf3-97e0-99f3d1d80ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a5921-1ff6-44f1-a544-25fdade6e653",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345aa0d-08ca-4c93-a3ca-a85e798cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799e5f2-6731-4cda-9fba-b81776c9bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox18(in_channels=1280)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5f28c-716a-4907-8fba-92a225a86dd3",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4aa30e-03bb-44b9-9532-35c858b60739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e5576-7913-4951-a627-595936fbcd56",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802a74f-8647-4878-b594-7e68b7fbc298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch[0]\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch[0].view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model((input_seq,batch[1]))\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bea11c-c41c-40e9-8161-ff157b9ba162",
   "metadata": {},
   "source": [
    "## **22. WaveNet con video upsampleado (linear) y audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41b0e6-707c-419b-95d2-5a21c8fecdc5",
   "metadata": {},
   "source": [
    "## **23. BatchPredictionWaveNet solo audio x2 faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783def04-4181-4288-b00d-68e84359741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de762745-e115-4ccb-85e2-72ada93d0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410d4cf-ddc3-4fcd-bc34-e09d64ba4741",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6434d27-2295-4c3d-aec2-73b4145242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241b477-41b5-47d0-8235-fcde2ef9d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox19(in_channels=256)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a78b89-ea3b-4f1e-ae5f-6a2f8926bc93",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc277a8f-cca2-4bef-bfcc-f46b403e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7473dd-53b9-4916-9cba-10133d10d75d",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe875a0-865f-4077-828d-398e3f2f6623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(input_seq)\n",
    "        print(\"Shape final output\",output.shape)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d46d2-65ef-4950-9686-b10c411888b8",
   "metadata": {},
   "source": [
    "## **24. BatchPredictionWaveNet solo audio x4 faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75b7d8-a51b-4938-9ac7-1ad474178cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1274470-ff32-493d-8175-15cd5dc5b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379774e-886f-407c-8b35-0b89cecc85de",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4022c6-3f2e-4b59-8be6-e67f25739eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4cc3cc-c34b-45c0-8dba-bdd6881019b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox19(in_channels=256, boost=4)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff7d97-ddf2-4dff-9c34-7705c1284e41",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f042df-50e3-4b28-a670-4d5167695987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef664c75-b3bf-4f5b-857a-d423c337e510",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3d6a1-0f91-496b-a60c-f025706b8a42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(input_seq)\n",
    "        print(\"Shape final output\",output.shape)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036148b-fdcd-45e9-9af5-52f5ae35d412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7495f326-0032-439a-b6e1-c0fa1400824e",
   "metadata": {},
   "source": [
    "## **25. BatchPredictionWaveNet solo audio x8 faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9a5e4-912c-4bf0-9cb8-bed98c0d2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDatasetAprox3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087f73d-4ca7-44b2-bf45-7c6151951c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset con %d instancias con las que poder trabajar, lo que equivale a %s de almacenamiento\"%(len(dataset), dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d601a5f-197a-4d5c-92c6-5f6fe38fa5af",
   "metadata": {},
   "source": [
    "Inicializamos el dataloader con el que poder ir extrayendo datos como un flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249719c-5c7a-4783-a238-8523e62a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d461de5-fac3-4142-ba09-546b1344bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo correspondiente\n",
    "model = ModelAprox19(in_channels=256, boost=8)\n",
    "# Llevamos el modelo al dispositivo que lo procesará\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definimos hiperparámetros\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Definimos función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0a1c1-3634-49dc-975e-c854cf8a573c",
   "metadata": {},
   "source": [
    "Definimos la función de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068e59e-9cd6-421e-9aa0-755862ce7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_seq, target_seq):\n",
    "    for sample in input_seq:\n",
    "        values_generated = sample[:68000]\n",
    "        n_value = 68000\n",
    "        for value in sample[68000:]:\n",
    "            if n_value>68000:\n",
    "                values_generated = torch.cat((values_generated,output[:,None]), 0)\n",
    "            value = values_generated[None,:]\n",
    "            output = model(value)\n",
    "            output = torch.argmax(output[-1,:])\n",
    "            print(output)\n",
    "            output = torch.tensor([float(output.numpy())])\n",
    "            n_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4dea1-42d7-46e1-92b7-6d08100bc963",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b2417-5665-47d1-b041-3e72e579cc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    n_batch = 0\n",
    "    for batch in iter(dataloader):\n",
    "        input_seq = batch\n",
    "        input_seq = nn.functional.one_hot(input_seq.long(), num_classes=256)\n",
    "        target_seq = batch.view(-1).long()[1:]\n",
    "        target_seq = torch.cat((target_seq, torch.tensor([float(target_seq[-1].numpy())])), 0).long()\n",
    "        target_seq = target_seq.resize_((batch_size,80000))\n",
    "        target_seq = target_seq[:,-70000:]\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        input_seq.to(device)\n",
    "        output = model(input_seq)\n",
    "        print(\"Shape final output\",output.shape)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        n_batch += 32\n",
    "        print('batch: {}/{}.............'.format(n_batch, len(dataset)), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64591516-41a3-4422-a0b7-ba4db6d3d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0109c89a-fe4d-48b7-905c-6e789c27b883",
   "metadata": {},
   "source": [
    "### Una vez probado solo con audio vemos como van con otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c142d19-e882-4929-bfbc-6e244945c690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af77ea-4035-4029-8081-e362d6152e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64424ecb-00e6-48b1-995a-b3045f30f616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8086a11-865a-4d21-b115-71cfe3ac9520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f96b4-7d64-444f-b23b-a023613efc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3dd1bc-2461-41d6-afcd-26797a978c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a48ce6-0aa3-4d66-bfba-973be7b6af70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057db9b-800e-4125-a976-1282b9a67ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debae53-6df1-4893-949d-10f387802103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
